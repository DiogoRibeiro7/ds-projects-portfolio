{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Daily Energy Usage Pattern Clustering (Household Power)\n",
        "\n",
        "This notebook is an **unsupervised energy project** based on the\n",
        "**Individual household electric power consumption** dataset.\n",
        "\n",
        "We will:\n",
        "\n",
        "1. Load and clean high-frequency household power data.\n",
        "2. Aggregate to hourly kWh.\n",
        "3. Build **daily profiles** (24h vectors) and aggregate features.\n",
        "4. Cluster days into usage pattern segments using KMeans.\n",
        "5. Interpret clusters (behavioural patterns) and visualise them.\n",
        "6. Train a simple classifier to predict the cluster of a day from\n",
        "   a small set of features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. How to run this notebook\n",
        "\n",
        "1. Download the dataset **Individual household electric power consumption**\n",
        "   from Kaggle or UCI.\n",
        "2. Save it in your project under:\n",
        "\n",
        "   ```text\n",
        "   data/household_power.csv\n",
        "   ```\n",
        "\n",
        "3. Make sure the file has at least the original columns:\n",
        "\n",
        "   - `Date`, `Time`\n",
        "   - `Global_active_power`\n",
        "   - `Global_reactive_power`, `Voltage`, `Global_intensity`\n",
        "   - `Sub_metering_1`, `Sub_metering_2`, `Sub_metering_3`\n",
        "\n",
        "4. Install Python dependencies in your environment:\n",
        "\n",
        "   ```bash\n",
        "   pip install numpy pandas matplotlib seaborn scikit-learn statsmodels\n",
        "   ```\n",
        "\n",
        "5. Open this notebook in Jupyter / VS Code and run all cells top to bottom.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports and data loading\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score, classification_report, confusion_matrix\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.rcParams[\"figure.figsize\"] = (11, 5)\n",
        "\n",
        "DATA_PATH = Path(\"data\") / \"household_power.csv\"\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "if not DATA_PATH.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Expected dataset at {DATA_PATH.resolve()}\\n\"\n",
        "        \"Download 'Individual household electric power consumption' and save as 'data/household_power.csv'.\"\n",
        "    )\n",
        "\n",
        "raw = pd.read_csv(DATA_PATH)\n",
        "raw.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Cleaning and hourly aggregation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def clean_household_power(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Clean and resample the household power dataset to hourly kWh.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pd.DataFrame\n",
        "        Raw dataframe with Date/Time, Global_active_power and related columns.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        Hourly dataframe indexed by timestamp with at least:\n",
        "        - kwh: energy in that hour (approx. mean kW * 1 hour)\n",
        "        - global_active_power: mean kW in that hour\n",
        "        - sub_metering_1/2/3: hourly sums (if available)\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # Combine Date and Time into a timestamp\n",
        "    if not {\"Date\", \"Time\"}.issubset(df.columns):\n",
        "        raise ValueError(\"Expected 'Date' and 'Time' columns in dataset.\")\n",
        "\n",
        "    df[\"timestamp\"] = pd.to_datetime(df[\"Date\"].astype(str) + \" \" + df[\"Time\"].astype(str), errors=\"coerce\")\n",
        "    df = df.dropna(subset=[\"timestamp\"]).sort_values(\"timestamp\")\n",
        "\n",
        "    # Convert numeric columns\n",
        "    num_cols = [\n",
        "        \"Global_active_power\",\n",
        "        \"Global_reactive_power\",\n",
        "        \"Voltage\",\n",
        "        \"Global_intensity\",\n",
        "        \"Sub_metering_1\",\n",
        "        \"Sub_metering_2\",\n",
        "        \"Sub_metering_3\",\n",
        "    ]\n",
        "    for col in num_cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "    df = df.set_index(\"timestamp\").sort_index()\n",
        "\n",
        "    # Resample to hourly frequency\n",
        "    hourly = pd.DataFrame()\n",
        "\n",
        "    if \"Global_active_power\" in df.columns:\n",
        "        hourly[\"global_active_power\"] = df[\"Global_active_power\"].resample(\"H\").mean()\n",
        "        # For 60-min average, mean kW over one hour approximates kWh\n",
        "        hourly[\"kwh\"] = hourly[\"global_active_power\"]\n",
        "\n",
        "    for col in [\"Sub_metering_1\", \"Sub_metering_2\", \"Sub_metering_3\"]:\n",
        "        if col in df.columns:\n",
        "            hourly[col] = df[col].resample(\"H\").sum()\n",
        "\n",
        "    hourly = hourly.dropna(subset=[\"kwh\"])\n",
        "    return hourly\n",
        "\n",
        "\n",
        "hourly = clean_household_power(raw)\n",
        "hourly.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Quick EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "hourly[\"kwh\"].plot(alpha=0.7)\n",
        "plt.title(\"Hourly energy consumption (kWh)\")\n",
        "plt.ylabel(\"kWh\")\n",
        "plt.show()\n",
        "\n",
        "sample_start = hourly.index.min() + pd.Timedelta(days=7)\n",
        "sample_end = sample_start + pd.Timedelta(days=7)\n",
        "sample = hourly.loc[sample_start:sample_end]\n",
        "sample[\"kwh\"].plot()\n",
        "plt.title(\"Sample week of hourly consumption\")\n",
        "plt.ylabel(\"kWh\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Daily profiles and features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def build_daily_profile_frame(hourly_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"Create daily features and 24h profiles from hourly kWh.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    daily_features : pd.DataFrame\n",
        "        One row per date with aggregate features and fractions.\n",
        "    daily_profiles : pd.DataFrame\n",
        "        One row per date, columns `h_00`..`h_23` with kWh at that hour.\n",
        "    \"\"\"\n",
        "    df = hourly_df.copy()\n",
        "    df[\"date\"] = df.index.date\n",
        "    df[\"hour\"] = df.index.hour\n",
        "\n",
        "    # 24h wide profile: rows=dates, cols=hours\n",
        "    profile = df.pivot_table(\n",
        "        index=\"date\",\n",
        "        columns=\"hour\",\n",
        "        values=\"kwh\",\n",
        "        aggfunc=\"mean\",\n",
        "    )\n",
        "    profile.columns = [f\"h_{h:02d}\" for h in profile.columns]\n",
        "\n",
        "    # Aggregate stats by date\n",
        "    daily = df.groupby(\"date\").agg(\n",
        "        total_kwh=(\"kwh\", \"sum\"),\n",
        "        max_kwh=(\"kwh\", \"max\"),\n",
        "        mean_kwh=(\"kwh\", \"mean\"),\n",
        "    )\n",
        "\n",
        "    # Day, night, evening kWh\n",
        "    def _fraction_sum(mask: pd.Series) -> pd.Series:\n",
        "        return df.loc[mask, :].groupby(\"date\")[\"kwh\"].sum()\n",
        "\n",
        "    day_mask = (df[\"hour\"] >= 8) & (df[\"hour\"] < 18)\n",
        "    night_mask = (df[\"hour\"] < 6) | (df[\"hour\"] >= 22)\n",
        "    evening_mask = (df[\"hour\"] >= 18) & (df[\"hour\"] < 23)\n",
        "\n",
        "    day_kwh = _fraction_sum(day_mask)\n",
        "    night_kwh = _fraction_sum(night_mask)\n",
        "    eve_kwh = _fraction_sum(evening_mask)\n",
        "\n",
        "    daily[\"day_kwh\"] = day_kwh\n",
        "    daily[\"night_kwh\"] = night_kwh\n",
        "    daily[\"evening_kwh\"] = eve_kwh\n",
        "\n",
        "    daily[\"day_frac\"] = daily[\"day_kwh\"] / daily[\"total_kwh\"]\n",
        "    daily[\"night_frac\"] = daily[\"night_kwh\"] / daily[\"total_kwh\"]\n",
        "    daily[\"evening_frac\"] = daily[\"evening_kwh\"] / daily[\"total_kwh\"]\n",
        "\n",
        "    features = daily.join(profile, how=\"inner\")\n",
        "    return features, profile\n",
        "\n",
        "\n",
        "daily_features, daily_profiles = build_daily_profile_frame(hourly)\n",
        "daily_features.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Daily totals and weekday patterns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "daily_features.index = pd.to_datetime(daily_features.index)\n",
        "daily_features[\"weekday\"] = daily_features.index.dayofweek\n",
        "\n",
        "daily_features[\"total_kwh\"].plot(alpha=0.7)\n",
        "plt.title(\"Total daily kWh over time\")\n",
        "plt.ylabel(\"kWh/day\")\n",
        "plt.show()\n",
        "\n",
        "sns.boxplot(data=daily_features, x=\"weekday\", y=\"total_kwh\")\n",
        "plt.title(\"Daily energy use by weekday (0=Mon)\")\n",
        "plt.ylabel(\"kWh/day\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Clustering daily patterns with KMeans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cluster_cols = [c for c in daily_features.columns if c not in [\"weekday\"]]\n",
        "X = daily_features[cluster_cols].fillna(0.0).to_numpy()\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "sil_scores: Dict[int, float] = {}\n",
        "for k in range(2, 8):\n",
        "    kmeans = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init=20)\n",
        "    labels = kmeans.fit_predict(X_scaled)\n",
        "    sil_scores[k] = silhouette_score(X_scaled, labels)\n",
        "\n",
        "sil_scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.plot(list(sil_scores.keys()), list(sil_scores.values()), marker=\"o\")\n",
        "plt.xlabel(\"K (number of clusters)\")\n",
        "plt.ylabel(\"Silhouette score\")\n",
        "plt.title(\"Silhouette vs K \u2013 daily energy patterns\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pick K based on silhouette and domain knowledge; we default to K=4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "K = 4\n",
        "\n",
        "kmeans_final = KMeans(n_clusters=K, random_state=RANDOM_STATE, n_init=50)\n",
        "cluster_labels = kmeans_final.fit_predict(X_scaled)\n",
        "\n",
        "daily_features[\"cluster\"] = cluster_labels\n",
        "daily_profiles_clustered = daily_profiles.copy()\n",
        "daily_profiles_clustered[\"cluster\"] = cluster_labels\n",
        "\n",
        "daily_features[[\"total_kwh\", \"day_frac\", \"night_frac\", \"evening_frac\", \"cluster\"]].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Cluster interpretation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cluster_counts = daily_features[\"cluster\"].value_counts().sort_index()\n",
        "cluster_counts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "agg_cols = [\"total_kwh\", \"day_frac\", \"night_frac\", \"evening_frac\", \"max_kwh\", \"mean_kwh\"]\n",
        "cluster_summary = daily_features.groupby(\"cluster\")[agg_cols].mean()\n",
        "cluster_summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "hour_cols = [c for c in daily_profiles.columns if c.startswith(\"h_\")]\n",
        "cluster_profiles = daily_profiles_clustered.groupby(\"cluster\")[hour_cols].mean()\n",
        "\n",
        "for cluster_id, row in cluster_profiles.iterrows():\n",
        "    plt.plot(range(24), row.values, label=f\"Cluster {cluster_id}\")\n",
        "\n",
        "plt.xticks(range(24))\n",
        "plt.xlabel(\"Hour of day\")\n",
        "plt.ylabel(\"Average kWh\")\n",
        "plt.title(\"Average daily load shape per cluster\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. PCA visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pca = PCA(n_components=2, random_state=RANDOM_STATE)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "pca_df = pd.DataFrame(X_pca, columns=[\"pc1\", \"pc2\"], index=daily_features.index)\n",
        "pca_df[\"cluster\"] = daily_features[\"cluster\"].values\n",
        "\n",
        "sns.scatterplot(data=pca_df, x=\"pc1\", y=\"pc2\", hue=\"cluster\", palette=\"tab10\", alpha=0.7)\n",
        "plt.title(\"Daily energy patterns \u2013 PCA projection\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Classifier to predict clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "clf_features = [\"total_kwh\", \"day_frac\", \"night_frac\", \"evening_frac\", \"weekday\"]\n",
        "X_clf = daily_features[clf_features].to_numpy()\n",
        "y_clf = daily_features[\"cluster\"].to_numpy()\n",
        "\n",
        "n_days = len(daily_features)\n",
        "split_idx = int(n_days * 0.8)\n",
        "\n",
        "X_clf_train, X_clf_test = X_clf[:split_idx], X_clf[split_idx:]\n",
        "y_clf_train, y_clf_test = y_clf[:split_idx], y_clf[split_idx:]\n",
        "\n",
        "rf_clf = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    random_state=RANDOM_STATE,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "rf_clf.fit(X_clf_train, y_clf_train)\n",
        "\n",
        "y_pred_clf = rf_clf.predict(X_clf_test)\n",
        "print(classification_report(y_clf_test, y_pred_clf))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_clf_test, y_pred_clf))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Export daily features with clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "export_path = Path(\"data\") / \"daily_profiles_with_clusters.csv\"\n",
        "export_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "daily_features.to_csv(export_path, index_label=\"date\")\n",
        "print(\"Exported daily features with cluster labels to:\", export_path.resolve())"
      ]
    }
  ]
}