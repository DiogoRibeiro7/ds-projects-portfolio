{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Bank Customer Churn \u2013 LightGBM, Optuna & SHAP\n\nThis notebook is part of the **Modern Bank Churn** project.\n\nGoal of this notebook:\n\n1. Reuse the bank churn dataset and preprocessing logic.\n2. Train a **LightGBM** model for churn prediction.\n3. Use **Optuna** to tune hyperparameters with cross-validation.\n4. Explain the tuned model with **SHAP** values.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1. Imports and configuration\n\nWe add to the usual stack:\n\n- `lightgbm` (`LGBMClassifier`) for gradient boosting.\n- `optuna` for hyperparameter optimisation.\n- `shap` for explainability."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "from __future__ import annotations\n\nfrom pathlib import Path\nfrom typing import Dict, List\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import roc_auc_score, accuracy_score, classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.base import BaseEstimator\n\nfrom lightgbm import LGBMClassifier\nimport optuna\nimport shap\n\nsns.set(style=\"whitegrid\")\nplt.rcParams[\"figure.figsize\"] = (8, 5)\n\nRANDOM_STATE: int = 42\nnp.random.seed(RANDOM_STATE)\n\nDATA_PATH: Path = Path(\"data\") / \"Churn_Modelling.csv\"\n\nif not DATA_PATH.exists():\n    raise FileNotFoundError(\n        f\"Data file not found at {DATA_PATH.resolve()}. \"\n        \"Please download the Bank Customer Churn CSV and place it under the 'data/' directory.\"\n    )\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2. Load and clean the data\n\nWe mirror the cleaning steps from the first notebook so this one is self-contained:\n\n- Drop identifier columns (`RowNumber`, `CustomerId`, `Surname`).\n- Ensure `Exited` is present.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def load_bank_churn_data(path: Path) -> pd.DataFrame:\n    \"\"\"Load the bank customer churn dataset from a CSV file.\"\"\"\n    if not path.exists():\n        raise FileNotFoundError(f\"File not found: {path!s}\")\n    df: pd.DataFrame = pd.read_csv(path)\n    if df.empty:\n        raise ValueError(f\"Loaded DataFrame is empty: {path!s}\")\n    return df\n\n\ndef clean_bank_churn_data(raw_df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Clean the bank customer churn dataset (drop IDs, check target).\"\"\"\n    df = raw_df.copy()\n\n    id_cols: List[str] = [\"RowNumber\", \"CustomerId\", \"Surname\"]\n    drop_cols: List[str] = [c for c in id_cols if c in df.columns]\n    if drop_cols:\n        df = df.drop(columns=drop_cols)\n        print(f\"Dropped identifier columns: {drop_cols}\")\n\n    if \"Exited\" not in df.columns:\n        raise ValueError(\"Target column 'Exited' not found in DataFrame.\")\n\n    return df\n\n\nraw_df: pd.DataFrame = load_bank_churn_data(DATA_PATH)\ndf: pd.DataFrame = clean_bank_churn_data(raw_df)\ndisplay(df.head())\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3. Train\u2013test split and preprocessing\n\nWe:\n\n- Separate `X` and `y`.\n- Perform a stratified train\u2013test split.\n- Use `ColumnTransformer` to one-hot encode `Geography` and `Gender`, while\n  leaving numeric features untouched.\n\nLightGBM handles raw numeric scales reasonably well, so scaling is optional,\nbut we keep a placeholder for flexibility.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "TARGET_COL: str = \"Exited\"\n\nif TARGET_COL not in df.columns:\n    raise KeyError(f\"Target column {TARGET_COL!r} not found in DataFrame.\")\n\nX: pd.DataFrame = df.drop(columns=[TARGET_COL])\ny: pd.Series = df[TARGET_COL].astype(int)\n\ncategorical_cols: List[str] = [c for c in [\"Geography\", \"Gender\"] if c in X.columns]\nnumeric_cols: List[str] = [c for c in X.columns if c not in categorical_cols]\n\nprint(\"Categorical columns:\", categorical_cols)\nprint(\"Numeric columns:\", numeric_cols)\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X,\n    y,\n    test_size=0.2,\n    stratify=y,\n    random_state=RANDOM_STATE,\n)\n\nprint(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n\nnumeric_transformer = Pipeline(\n    steps=[(\"scaler\", StandardScaler())]\n)\ncategorical_transformer = Pipeline(\n    steps=[(\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))]\n)\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num\", numeric_transformer, numeric_cols),\n        (\"cat\", categorical_transformer, categorical_cols),\n    ]\n)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4. Baseline LightGBM model\n\nWe start with a reasonable default `LGBMClassifier` inside a pipeline and\nevaluate it using a simple train/test split.\n\nThis gives us a reference point before hyperparameter tuning with Optuna.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def evaluate_model_simple(\n    model: BaseEstimator,\n    X_train: pd.DataFrame,\n    X_test: pd.DataFrame,\n    y_train: pd.Series,\n    y_test: pd.Series,\n) -> Dict[str, float]:\n    \"\"\"Fit a model and compute basic metrics on train and test data.\"\"\"\n    model.fit(X_train, y_train)\n\n    y_pred_test = model.predict(X_test)\n    y_proba_test = model.predict_proba(X_test)[:, 1]\n\n    acc = accuracy_score(y_test, y_pred_test)\n    roc_auc = roc_auc_score(y_test, y_proba_test)\n\n    print(f\"Test accuracy: {acc:.3f}\")\n    print(f\"Test ROC-AUC: {roc_auc:.3f}\")\n    print(\"\\nClassification report (test):\")\n    print(classification_report(y_test, y_pred_test, target_names=[\"Stayed\", \"Exited\"]))\n\n    cm = confusion_matrix(y_test, y_pred_test)\n    sns.heatmap(\n        cm,\n        annot=True,\n        fmt=\"d\",\n        cmap=\"Blues\",\n        xticklabels=[\"Pred stayed\", \"Pred exited\"],\n        yticklabels=[\"True stayed\", \"True exited\"],\n    )\n    plt.title(\"Confusion matrix - LightGBM (baseline)\")\n    plt.ylabel(\"True label\")\n    plt.xlabel(\"Predicted label\")\n    plt.show()\n\n    RocCurveDisplay.from_predictions(y_test, y_proba_test)\n    plt.title(\"ROC curve - LightGBM (baseline)\")\n    plt.show()\n\n    return {\"accuracy\": acc, \"roc_auc\": roc_auc}\n\n\nlgbm_baseline = Pipeline(\n    steps=[\n        (\"preprocess\", preprocessor),\n        (\n            \"clf\",\n            LGBMClassifier(\n                n_estimators=200,\n                learning_rate=0.05,\n                subsample=0.8,\n                colsample_bytree=0.8,\n                random_state=RANDOM_STATE,\n            ),\n        ),\n    ]\n)\n\nbaseline_metrics = evaluate_model_simple(lgbm_baseline, X_train, X_test, y_train, y_test)\nbaseline_metrics\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5. Hyperparameter tuning with Optuna\n\nWe now define an **Optuna** optimisation loop that:\n\n1. Samples LightGBM hyperparameters.\n2. Builds a pipeline with those hyperparameters.\n3. Evaluates mean ROC-AUC via cross-validation on the training set.\n4. Returns the negative loss (1 - ROC-AUC) or directly ROC-AUC as the objective.\n\nWe use:\n\n- `StratifiedKFold` for consistent splits.\n- A modest number of trials (e.g. 30\u201350) to keep runtime manageable.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def create_lgbm_pipeline(trial: optuna.Trial) -> Pipeline:\n    \"\"\"Create a LightGBM pipeline with hyperparameters suggested by Optuna.\"\"\"\n    # Hyperparameters suggested by Optuna\n    num_leaves = trial.suggest_int(\"num_leaves\", 16, 64)\n    max_depth = trial.suggest_int(\"max_depth\", 3, 10)\n    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.2, log=True)\n    n_estimators = trial.suggest_int(\"n_estimators\", 100, 500)\n    min_child_samples = trial.suggest_int(\"min_child_samples\", 10, 100)\n    subsample = trial.suggest_float(\"subsample\", 0.6, 1.0)\n    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.6, 1.0)\n    reg_lambda = trial.suggest_float(\"reg_lambda\", 0.0, 10.0)\n    reg_alpha = trial.suggest_float(\"reg_alpha\", 0.0, 10.0)\n\n    clf = LGBMClassifier(\n        num_leaves=num_leaves,\n        max_depth=max_depth,\n        learning_rate=learning_rate,\n        n_estimators=n_estimators,\n        min_child_samples=min_child_samples,\n        subsample=subsample,\n        colsample_bytree=colsample_bytree,\n        reg_lambda=reg_lambda,\n        reg_alpha=reg_alpha,\n        random_state=RANDOM_STATE,\n        n_jobs=-1,\n    )\n\n    pipeline = Pipeline(\n        steps=[\n            (\"preprocess\", preprocessor),\n            (\"clf\", clf),\n        ]\n    )\n    return pipeline\n\n\ndef objective(trial: optuna.Trial) -> float:\n    \"\"\"Optuna objective function: maximise ROC-AUC via cross-validation.\n\n    We return the mean ROC-AUC across folds.\n    \"\"\"\n    pipeline = create_lgbm_pipeline(trial)\n\n    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n\n    scores = cross_val_score(\n        pipeline,\n        X_train,\n        y_train,\n        cv=cv,\n        scoring=\"roc_auc\",\n        n_jobs=-1,\n    )\n    mean_score = float(scores.mean())\n    return mean_score\n\n\nstudy = optuna.create_study(direction=\"maximize\", study_name=\"lgbm_bank_churn\")\nstudy.optimize(objective, n_trials=30, show_progress_bar=False)\n\nprint(\"Best trial:\")\nprint(\"  Value (ROC-AUC):\", study.best_value)\nprint(\"  Params:\")\nfor k, v in study.best_params.items():\n    print(f\"    {k}: {v}\")\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 5.1 Fit the best LightGBM model\n\nWe now create a pipeline with the best parameters found by Optuna, fit it\non the full training data, and evaluate it on the test set.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "best_params = study.best_params\nbest_clf = LGBMClassifier(\n    num_leaves=best_params[\"num_leaves\"],\n    max_depth=best_params[\"max_depth\"],\n    learning_rate=best_params[\"learning_rate\"],\n    n_estimators=best_params[\"n_estimators\"],\n    min_child_samples=best_params[\"min_child_samples\"],\n    subsample=best_params[\"subsample\"],\n    colsample_bytree=best_params[\"colsample_bytree\"],\n    reg_lambda=best_params[\"reg_lambda\"],\n    reg_alpha=best_params[\"reg_alpha\"],\n    random_state=RANDOM_STATE,\n    n_jobs=-1,\n)\n\nbest_lgbm_pipeline = Pipeline(\n    steps=[\n        (\"preprocess\", preprocessor),\n        (\"clf\", best_clf),\n    ]\n)\n\ntuned_metrics = evaluate_model_simple(best_lgbm_pipeline, X_train, X_test, y_train, y_test)\ntuned_metrics\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6. Model explainability with SHAP\n\nWe use **SHAP** to understand how features influence the LightGBM predictions.\n\nSteps:\n\n1. Fit the best pipeline on the full training set (already done).\n2. Extract the trained `LGBMClassifier` and the transformed training data.\n3. Use `shap.TreeExplainer` to compute SHAP values.\n4. Plot:\n   - SHAP summary plot (global importance).\n   - SHAP dependence plots for key features.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Fit on full training data to ensure the explainer uses the final model\nbest_lgbm_pipeline.fit(X_train, y_train)\n\n# Extract trained model and transformed training features\npreprocessor_fitted: ColumnTransformer = best_lgbm_pipeline.named_steps[\"preprocess\"]  # type: ignore[assignment]\nclf_fitted: LGBMClassifier = best_lgbm_pipeline.named_steps[\"clf\"]  # type: ignore[assignment]\n\nX_train_transformed = preprocessor_fitted.transform(X_train)\n\n# Build SHAP explainer\nexplainer = shap.TreeExplainer(clf_fitted)\nshap_values = explainer.shap_values(X_train_transformed)\n\n# SHAP expects a dense matrix for plotting in many cases\nX_train_transformed_dense = X_train_transformed.toarray() if hasattr(X_train_transformed, \"toarray\") else X_train_transformed\n\n# Get feature names from preprocessor\ncat_encoder: OneHotEncoder = preprocessor_fitted.named_transformers_[\"cat\"].named_steps[\"encoder\"]  # type: ignore[index]\ncat_feature_names = cat_encoder.get_feature_names_out(categorical_cols)\n\nfeature_names: List[str] = numeric_cols + list(cat_feature_names)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# SHAP summary plot (global importance)\nshap.summary_plot(shap_values[1], X_train_transformed_dense, feature_names=feature_names)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Optional: dependence plot for selected key features\n# You can change feature names depending on importance and domain interest.\nfor feat in [\"Age\", \"Balance\", \"NumOfProducts\", \"IsActiveMember\"]:\n    if feat in feature_names:\n        shap.dependence_plot(feat, shap_values[1], X_train_transformed_dense, feature_names=feature_names)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Section summary\n\nIn this notebook we:\n\n- Built a **LightGBM** churn model.\n- Tuned its hyperparameters with **Optuna** using ROC-AUC as objective.\n- Achieved improved performance over the baseline model.\n- Used **SHAP** to interpret which features drive churn predictions.\n\nNext, in the segmentation notebook, we will use the tuned model to create\n**actionable customer segments** and link them to potential retention strategies.\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}