{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Bank Customer Churn \u2013 EDA and Baseline Models\n\nThis notebook is part of the **Modern Bank Churn** project.\n\nGoal of this notebook:\n\n1. Load and clean the **Bank Customer Churn** dataset (`Churn_Modelling.csv`).\n2. Perform **Exploratory Data Analysis (EDA)** to understand churn patterns.\n3. Build **baseline models** (dummy, logistic regression, random forest).\n4. Establish a reference performance for more advanced models (LightGBM, Optuna, SHAP)\n   in later notebooks.\n\nThe target variable is **`Exited`**:\n\n- `0` \u2013 customer stayed.\n- `1` \u2013 customer left (churn).\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1. Imports and configuration\n\nWe import:\n\n- `pandas`, `numpy` for data handling.\n- `matplotlib`, `seaborn` for visualization.\n- `scikit-learn` for preprocessing, modelling, and evaluation.\n\nWe also:\n\n- Set a random seed for reproducibility.\n- Define the expected path to the dataset.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "from __future__ import annotations\n\nfrom pathlib import Path\nfrom typing import Dict, List\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import (\n    accuracy_score,\n    classification_report,\n    confusion_matrix,\n    roc_auc_score,\n    RocCurveDisplay,\n)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.base import BaseEstimator\n\nsns.set(style=\"whitegrid\")\nplt.rcParams[\"figure.figsize\"] = (8, 5)\n\nRANDOM_STATE: int = 42\nnp.random.seed(RANDOM_STATE)\n\nDATA_PATH: Path = Path(\"data\") / \"Churn_Modelling.csv\"\n\nif not DATA_PATH.exists():\n    raise FileNotFoundError(\n        f\"Data file not found at {DATA_PATH.resolve()}. \"\n        \"Please download the Bank Customer Churn CSV and place it under the 'data/' directory.\"\n    )\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2. Load and inspect the data\n\nWe now:\n\n1. Load the CSV into a DataFrame.\n2. Inspect the head, info, and basic statistics.\n3. Verify that the target column `Exited` is present.\n\nThe raw dataset typically contains columns like:\n\n- `RowNumber`, `CustomerId`, `Surname` (identifiers, not useful for prediction).\n- `CreditScore`, `Geography`, `Gender`, `Age`, `Tenure`, `Balance`,\n  `NumOfProducts`, `HasCrCard`, `IsActiveMember`, `EstimatedSalary`.\n- `Exited` \u2013 target variable (0/1).\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def load_bank_churn_data(path: Path) -> pd.DataFrame:\n    \"\"\"Load the bank customer churn dataset from a CSV file.\n\n    Args:\n        path: Path to the CSV file.\n\n    Returns:\n        DataFrame containing the bank churn data.\n\n    Raises:\n        FileNotFoundError: If the file does not exist.\n        ValueError: If the loaded DataFrame is empty.\n    \"\"\"\n    if not path.exists():\n        raise FileNotFoundError(f\"File not found: {path!s}\")\n\n    df: pd.DataFrame = pd.read_csv(path)\n\n    if df.empty:\n        raise ValueError(f\"Loaded DataFrame is empty: {path!s}\")\n\n    return df\n\n\nraw_df: pd.DataFrame = load_bank_churn_data(DATA_PATH)\n\ndisplay(raw_df.head())\ndisplay(raw_df.info())\ndisplay(raw_df.describe(include=\"all\").T)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Section summary\n\nWe loaded the bank churn dataset and inspected its structure.\n\nNext we will clean it:\n\n- Remove purely identifier columns.\n- Confirm data types.\n- Look for missing values.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3. Data cleaning\n\nSteps:\n\n1. Drop identifier columns (`RowNumber`, `CustomerId`, `Surname`) which do not\n   carry predictive signal.\n2. Check and report missing values.\n3. Ensure the target `Exited` is present and binary (0/1).\n\nWe keep the cleaning simple and explicit so that it is easy to review and audit.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def clean_bank_churn_data(raw_df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Clean the bank customer churn dataset.\n\n    - Drop identifier columns.\n    - Check for missing values.\n    - Ensure `Exited` is present.\n\n    Args:\n        raw_df: Raw bank churn DataFrame.\n\n    Returns:\n        Cleaned DataFrame.\n    \"\"\"\n    df = raw_df.copy()\n\n    # Drop known identifier columns if present\n    id_cols: List[str] = [\"RowNumber\", \"CustomerId\", \"Surname\"]\n    drop_cols: List[str] = [c for c in id_cols if c in df.columns]\n\n    if drop_cols:\n        df = df.drop(columns=drop_cols)\n        print(f\"Dropped identifier columns: {drop_cols}\")\n    else:\n        print(\"No identifier columns to drop.\")\n\n    # Check missing values\n    missing = df.isna().sum()\n    print(\"Missing values per column (non-zero only):\")\n    display(missing[missing > 0])\n\n    # Basic target checks\n    if \"Exited\" not in df.columns:\n        raise ValueError(\"Target column 'Exited' not found in DataFrame.\")\n\n    unique_exited = df[\"Exited\"].unique()\n    print(f\"Unique values in 'Exited': {unique_exited}\")\n\n    return df\n\n\ndf: pd.DataFrame = clean_bank_churn_data(raw_df)\ndisplay(df.head())\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Section summary\n\nWe:\n\n- Dropped identifier columns.\n- Confirmed that `Exited` exists.\n- Checked missing values (usually none in this dataset).\n\nNow we explore churn patterns through EDA.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4. Exploratory Data Analysis (EDA)\n\nWe start with:\n\n1. **Churn rate and class balance** (distribution of `Exited`).\n2. **Numerical features vs churn** (e.g. `Age`, `Balance`, `CreditScore`).\n3. **Categorical features vs churn** (e.g. `Geography`, `Gender`, `IsActiveMember`).\n\nThe goal is to build intuition about what drives churn.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def plot_churn_distribution(df: pd.DataFrame, target_col: str = \"Exited\") -> None:\n    \"\"\"Plot the distribution of the churn target variable.\n\n    Args:\n        df: Clean bank churn DataFrame.\n        target_col: Name of the churn column.\n\n    Raises:\n        KeyError: If the target column is not in the DataFrame.\n    \"\"\"\n    if target_col not in df.columns:\n        raise KeyError(f\"Column {target_col!r} not found in DataFrame.\")\n\n    counts = df[target_col].value_counts().sort_index()\n    churn_rate = (counts.get(1, 0) / counts.sum()) * 100.0\n    print(f\"Churn rate (Exited=1): {churn_rate:.2f}%\")\n\n    ax = sns.countplot(data=df, x=target_col)\n    ax.set_title(\"Churn distribution (Exited)\")\n    ax.bar_label(ax.containers[0])\n    plt.show()\n\n\nplot_churn_distribution(df)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 4.1 Numerical features vs churn\n\nWe look at distributions of key numerical features split by churn status:\n\n- `Age`\n- `Balance`\n- `CreditScore`\n\nWe use kernel density plots to compare the shapes.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "numeric_to_inspect: List[str] = [\"Age\", \"Balance\", \"CreditScore\"]\n\nfor col in numeric_to_inspect:\n    if col not in df.columns:\n        raise KeyError(f\"Expected numeric column {col!r} not found in DataFrame.\")\n\nfig, axes = plt.subplots(1, len(numeric_to_inspect), figsize=(18, 4))\n\nfor ax, col in zip(axes, numeric_to_inspect):\n    sns.kdeplot(\n        data=df,\n        x=col,\n        hue=\"Exited\",\n        common_norm=False,\n        fill=True,\n        alpha=0.5,\n        ax=ax,\n    )\n    ax.set_title(f\"{col} distribution by churn\")\n\nplt.tight_layout()\nplt.show()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 4.2 Categorical features vs churn\n\nWe examine churn rates for selected categorical features:\n\n- `Geography`\n- `Gender`\n- `IsActiveMember`\n\nWe compute churn rate per category and visualise as bar charts.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def churn_rate_by_category(\n    df: pd.DataFrame,\n    category_col: str,\n    target_col: str = \"Exited\",\n) -> pd.DataFrame:\n    \"\"\"Compute churn rate for each category in a given column.\n\n    Args:\n        df: Clean bank churn DataFrame.\n        category_col: Name of the categorical column.\n        target_col: Target column, expected values 0/1.\n\n    Returns:\n        DataFrame with counts and churn rate per category.\n    \"\"\"\n    for col in (category_col, target_col):\n        if col not in df.columns:\n            raise KeyError(f\"Column {col!r} not found in DataFrame.\")\n\n    grouped = (\n        df.groupby(category_col)[target_col]\n        .value_counts()\n        .unstack(fill_value=0)\n        .rename(columns={0: \"Stayed\", 1: \"Exited\"})\n    )\n    grouped[\"Total\"] = grouped[\"Stayed\"] + grouped[\"Exited\"]\n    grouped[\"ChurnRate\"] = grouped[\"Exited\"] / grouped[\"Total\"]\n    return grouped.sort_values(\"ChurnRate\", ascending=False)\n\n\ncat_cols_to_inspect: List[str] = [\"Geography\", \"Gender\", \"IsActiveMember\"]\n\nfor col in cat_cols_to_inspect:\n    if col not in df.columns:\n        print(f\"Skipping {col!r} (not found).\")\n        continue\n\n    print(f\"\\n=== Churn rate by {col} ===\")\n    summary_df = churn_rate_by_category(df, col)\n    display(summary_df)\n\n    ax = sns.barplot(\n        data=summary_df.reset_index(),\n        x=col,\n        y=\"ChurnRate\",\n        order=summary_df.index,\n    )\n    ax.set_title(f\"Churn rate by {col}\")\n    ax.set_ylabel(\"Churn rate\")\n    ax.set_xlabel(col)\n    ax.set_ylim(0, 1)\n    ax.bar_label(ax.containers[0], fmt=\"%.2f\")\n    plt.xticks(rotation=30)\n    plt.tight_layout()\n    plt.show()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Section summary\n\nFrom EDA we usually observe patterns such as:\n\n- Certain **geographies** having higher churn.\n- Differences in churn by **activity status** (`IsActiveMember`).\n- Older customers or customers with certain balance ranges being more likely to churn.\n\nThese qualitative insights will be complemented by quantitative models next.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5. Train\u2013test split and preprocessing\n\nWe now prepare data for modelling:\n\n1. Separate **features (X)** and **target (y)**.\n2. Perform a train\u2013test split with stratification on `Exited`.\n3. Define a preprocessing pipeline:\n   - Standard scaling for numeric features.\n   - One-hot encoding for categorical features (`Geography`, `Gender`).\n\nWe use `ColumnTransformer` and `Pipeline` from scikit-learn to keep the process clean.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "TARGET_COL: str = \"Exited\"\n\nif TARGET_COL not in df.columns:\n    raise KeyError(f\"Target column {TARGET_COL!r} not found in DataFrame.\")\n\nX: pd.DataFrame = df.drop(columns=[TARGET_COL])\ny: pd.Series = df[TARGET_COL].astype(int)\n\ncategorical_cols: List[str] = [c for c in [\"Geography\", \"Gender\"] if c in X.columns]\nnumeric_cols: List[str] = [c for c in X.columns if c not in categorical_cols]\n\nprint(\"Categorical columns:\", categorical_cols)\nprint(\"Numeric columns:\", numeric_cols)\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X,\n    y,\n    test_size=0.2,\n    stratify=y,\n    random_state=RANDOM_STATE,\n)\n\nprint(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n\nnumeric_transformer = Pipeline(\n    steps=[(\"scaler\", StandardScaler())]\n)\ncategorical_transformer = Pipeline(\n    steps=[(\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))]\n)\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num\", numeric_transformer, numeric_cols),\n        (\"cat\", categorical_transformer, categorical_cols),\n    ]\n)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6. Baseline and classical models\n\nWe evaluate three models:\n\n1. **DummyClassifier** (most frequent class) \u2013 baseline.\n2. **Logistic Regression** \u2013 linear, interpretable model.\n3. **Random Forest** \u2013 non-linear ensemble for tabular data.\n\nWe define a helper function `evaluate_classifier` to:\n\n- Fit the model.\n- Compute accuracy and ROC-AUC.\n- Print a classification report.\n- Show a confusion matrix and ROC curve.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def evaluate_classifier(\n    name: str,\n    model: BaseEstimator,\n    X_train: pd.DataFrame,\n    X_test: pd.DataFrame,\n    y_train: pd.Series,\n    y_test: pd.Series,\n) -> Dict[str, float]:\n    \"\"\"Fit a classifier and evaluate it on train and test data.\n\n    Args:\n        name: Name of the model (for printing).\n        model: Unfitted scikit-learn estimator or pipeline.\n        X_train: Training features.\n        X_test: Test features.\n        y_train: Training labels (0/1).\n        y_test: Test labels (0/1).\n\n    Returns:\n        Dictionary with key metrics on the test set.\n    \"\"\"\n    print(f\"\\n===== {name} =====\")\n    model.fit(X_train, y_train)\n\n    y_pred_train = model.predict(X_train)\n    y_pred_test = model.predict(X_test)\n\n    if hasattr(model, \"predict_proba\"):\n        y_proba_test = model.predict_proba(X_test)[:, 1]\n        roc_auc = roc_auc_score(y_test, y_proba_test)\n    else:\n        y_proba_test = None\n        roc_auc = np.nan\n\n    acc_train = accuracy_score(y_train, y_pred_train)\n    acc_test = accuracy_score(y_test, y_pred_test)\n\n    print(f\"Train accuracy: {acc_train:.3f}\")\n    print(f\"Test accuracy:  {acc_test:.3f}\")\n    if not np.isnan(roc_auc):\n        print(f\"Test ROC-AUC:  {roc_auc:.3f}\")\n\n    print(\"\\nClassification report (test):\")\n    print(classification_report(y_test, y_pred_test, target_names=[\"Stayed\", \"Exited\"]))\n\n    cm = confusion_matrix(y_test, y_pred_test)\n    sns.heatmap(\n        cm,\n        annot=True,\n        fmt=\"d\",\n        cmap=\"Blues\",\n        xticklabels=[\"Pred stayed\", \"Pred exited\"],\n        yticklabels=[\"True stayed\", \"True exited\"],\n    )\n    plt.title(f\"Confusion matrix - {name}\")\n    plt.ylabel(\"True label\")\n    plt.xlabel(\"Predicted label\")\n    plt.show()\n\n    if y_proba_test is not None:\n        RocCurveDisplay.from_predictions(y_test, y_proba_test)\n        plt.title(f\"ROC curve - {name}\")\n        plt.show()\n\n    return {\n        \"model\": name,\n        \"train_accuracy\": acc_train,\n        \"test_accuracy\": acc_test,\n        \"roc_auc\": float(roc_auc) if not np.isnan(roc_auc) else np.nan,\n    }\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# 6.1 Dummy baseline\ndummy_clf = Pipeline(\n    steps=[\n        (\"preprocess\", preprocessor),\n        (\"clf\", DummyClassifier(strategy=\"most_frequent\", random_state=RANDOM_STATE)),\n    ]\n)\n\ndummy_metrics = evaluate_classifier(\n    \"Dummy (Most Frequent)\", dummy_clf, X_train, X_test, y_train, y_test\n)\ndummy_metrics\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# 6.2 Logistic Regression\nlog_reg_clf = Pipeline(\n    steps=[\n        (\"preprocess\", preprocessor),\n        (\n            \"clf\",\n            LogisticRegression(\n                max_iter=1000,\n                random_state=RANDOM_STATE,\n                n_jobs=-1,\n            ),\n        ),\n    ]\n)\n\nlog_reg_metrics = evaluate_classifier(\n    \"Logistic Regression\", log_reg_clf, X_train, X_test, y_train, y_test\n)\nlog_reg_metrics\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# 6.3 Random Forest\nrf_clf = Pipeline(\n    steps=[\n        (\"preprocess\", preprocessor),\n        (\n            \"clf\",\n            RandomForestClassifier(\n                n_estimators=200,\n                max_depth=None,\n                min_samples_split=4,\n                min_samples_leaf=2,\n                random_state=RANDOM_STATE,\n                n_jobs=-1,\n            ),\n        ),\n    ]\n)\n\nrf_metrics = evaluate_classifier(\n    \"Random Forest\", rf_clf, X_train, X_test, y_train, y_test\n)\nrf_metrics\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 7. Model comparison and conclusions\n\nWe summarise the performance of all three models to establish a reference.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "results_df = pd.DataFrame([dummy_metrics, log_reg_metrics, rf_metrics])\ndisplay(results_df)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Section summary\n\nIn this notebook we:\n\n- Explored the bank churn dataset.\n- Built three baseline models:\n  - A dummy classifier (most frequent class).\n  - Logistic Regression.\n  - Random Forest.\n- Compared their performance using accuracy and ROC-AUC.\n\nThese baselines give us a **benchmark**. In the next notebook we will use\n**LightGBM + Optuna + SHAP** to build a stronger and more explainable churn model.\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}