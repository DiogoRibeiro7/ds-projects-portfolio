{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0b8310c",
   "metadata": {},
   "source": [
    "\n",
    "# Meta-analysis of Experiments: Portfolio View\n",
    "\n",
    "This notebook treats a **set of experiments** as a *portfolio* and shows how to\n",
    "combine their results using **meta-analysis**.\n",
    "\n",
    "Instead of looking at a single A/B test in isolation, we ask:\n",
    "\n",
    "- What is the **typical effect size** across many experiments?\n",
    "- How much **heterogeneity** is there between experiments?\n",
    "- How are our conclusions biased if we only look at **statistically significant** wins?\n",
    "- How can we build **partial-pooling / Bayesian-style shrinkage** for experiment effects?\n",
    "\n",
    "We will:\n",
    "\n",
    "1. Simulate a portfolio of experiments on the same metric.  \n",
    "2. Compute per-experiment effects and p-values.  \n",
    "3. Perform **fixed-effect** and **random-effects (DerSimonian–Laird)** meta-analysis.  \n",
    "4. Visualize a **forest plot** of experiment estimates and the pooled effect.  \n",
    "5. Show **publication bias** by only looking at significant experiments.  \n",
    "6. Build a simple **Bayesian-style shrinkage** for experiment effects (partial pooling).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2aeda5",
   "metadata": {},
   "source": [
    "## 0) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ede1dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 4.5)\n",
    "plt.rcParams[\"axes.grid\"] = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d644c4d",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Simulating a portfolio of experiments\n",
    "\n",
    "We simulate a set of experiments that:\n",
    "\n",
    "- All target the **same metric** (e.g., conversion rate).  \n",
    "- Share a **global average treatment effect** \\(\\mu\\).  \n",
    "- Have **between-experiment heterogeneity** \\(\\tau\\) (some experiments do better, some worse).  \n",
    "- Have varying sample sizes and noise.\n",
    "\n",
    "Model (log-odds formulation):\n",
    "\n",
    "- Baseline control conversion: \\(p_C\\).  \n",
    "- For experiment \\(i\\), draw a *true* log-odds treatment effect \\(\\theta_i \\sim \\mathcal{N}(\\mu, \\tau^2)\\).  \n",
    "- Treatment conversion probability:\n",
    "\n",
    "\\[\n",
    "\\text{logit}(p_{T,i}) = \\text{logit}(p_C) + \\theta_i.\n",
    "\\]\n",
    "\n",
    "We then run a standard two-proportion experiment and estimate the **difference in conversion rates**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ed0e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class PortfolioSimConfig:\n",
    "    n_experiments: int = 50\n",
    "    mean_logodds_effect: float = 0.05\n",
    "    tau_logodds: float = 0.15\n",
    "    baseline_rate: float = 0.10\n",
    "    mean_n_per_group: int = 5000\n",
    "    n_sd_per_group: int = 1000\n",
    "    seed: int | None = 1234\n",
    "\n",
    "\n",
    "def _logit(p: float) -> float:\n",
    "    if p <= 0.0 or p >= 1.0:\n",
    "        raise ValueError(\"p must be in (0,1) for logit.\")\n",
    "    return math.log(p / (1.0 - p))\n",
    "\n",
    "\n",
    "def _inv_logit(z: float) -> float:\n",
    "    return 1.0 / (1.0 + math.exp(-z))\n",
    "\n",
    "\n",
    "def simulate_experiment_portfolio(config: PortfolioSimConfig) -> pd.DataFrame:\n",
    "    rng = np.random.default_rng(config.seed)\n",
    "\n",
    "    theta_true = rng.normal(\n",
    "        loc=config.mean_logodds_effect,\n",
    "        scale=config.tau_logodds,\n",
    "        size=config.n_experiments,\n",
    "    )\n",
    "\n",
    "    logit_p_c = _logit(config.baseline_rate)\n",
    "\n",
    "    records: list[Dict[str, Any]] = []\n",
    "\n",
    "    for i in range(config.n_experiments):\n",
    "        n_c = int(max(100, rng.normal(config.mean_n_per_group, config.n_sd_per_group)))\n",
    "        n_t = int(max(100, rng.normal(config.mean_n_per_group, config.n_sd_per_group)))\n",
    "\n",
    "        theta_i = float(theta_true[i])\n",
    "        p_c = config.baseline_rate\n",
    "        p_t = _inv_logit(logit_p_c + theta_i)\n",
    "\n",
    "        conv_c = int(rng.binomial(n_c, p_c))\n",
    "        conv_t = int(rng.binomial(n_t, p_t))\n",
    "\n",
    "        rate_c = conv_c / n_c\n",
    "        rate_t = conv_t / n_t\n",
    "        effect_hat = rate_t - rate_c\n",
    "\n",
    "        se_hat = math.sqrt(\n",
    "            rate_c * (1.0 - rate_c) / n_c + rate_t * (1.0 - rate_t) / n_t\n",
    "        )\n",
    "\n",
    "        z_stat = effect_hat / se_hat if se_hat > 0 else float(\"nan\")\n",
    "        cdf = 0.5 * (1.0 + math.erf(z_stat / math.sqrt(2.0)))\n",
    "        p_value = 2.0 * min(cdf, 1.0 - cdf)\n",
    "\n",
    "        records.append(\n",
    "            {\n",
    "                \"exp_id\": i,\n",
    "                \"n_control\": n_c,\n",
    "                \"n_treatment\": n_t,\n",
    "                \"conv_control\": conv_c,\n",
    "                \"conv_treatment\": conv_t,\n",
    "                \"rate_control\": rate_c,\n",
    "                \"rate_treatment\": rate_t,\n",
    "                \"effect_hat\": effect_hat,\n",
    "                \"se_hat\": se_hat,\n",
    "                \"z_stat\": z_stat,\n",
    "                \"p_value\": p_value,\n",
    "                \"true_logodds_effect\": theta_i,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame.from_records(records)\n",
    "\n",
    "\n",
    "sim_config = PortfolioSimConfig()\n",
    "df_portfolio = simulate_experiment_portfolio(sim_config)\n",
    "df_portfolio.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa99f5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_portfolio[[\"effect_hat\", \"se_hat\", \"p_value\"]].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5926246b",
   "metadata": {},
   "source": [
    "\n",
    "We now have a simulated **portfolio of experiments** with true heterogeneous effects,\n",
    "observed effect estimates, standard errors and p-values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825fb47a",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Exploring the portfolio\n",
    "\n",
    "We can look at:\n",
    "\n",
    "- The distribution of estimated effects.  \n",
    "- How often we see **significant** experiments at a given level (e.g., 5%).  \n",
    "- How much **winner's curse** we get if we only look at significant winners.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51c7e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alpha = 0.05\n",
    "sig_mask = df_portfolio[\"p_value\"] < alpha\n",
    "\n",
    "print(\"Total experiments:\", len(df_portfolio))\n",
    "print(\"Significant at 5%:\", sig_mask.sum())\n",
    "print(\"Share significant:\", sig_mask.mean())\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axes[0].hist(df_portfolio[\"effect_hat\"], bins=20)\n",
    "axes[0].set_title(\"All experiments: effect_hat\")\n",
    "axes[0].set_xlabel(\"effect_hat (p_T - p_C)\")\n",
    "axes[0].set_ylabel(\"count\")\n",
    "\n",
    "axes[1].hist(df_portfolio.loc[sig_mask, \"effect_hat\"], bins=20)\n",
    "axes[1].set_title(\"Significant experiments only\")\n",
    "axes[1].set_xlabel(\"effect_hat (p_T - p_C)\")\n",
    "axes[1].set_ylabel(\"count\")\n",
    "\n",
    "fig.suptitle(\"Distribution of observed effects (winner's curse demo)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f48256",
   "metadata": {},
   "source": [
    "\n",
    "The right-hand histogram typically shows **inflated effect sizes** because we only look\n",
    "at experiments that happened to be significant (winner's curse / publication bias).\n",
    "\n",
    "Meta-analysis helps to recover a more realistic **typical effect size** across the whole\n",
    "portfolio, including small and non-significant experiments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971eaba4",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Fixed-effect meta-analysis\n",
    "\n",
    "The **fixed-effect** model assumes that all experiments share the *same* true effect\n",
    "\\(\\theta\\), and any differences we see are due only to sampling noise.\n",
    "\n",
    "For experiment \\(i\\) with estimate \\(\\hat\\theta_i\\) and standard error \\(s_i\\):\n",
    "\n",
    "- Weight: \\(w_i = 1 / s_i^2\\).  \n",
    "- Pooled estimate:\n",
    "\n",
    "\\[\n",
    "\\hat\\theta_{FE} = \\frac{\\sum_i w_i \\hat\\theta_i}{\\sum_i w_i}.\n",
    "\\]\n",
    "\n",
    "- Standard error: \\(s_{FE} = 1 / \\sqrt{\\sum_i w_i}\\).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42da1ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class MetaAnalysisResult:\n",
    "    model: str\n",
    "    theta_hat: float\n",
    "    se: float\n",
    "    ci_low: float\n",
    "    ci_high: float\n",
    "    tau2: float | None = None\n",
    "\n",
    "\n",
    "def meta_fixed_effect(effect_hat: np.ndarray, se_hat: np.ndarray) -> MetaAnalysisResult:\n",
    "    effect_hat = np.asarray(effect_hat, dtype=float)\n",
    "    se_hat = np.asarray(se_hat, dtype=float)\n",
    "\n",
    "    var_hat = se_hat ** 2\n",
    "    w = 1.0 / var_hat\n",
    "\n",
    "    w_sum = float(np.sum(w))\n",
    "    theta_hat = float(np.sum(w * effect_hat) / w_sum)\n",
    "    se = 1.0 / math.sqrt(w_sum)\n",
    "\n",
    "    z = 1.96\n",
    "    ci_low = theta_hat - z * se\n",
    "    ci_high = theta_hat + z * se\n",
    "\n",
    "    return MetaAnalysisResult(\n",
    "        model=\"fixed_effect\",\n",
    "        theta_hat=theta_hat,\n",
    "        se=se,\n",
    "        ci_low=ci_low,\n",
    "        ci_high=ci_high,\n",
    "        tau2=None,\n",
    "    )\n",
    "\n",
    "\n",
    "fe_res = meta_fixed_effect(\n",
    "    df_portfolio[\"effect_hat\"].to_numpy(),\n",
    "    df_portfolio[\"se_hat\"].to_numpy(),\n",
    ")\n",
    "fe_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07abf586",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Random-effects meta-analysis (DerSimonian–Laird)\n",
    "\n",
    "The **random-effects** model assumes that each experiment has its own true effect\n",
    "\\(\\theta_i\\), drawn from a distribution:\n",
    "\n",
    "\\[\n",
    "\\theta_i \\sim \\mathcal{N}(\\mu, \\tau^2),\n",
    "\\]\n",
    "\n",
    "where:\n",
    "\n",
    "- \\(\\mu\\) is the **overall mean effect** across experiments.  \n",
    "- \\(\\tau^2\\) is the **between-experiment variance** (heterogeneity).\n",
    "\n",
    "We observe noisy estimates \\(\\hat\\theta_i \\sim \\mathcal{N}(\\theta_i, s_i^2)\\).\n",
    "\n",
    "The DerSimonian–Laird (DL) method estimates \\(\\tau^2\\) using the **Q-statistic** and then\n",
    "computes a weighted average with **augmented variances** \\(s_i^2 + \\tau^2\\).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8cb17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def meta_random_effects_dl(\n",
    "    effect_hat: np.ndarray,\n",
    "    se_hat: np.ndarray,\n",
    ") -> MetaAnalysisResult:\n",
    "    effect_hat = np.asarray(effect_hat, dtype=float)\n",
    "    se_hat = np.asarray(se_hat, dtype=float)\n",
    "\n",
    "    var_hat = se_hat ** 2\n",
    "    w_fe = 1.0 / var_hat\n",
    "    w_fe_sum = float(np.sum(w_fe))\n",
    "    theta_fe = float(np.sum(w_fe * effect_hat) / w_fe_sum)\n",
    "\n",
    "    Q = float(np.sum(w_fe * (effect_hat - theta_fe) ** 2))\n",
    "    df = effect_hat.size - 1\n",
    "    c = w_fe_sum - np.sum(w_fe ** 2) / w_fe_sum\n",
    "    tau2 = max(0.0, (Q - df) / c) if c > 0 else 0.0\n",
    "\n",
    "    w_re = 1.0 / (var_hat + tau2)\n",
    "    w_re_sum = float(np.sum(w_re))\n",
    "    theta_re = float(np.sum(w_re * effect_hat) / w_re_sum)\n",
    "    se_re = 1.0 / math.sqrt(w_re_sum)\n",
    "\n",
    "    z = 1.96\n",
    "    ci_low = theta_re - z * se_re\n",
    "    ci_high = theta_re + z * se_re\n",
    "\n",
    "    return MetaAnalysisResult(\n",
    "        model=\"random_effects_DL\",\n",
    "        theta_hat=theta_re,\n",
    "        se=se_re,\n",
    "        ci_low=ci_low,\n",
    "        ci_high=ci_high,\n",
    "        tau2=tau2,\n",
    "    )\n",
    "\n",
    "\n",
    "re_res = meta_random_effects_dl(\n",
    "    df_portfolio[\"effect_hat\"].to_numpy(),\n",
    "    df_portfolio[\"se_hat\"].to_numpy(),\n",
    ")\n",
    "re_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f790de",
   "metadata": {},
   "source": [
    "\n",
    "The random-effects model accounts for **between-experiment heterogeneity**. The estimated\n",
    "\\(\\tau^2\\) gives a sense of how much the true effects differ across experiments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40041846",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Forest plot of experiment estimates and pooled effect\n",
    "\n",
    "A **forest plot** shows:\n",
    "\n",
    "- Each experiment's point estimate and confidence interval.  \n",
    "- The fixed-effect and/or random-effects pooled estimate at the bottom.\n",
    "\n",
    "This makes heterogeneity very visible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfdad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_forest(\n",
    "    df: pd.DataFrame,\n",
    "    fe_res: MetaAnalysisResult,\n",
    "    re_res: MetaAnalysisResult,\n",
    "    max_experiments: int = 30,\n",
    ") -> None:\n",
    "    df_plot = df.sort_values(\"effect_hat\").head(max_experiments).copy()\n",
    "    k = len(df_plot)\n",
    "\n",
    "    y_positions = np.arange(k)\n",
    "\n",
    "    effects = df_plot[\"effect_hat\"].to_numpy()\n",
    "    ses = df_plot[\"se_hat\"].to_numpy()\n",
    "    ci_low = effects - 1.96 * ses\n",
    "    ci_high = effects + 1.96 * ses\n",
    "\n",
    "    plt.figure(figsize=(8, 0.3 * k + 3))\n",
    "\n",
    "    for y, lo, hi in zip(y_positions, ci_low, ci_high):\n",
    "        plt.hlines(y, lo, hi)\n",
    "    plt.plot(effects, y_positions, \"o\")\n",
    "\n",
    "    plt.axvline(0.0, linestyle=\"--\", linewidth=1)\n",
    "    plt.axvline(fe_res.theta_hat, linestyle=\"-\", linewidth=1.5)\n",
    "    plt.axvline(re_res.theta_hat, linestyle=\":\", linewidth=1.5)\n",
    "\n",
    "    plt.yticks(y_positions, df_plot[\"exp_id\"])\n",
    "    plt.xlabel(\"Effect (p_T - p_C)\")\n",
    "    plt.ylabel(\"Experiment id (subset)\")\n",
    "    plt.title(\"Forest plot of experiment effects (subset)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_forest(df_portfolio, fe_res, re_res, max_experiments=25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f70763",
   "metadata": {},
   "source": [
    "\n",
    "The vertical dashed line at 0 represents **no effect**.\n",
    "\n",
    "The two vertical lines represent the **fixed-effect** and **random-effects**\n",
    "pooled estimates. Experiments scattered widely around them indicate substantial\n",
    "heterogeneity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3313c5a8",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Bayesian-style shrinkage for experiment effects (partial pooling)\n",
    "\n",
    "We can reuse the random-effects idea in a **Bayesian / partial pooling** view.\n",
    "\n",
    "Assume:\n",
    "\n",
    "- \\(\\hat\\theta_i \\sim \\mathcal{N}(\\theta_i, s_i^2)\\) (approximate normal estimator).  \n",
    "- \\(\\theta_i \\sim \\mathcal{N}(\\mu, \\tau^2)\\), where \\(\\mu\\) and \\(\\tau^2\\) come from\n",
    "  the random-effects meta-analysis (as an empirical Bayes step).\n",
    "\n",
    "Conditionally on \\(\\mu\\) and \\(\\tau^2\\), the posterior for each \\(\\theta_i\\) is Normal:\n",
    "\n",
    "\\[\n",
    "\\theta_i \\mid \\hat\\theta_i \\sim \\mathcal{N}(m_i, v_i)\n",
    "\\]\n",
    "\n",
    "with\n",
    "\n",
    "\\[\n",
    "v_i = \\left(\\frac{1}{s_i^2} + \\frac{1}{\\tau^2}\\right)^{-1}, \\quad\n",
    "m_i = v_i \\left(\\frac{\\hat\\theta_i}{s_i^2} + \\frac{\\mu}{\\tau^2}\\right).\n",
    "\\]\n",
    "\n",
    "This produces **shrunken per-experiment effects** that:\n",
    "\n",
    "- Move noisy experiments closer to the global mean.  \n",
    "- Leave well-measured experiments closer to their raw estimates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df13a355",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class ShrinkageResult:\n",
    "    df: pd.DataFrame\n",
    "    mu: float\n",
    "    tau2: float\n",
    "\n",
    "\n",
    "def shrink_experiment_effects(\n",
    "    df: pd.DataFrame,\n",
    "    re_res: MetaAnalysisResult,\n",
    ") -> ShrinkageResult:\n",
    "    if re_res.tau2 is None or re_res.tau2 <= 0.0:\n",
    "        df2 = df.copy()\n",
    "        df2[\"effect_shrunken\"] = df2[\"effect_hat\"]\n",
    "        df2[\"effect_sd_post\"] = df2[\"se_hat\"]\n",
    "        return ShrinkageResult(df=df2, mu=re_res.theta_hat, tau2=0.0)\n",
    "\n",
    "    tau2 = float(re_res.tau2)\n",
    "    mu = float(re_res.theta_hat)\n",
    "\n",
    "    effects = df[\"effect_hat\"].to_numpy()\n",
    "    ses = df[\"se_hat\"].to_numpy()\n",
    "    var = ses ** 2\n",
    "\n",
    "    v_i = 1.0 / (1.0 / var + 1.0 / tau2)\n",
    "    m_i = v_i * (effects / var + mu / tau2)\n",
    "\n",
    "    df2 = df.copy()\n",
    "    df2[\"effect_shrunken\"] = m_i\n",
    "    df2[\"effect_sd_post\"] = np.sqrt(v_i)\n",
    "\n",
    "    return ShrinkageResult(df=df2, mu=mu, tau2=tau2)\n",
    "\n",
    "\n",
    "shrink_res = shrink_experiment_effects(df_portfolio, re_res)\n",
    "shrink_res.df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add17b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_s = shrink_res.df.sort_values(\"effect_hat\").reset_index(drop=True)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(df_s[\"effect_hat\"], df_s[\"effect_shrunken\"])\n",
    "plt.axhline(shrink_res.mu, linestyle=\"--\", linewidth=1)\n",
    "plt.axvline(shrink_res.mu, linestyle=\"--\", linewidth=1)\n",
    "plt.xlabel(\"Raw effect_hat\")\n",
    "plt.ylabel(\"Shrunken effect\")\n",
    "plt.title(\"Partial pooling: raw vs shrunken experiment effects\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad1fa6b",
   "metadata": {},
   "source": [
    "\n",
    "In the scatter plot:\n",
    "\n",
    "- Points near the diagonal are experiments with **little shrinkage** (large sample sizes).  \n",
    "- Points pulled towards the intersection of the dashed lines are **noisier experiments**\n",
    "  that get pulled towards the global mean.\n",
    "\n",
    "This is a simple empirical Bayes view of **partial pooling** for experiment effects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07afd7a7",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Using meta-analysis to set priors and expectations\n",
    "\n",
    "From the random-effects model we get two key quantities:\n",
    "\n",
    "- \\(\\mu\\): typical effect size across experiments.  \n",
    "- \\(\\tau\\): between-experiment standard deviation.\n",
    "\n",
    "This can be used to set **realistic priors** for new experiments:\n",
    "\n",
    "- Before starting a new test, treat its unknown true effect \\(\\theta_{\\text{new}}\\) as:\n",
    "\n",
    "\\[\n",
    "\\theta_{\\text{new}} \\sim \\mathcal{N}(\\mu, \\tau^2)\n",
    "\\]\n",
    "\n",
    "- This prior can then be used in Bayesian analyses of the new experiment, or simply\n",
    "  as a sanity check when someone expects a huge uplift.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb97ad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mu = shrink_res.mu\n",
    "tau = math.sqrt(max(0.0, shrink_res.tau2))\n",
    "\n",
    "print(\"Meta-level mean effect (mu):\", mu)\n",
    "print(\"Meta-level between-experiment sd (tau):\", tau)\n",
    "\n",
    "if tau > 0:\n",
    "    z = (0.0 - mu) / tau\n",
    "    cdf = 0.5 * (1.0 + math.erf(z / math.sqrt(2.0)))\n",
    "    prob_positive = 1.0 - cdf\n",
    "else:\n",
    "    prob_positive = 1.0 if mu > 0 else 0.0\n",
    "\n",
    "print(\"P(theta_new > 0) under meta prior:\", prob_positive)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e8c79d",
   "metadata": {},
   "source": [
    "\n",
    "You can expose these meta-level summaries to product / growth teams as:\n",
    "\n",
    "- A **prior belief** about likely effect sizes.  \n",
    "- A way to calibrate expectations: *\"Most experiments are in the X–Y% range.\"*  \n",
    "- Input into **power and MDE calculations** for future experiments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9309c365",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Significance-filtered vs full meta-analysis\n",
    "\n",
    "A common failure mode in real experimentation programs is to only pay attention to\n",
    "**“successful”** experiments (e.g., p-value < 0.05).\n",
    "\n",
    "Here we compare:\n",
    "\n",
    "- Meta-analysis using **all experiments** (full portfolio).  \n",
    "- Meta-analysis using only **statistically significant** experiments.\n",
    "\n",
    "We expect the significance-filtered meta-analysis to be **biased upwards** because it\n",
    "ignores all the noisy near-zero / negative experiments that did not pass the threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c905cc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alpha_sig = 0.05\n",
    "mask_sig = df_portfolio[\"p_value\"] < alpha_sig\n",
    "\n",
    "full_fe = meta_fixed_effect(\n",
    "    df_portfolio[\"effect_hat\"].to_numpy(),\n",
    "    df_portfolio[\"se_hat\"].to_numpy(),\n",
    ")\n",
    "full_re = meta_random_effects_dl(\n",
    "    df_portfolio[\"effect_hat\"].to_numpy(),\n",
    "    df_portfolio[\"se_hat\"].to_numpy(),\n",
    ")\n",
    "\n",
    "df_sig = df_portfolio.loc[mask_sig].copy()\n",
    "\n",
    "if len(df_sig) > 0:\n",
    "    sig_fe = meta_fixed_effect(\n",
    "        df_sig[\"effect_hat\"].to_numpy(),\n",
    "        df_sig[\"se_hat\"].to_numpy(),\n",
    "    )\n",
    "    sig_re = meta_random_effects_dl(\n",
    "        df_sig[\"effect_hat\"].to_numpy(),\n",
    "        df_sig[\"se_hat\"].to_numpy(),\n",
    "    )\n",
    "else:\n",
    "    sig_fe = None\n",
    "    sig_re = None\n",
    "\n",
    "print(\"Number of experiments (full):\", len(df_portfolio))\n",
    "print(\"Number of significant experiments:\", len(df_sig))\n",
    "print(\"---\")\n",
    "print(\"Full fixed-effect:\", full_fe)\n",
    "print(\"Full random-effects:\", full_re)\n",
    "print(\"---\")\n",
    "print(\"Significant-only fixed-effect:\", sig_fe)\n",
    "print(\"Significant-only random-effects:\", sig_re)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36ba292",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Quick visual comparison of pooled estimates (full vs significant-only)\n",
    "\n",
    "labels = []\n",
    "means = []\n",
    "errors = []\n",
    "\n",
    "labels.append(\"Full FE\")\n",
    "means.append(full_fe.theta_hat)\n",
    "errors.append(1.96 * full_fe.se)\n",
    "\n",
    "labels.append(\"Full RE\")\n",
    "means.append(full_re.theta_hat)\n",
    "errors.append(1.96 * full_re.se)\n",
    "\n",
    "if sig_fe is not None and sig_re is not None:\n",
    "    labels.append(\"Sig-only FE\")\n",
    "    means.append(sig_fe.theta_hat)\n",
    "    errors.append(1.96 * sig_fe.se)\n",
    "\n",
    "    labels.append(\"Sig-only RE\")\n",
    "    means.append(sig_re.theta_hat)\n",
    "    errors.append(1.96 * sig_re.se)\n",
    "\n",
    "x = range(len(labels))\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.errorbar(x, means, yerr=errors, fmt=\"o\")\n",
    "plt.axhline(0.0, linestyle=\"--\", linewidth=1)\n",
    "plt.xticks(list(x), labels)\n",
    "plt.ylabel(\"Pooled effect (p_T - p_C)\")\n",
    "plt.title(\"Pooled estimates: full portfolio vs significance-filtered\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c097da34",
   "metadata": {},
   "source": [
    "\n",
    "In general you should meta-analyze **all experiments**, not just “winners”.\n",
    "\n",
    "Filtering on significance before combining results tends to **inflate** the pooled\n",
    "estimate and gives an over-optimistic view of what experiments usually deliver.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff3fdc8",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Bayesian hierarchical meta-analysis (simple version)\n",
    "\n",
    "We now add a lightweight **Bayesian hierarchical view** on top of the random-effects\n",
    "model.\n",
    "\n",
    "Assume:\n",
    "\n",
    "- Observed per-experiment estimates: \\(y_i = \\hat\\theta_i\\).  \n",
    "- Observation model: \\(y_i \\sim \\mathcal{N}(\\mu, \\tau^2 + s_i^2)\\), where\n",
    "  \\(s_i\\) is the standard error from the individual experiment and \\(\\tau^2\\) is the\n",
    "  between-experiment variance (heterogeneity).  \n",
    "- Prior for the meta-mean: \\(\\mu \\sim \\mathcal{N}(m_0, s_0^2)\\).\n",
    "\n",
    "Conditionally on \\(\\tau^2\\), the posterior for \\(\\mu\\) is still Normal and has\n",
    "closed form:\n",
    "\n",
    "\\[\n",
    "v_{\\mu} = \\left( \\frac{1}{s_0^2} + \\sum_i \\frac{1}{\\tau^2 + s_i^2} \\right)^{-1}, \\quad\n",
    "m_{\\mu} = v_{\\mu} \\left( \\frac{m_0}{s_0^2} + \\sum_i \\frac{y_i}{\\tau^2 + s_i^2} \\right).\n",
    "\\]\n",
    "\n",
    "Here we use the DerSimonian–Laird estimate of \\(\\tau^2\\) as an empirical Bayes plug-in.\n",
    "A fully Bayesian treatment would also place a prior on \\(\\tau^2\\) and sample it;\n",
    "that typically requires MCMC and external libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be6bf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class BayesMetaMuPosterior:\n",
    "    mean: float\n",
    "    sd: float\n",
    "    prior_mean: float\n",
    "    prior_sd: float\n",
    "    tau2_used: float\n",
    "\n",
    "\n",
    "def bayes_meta_mu_posterior(\n",
    "    df: pd.DataFrame,\n",
    "    re_res: MetaAnalysisResult,\n",
    "    prior_mean: float = 0.0,\n",
    "    prior_sd: float = 0.05,\n",
    ") -> BayesMetaMuPosterior:\n",
    "    \"\"\"Posterior for the meta-mean mu under a Normal prior and known tau^2.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Portfolio with columns ['effect_hat', 'se_hat'].\n",
    "    re_res : MetaAnalysisResult\n",
    "        Random-effects meta-analysis result providing tau^2 and a point estimate.\n",
    "    prior_mean : float\n",
    "        Prior mean m0 for mu.\n",
    "    prior_sd : float\n",
    "        Prior standard deviation s0 for mu.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    BayesMetaMuPosterior\n",
    "        Posterior mean and standard deviation for mu.\n",
    "    \"\"\"\n",
    "    if re_res.tau2 is None:\n",
    "        raise ValueError(\"Random-effects result must contain tau2.\")\n",
    "\n",
    "    tau2 = max(0.0, float(re_res.tau2))\n",
    "    effects = df[\"effect_hat\"].to_numpy()\n",
    "    ses = df[\"se_hat\"].to_numpy()\n",
    "    var_obs = ses**2 + tau2\n",
    "\n",
    "    m0 = prior_mean\n",
    "    s0_sq = prior_sd**2\n",
    "\n",
    "    # Posterior variance\n",
    "    inv_v = 1.0 / s0_sq + np.sum(1.0 / var_obs)\n",
    "    v_mu = 1.0 / inv_v\n",
    "\n",
    "    # Posterior mean\n",
    "    m_mu = v_mu * (m0 / s0_sq + np.sum(effects / var_obs))\n",
    "\n",
    "    return BayesMetaMuPosterior(\n",
    "        mean=float(m_mu),\n",
    "        sd=float(math.sqrt(v_mu)),\n",
    "        prior_mean=prior_mean,\n",
    "        prior_sd=prior_sd,\n",
    "        tau2_used=tau2,\n",
    "    )\n",
    "\n",
    "\n",
    "bayes_mu_post = bayes_meta_mu_posterior(\n",
    "    df_portfolio,\n",
    "    re_res=re_res,\n",
    "    prior_mean=0.0,\n",
    "    prior_sd=0.05,\n",
    ")\n",
    "bayes_mu_post\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ba99da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compare FE, RE, and Bayesian meta-mean estimates\n",
    "\n",
    "print(\"Fixed-effect pooled mean:\", fe_res.theta_hat, \"+/-\", 1.96 * fe_res.se)\n",
    "print(\"Random-effects pooled mean:\", re_res.theta_hat, \"+/-\", 1.96 * re_res.se)\n",
    "print(\n",
    "    \"Bayesian mu posterior mean:\", bayes_mu_post.mean,\n",
    "    \"+/-\", 1.96 * bayes_mu_post.sd,\n",
    ")\n",
    "\n",
    "# Simple visualization of the posterior for mu\n",
    "mu_grid = np.linspace(\n",
    "    bayes_mu_post.mean - 4 * bayes_mu_post.sd,\n",
    "    bayes_mu_post.mean + 4 * bayes_mu_post.sd,\n",
    "    200,\n",
    ")\n",
    "dens = (1.0 / (math.sqrt(2.0 * math.pi) * bayes_mu_post.sd)\n",
    "        * np.exp(-0.5 * ((mu_grid - bayes_mu_post.mean) / bayes_mu_post.sd) ** 2))\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(mu_grid, dens)\n",
    "plt.axvline(0.0, linestyle=\"--\", linewidth=1, label=\"no effect\")\n",
    "plt.axvline(bayes_mu_post.mean, linestyle=\"-\", linewidth=1.5, label=\"posterior mean\")\n",
    "plt.xlabel(\"mu (meta-level mean effect)\")\n",
    "plt.ylabel(\"posterior density (up to scaling)\")\n",
    "plt.title(\"Posterior for meta-level mean effect mu\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab004bb",
   "metadata": {},
   "source": [
    "\n",
    "This Bayesian hierarchical view gives you:\n",
    "\n",
    "- A posterior distribution for the **overall mean effect** \\(\\mu\\) across experiments.  \n",
    "- A way to quantify uncertainty around \\(\\mu\\) (not just a point estimate and CI).  \n",
    "- A prior that you can reuse for new experiments, together with the\n",
    "  **per-experiment partial pooling** we implemented earlier.\n",
    "\n",
    "In practice you would typically implement a full Bayesian hierarchical model with\n",
    "a prior on \\(\\tau^2\\) and sample both \\(\\mu\\) and \\(\\tau^2\\) using MCMC\n",
    "(PyMC, Stan, etc.), but the structure here mirrors that model in a lightweight,\n",
    "teachable way.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88d6b9b",
   "metadata": {},
   "source": [
    "\n",
    "## 10) Meta-experiment dashboard\n",
    "\n",
    "To make this notebook directly useful as a **portfolio summary**, we add a small\n",
    "“meta-experiment dashboard” cell that pulls together the key quantities:\n",
    "\n",
    "- Meta-level mean effect \\(\\mu\\).  \n",
    "- Between-experiment standard deviation \\(\\tau\\).  \n",
    "- Probability that a random future experiment has **positive effect**,  \n",
    "  \\(P(\\theta_{\\text{new}} > 0)\\).  \n",
    "- Uplift bands (e.g. 10%, 50%, 90% quantiles) for \\(\\theta_{\\text{new}}\\) under\n",
    "  the meta prior.\n",
    "\n",
    "This is the kind of summary you can show to stakeholders as a **“what do experiments\n",
    "usually do here?”** overview.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af1b046",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dataclasses import asdict\n",
    "\n",
    "def compute_meta_dashboard(\n",
    "    shrink_res: ShrinkageResult,\n",
    "    bayes_mu_post: BayesMetaMuPosterior,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Build a small dashboard of meta-level quantities.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    shrink_res : ShrinkageResult\n",
    "        Result of shrink_experiment_effects, carrying mu and tau^2.\n",
    "    bayes_mu_post : BayesMetaMuPosterior\n",
    "        Posterior for the meta-level mean effect mu.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        One-row summary with key statistics.\n",
    "    \"\"\"\n",
    "    mu = shrink_res.mu\n",
    "    tau = math.sqrt(max(0.0, shrink_res.tau2))\n",
    "\n",
    "    # Probability theta_new > 0 under Normal(mu, tau^2)\n",
    "    if tau > 0:\n",
    "        z0 = (0.0 - mu) / tau\n",
    "        cdf0 = 0.5 * (1.0 + math.erf(z0 / math.sqrt(2.0)))\n",
    "        prob_positive = 1.0 - cdf0\n",
    "    else:\n",
    "        prob_positive = 1.0 if mu > 0 else 0.0\n",
    "\n",
    "    # Uplift bands: 10%, 50%, 90% quantiles of theta_new ~ N(mu, tau^2)\n",
    "    from math import erf, sqrt\n",
    "\n",
    "    def normal_ppf(q: float, mean: float, sd: float) -> float:\n",
    "        \"\"\"Approximate inverse CDF using binary search on Normal(mean, sd^2).\"\"\"\n",
    "        # Simple, self-contained implementation; accuracy is enough for reporting.\n",
    "        if sd <= 0:\n",
    "            return mean\n",
    "        low, high = mean - 10 * sd, mean + 10 * sd\n",
    "        for _ in range(60):\n",
    "            mid = 0.5 * (low + high)\n",
    "            z = (mid - mean) / (sd * sqrt(2.0))\n",
    "            cdf_mid = 0.5 * (1.0 + erf(z))\n",
    "            if cdf_mid < q:\n",
    "                low = mid\n",
    "            else:\n",
    "                high = mid\n",
    "        return 0.5 * (low + high)\n",
    "\n",
    "    if tau > 0:\n",
    "        q10 = normal_ppf(0.10, mu, tau)\n",
    "        q50 = normal_ppf(0.50, mu, tau)\n",
    "        q90 = normal_ppf(0.90, mu, tau)\n",
    "    else:\n",
    "        q10 = q50 = q90 = mu\n",
    "\n",
    "    data = {\n",
    "        \"meta_mu_mean\": mu,\n",
    "        \"meta_tau_sd\": tau,\n",
    "        \"P(theta_new > 0)\": prob_positive,\n",
    "        \"theta_new_q10\": q10,\n",
    "        \"theta_new_q50\": q50,\n",
    "        \"theta_new_q90\": q90,\n",
    "        \"bayes_mu_post_mean\": bayes_mu_post.mean,\n",
    "        \"bayes_mu_post_sd\": bayes_mu_post.sd,\n",
    "    }\n",
    "    return pd.DataFrame([data])\n",
    "\n",
    "\n",
    "try:\n",
    "    dashboard_df = compute_meta_dashboard(shrink_res, bayes_mu_post)\n",
    "    display(dashboard_df)\n",
    "except NameError as e:\n",
    "    print(\n",
    "        \"Dashboard depends on 'shrink_res' and 'bayes_mu_post'. \"\n",
    "        \"Make sure to run the previous meta-analysis cells first.\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}