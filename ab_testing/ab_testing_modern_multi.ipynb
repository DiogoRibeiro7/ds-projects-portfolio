{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b01745f",
   "metadata": {},
   "source": [
    "\n",
    "# Modern A/B Testing Notebook — Multiple Public Case Studies (with Uplift)\n",
    "\n",
    "This notebook aggregates **multiple well-known A/B case studies** and adds a **modern uplift** example:\n",
    "\n",
    "1) **Udacity — Landing Page (`ab_data.csv`)**: user-level test, classic conversion analysis.  \n",
    "2) **Udacity — Free Trial Screener (aggregates)**: GC/NC metrics, power/MDE.  \n",
    "3) **Criteo Uplift Modeling (public sample)**: treatment/control ads with features, enabling **uplift evaluation** (Qini, uplift@K).\n",
    "\n",
    "All sections come with Markdown explanations before/after code cells.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562a6a65",
   "metadata": {},
   "source": [
    "## Setup — Imports & Shared Statistical Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0a20bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Dict, Optional\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (7, 4.5)\n",
    "plt.rcParams['axes.grid'] = True\n",
    "RANDOM_SEED = 7\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ProportionSummary:\n",
    "    p: float\n",
    "    n: int\n",
    "    x: int\n",
    "\n",
    "def summarize_proportion(x: int, n: int) -> ProportionSummary:\n",
    "    if n <= 0:\n",
    "        raise ValueError(\"n must be positive.\")\n",
    "    if not (0 <= x <= n):\n",
    "        raise ValueError(\"x must be in [0, n].\")\n",
    "    return ProportionSummary(p=x / n, n=n, x=x)\n",
    "\n",
    "def two_prop_ztest(x1: int, n1: int, x2: int, n2: int, two_sided: bool = True):\n",
    "    s1 = summarize_proportion(x1, n1)\n",
    "    s2 = summarize_proportion(x2, n2)\n",
    "    p_pool = (s1.x + s2.x) / (s1.n + s2.n)\n",
    "    se = math.sqrt(p_pool * (1 - p_pool) * (1/s1.n + 1/s2.n))\n",
    "    if se == 0.0:\n",
    "        raise ZeroDivisionError(\"SE=0; verify inputs.\")\n",
    "    z = (s1.p - s2.p) / se\n",
    "    p_val = 2 * (1 - 0.5 * (1 + math.erf(abs(z) / math.sqrt(2)))) if two_sided else (1 - 0.5 * (1 + math.erf(z / math.sqrt(2))))\n",
    "    return z, p_val\n",
    "\n",
    "def bootstrap_ci_diff(pA: float, pB: float, nA: int, nB: int, B: int = 5000, alpha: float = 0.05):\n",
    "    diffs = np.empty(B, dtype=float)\n",
    "    for b in range(B):\n",
    "        xA = np.random.binomial(nA, pA)\n",
    "        xB = np.random.binomial(nB, pB)\n",
    "        diffs[b] = xB / nB - xA / nA\n",
    "    lo = float(np.quantile(diffs, alpha/2))\n",
    "    hi = float(np.quantile(diffs, 1 - alpha/2))\n",
    "    return lo, hi\n",
    "\n",
    "def required_n_two_proportions(pA: float, pB: float, alpha: float = 0.05, power: float = 0.8, two_sided: bool = True) -> int:\n",
    "    def invPhi(u: float) -> float:\n",
    "        return math.sqrt(2) * math.erfcinv(2*(1 - u))\n",
    "    z_alpha = abs(invPhi(1 - alpha/2)) if two_sided else abs(invPhi(1 - alpha))\n",
    "    z_beta = abs(invPhi(power))\n",
    "    pbar = 0.5 * (pA + pB)\n",
    "    delta = abs(pB - pA)\n",
    "    if delta == 0.0:\n",
    "        raise ValueError(\"delta=0 implies infinite sample size to detect.\")\n",
    "    se = math.sqrt(2 * pbar * (1 - pbar))\n",
    "    n = ((z_alpha + z_beta) * se / delta) ** 2\n",
    "    return math.ceil(n)\n",
    "\n",
    "def mde_for_n(pA: float, n_per_arm: int, alpha: float = 0.05, power: float = 0.8, two_sided: bool = True) -> float:\n",
    "    def invPhi(u: float) -> float:\n",
    "        return math.sqrt(2) * math.erfcinv(2*(1 - u))\n",
    "    z_alpha = abs(invPhi(1 - alpha/2)) if two_sided else abs(invPhi(1 - alpha))\n",
    "    z_beta = abs(invPhi(power))\n",
    "    se = math.sqrt(2 * pA * (1 - pA))\n",
    "    return float((z_alpha + z_beta) * se / math.sqrt(max(n_per_arm, 1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8228101c",
   "metadata": {},
   "source": [
    "**Helpers.** Z-test, bootstrap CI, sample size (required_n), and MDE calculation are provided once and reused."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8619bc7",
   "metadata": {},
   "source": [
    "## 1) Udacity — Landing Page (`ab_data.csv`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b84c6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RAW_URL = \"https://raw.githubusercontent.com/udacity/sdand-ab-testing-project/main/ab_data.csv\"\n",
    "df = pd.read_csv(RAW_URL)\n",
    "mask_ok = ((df['group']=='control') & (df['landing_page']=='old_page')) | ((df['group']=='treatment') & (df['landing_page']=='new_page'))\n",
    "df_clean = df[mask_ok].drop_duplicates('user_id', keep='first').copy()\n",
    "\n",
    "grp = df_clean.groupby('group')['converted'].agg(['sum','count','mean']).rename(columns={'sum':'x','count':'n','mean':'rate'})\n",
    "A = summarize_proportion(int(grp.loc['control','x']), int(grp.loc['control','n']))\n",
    "B = summarize_proportion(int(grp.loc['treatment','x']), int(grp.loc['treatment','n']))\n",
    "z, p = two_prop_ztest(A.x, A.n, B.x, B.n, two_sided=True)\n",
    "ci_lo, ci_hi = bootstrap_ci_diff(A.p, B.p, A.n, B.n, B=3000, alpha=0.05)\n",
    "abs_lift = B.p - A.p\n",
    "rel_lift = abs_lift / A.p if A.p else float('inf')\n",
    "\n",
    "pd.DataFrame({\n",
    "    'arm':['control','treatment'],\n",
    "    'n':[A.n,B.n],\n",
    "    'x':[A.x,B.x],\n",
    "    'rate':[A.p,B.p],\n",
    "    'p_value(z-test)': [p,p],\n",
    "    'abs_lift(B-A)':[abs_lift,abs_lift],\n",
    "    'rel_lift':[rel_lift,rel_lift],\n",
    "    'boot_CI_lo':[ci_lo,ci_lo],\n",
    "    'boot_CI_hi':[ci_hi,ci_hi],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17424e45",
   "metadata": {},
   "source": [
    "**Explanation.** Classic two-proportion test on conversion; bootstrap CI provides a robust interval for the absolute lift."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44c275f",
   "metadata": {},
   "source": [
    "## 2) Udacity — Free Trial Screener (Aggregates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5c1233",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "totals = {\n",
    "    \"sanity\": {\n",
    "        \"pageviews\": {\"control\": 345543, \"experiment\": 344660},\n",
    "        \"clicks\":    {\"control\": 28378,  \"experiment\": 28325},\n",
    "    },\n",
    "    \"metrics\": {\n",
    "        \"gross_conversion\": {\n",
    "            \"clicks\":      {\"control\": 17293, \"experiment\": 17260},\n",
    "            \"enrollments\": {\"control\":  3785, \"experiment\":  3423},\n",
    "        },\n",
    "        \"net_conversion\": {\n",
    "            \"clicks\":   {\"control\": 17293, \"experiment\": 17260},\n",
    "            \"payments\": {\"control\":  2033, \"experiment\":  1945},\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "def run_ratio_test(xA, nA, xB, nB):\n",
    "    A = summarize_proportion(xA, nA); B = summarize_proportion(xB, nB)\n",
    "    z, p = two_prop_ztest(A.x, A.n, B.x, B.n, two_sided=True)\n",
    "    ci_lo, ci_hi = bootstrap_ci_diff(A.p, B.p, A.n, B.n, B=3000, alpha=0.05)\n",
    "    return A, B, z, p, ci_lo, ci_hi\n",
    "\n",
    "# Gross Conversion\n",
    "gc = totals[\"metrics\"][\"gross_conversion\"]\n",
    "A, B, z_gc, p_gc, lo_gc, hi_gc = run_ratio_test(gc[\"enrollments\"][\"control\"], gc[\"clicks\"][\"control\"],\n",
    "                                                gc[\"enrollments\"][\"experiment\"], gc[\"clicks\"][\"experiment\"])\n",
    "\n",
    "# Net Conversion\n",
    "nc = totals[\"metrics\"][\"net_conversion\"]\n",
    "A2, B2, z_nc, p_nc, lo_nc, hi_nc = run_ratio_test(nc[\"payments\"][\"control\"], nc[\"clicks\"][\"control\"],\n",
    "                                                  nc[\"payments\"][\"experiment\"], nc[\"clicks\"][\"experiment\"])\n",
    "\n",
    "pd.DataFrame({\n",
    "    'metric':['gross_conversion','net_conversion'],\n",
    "    'control_rate':[A.p, A2.p],\n",
    "    'treatment_rate':[B.p, B2.p],\n",
    "    'p_value(z-test)':[p_gc, p_nc],\n",
    "    'boot_CI_lo(B-A)':[lo_gc, lo_nc],\n",
    "    'boot_CI_hi(B-A)':[hi_gc, hi_nc],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d99c9b",
   "metadata": {},
   "source": [
    "**Explanation.** Screener aims to reduce GC while keeping NC flat. We report p-values and bootstrap CIs for both metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baab066",
   "metadata": {},
   "source": [
    "## 3) Criteo Uplift Modeling — Modern Uplift A/B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e473f4f5",
   "metadata": {},
   "source": [
    "\n",
    "**Why this is modern?** Many modern experiments focus on **heterogeneous treatment effects**: *who* benefits from treatment, not just whether treatment is better on average.  \n",
    "The **Criteo Uplift Modeling** dataset contains treatment (`treatment`) and outcome (`conversion`) with user features, enabling **uplift** analysis.\n",
    "\n",
    "We load a **public sample** from the CausalML repository (CSV.gz). We'll compute:\n",
    "- Group-level conversion (classic A/B sanity).\n",
    "- A simple **uplift@K** curve using a logistic score (no external libraries).\n",
    "- **Qini coefficient** approximation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc724e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Public sample hosted by CausalML repo (CSV.GZ)\n",
    "URL = \"https://raw.githubusercontent.com/uber/causalml/master/examples/data/criteo_uplift.csv.gz\"\n",
    "upl = pd.read_csv(URL, compression='gzip')\n",
    "\n",
    "# Expect columns (common sample): 'treatment', 'conversion' (0/1), and features.\n",
    "expected = {'treatment','conversion'}\n",
    "missing = expected - set(upl.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Expected columns missing: {missing}\")\n",
    "\n",
    "upl[['treatment','conversion']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be3e8eb",
   "metadata": {},
   "source": [
    "**Sanity.** We check that treatment/control exist and compute base conversion by group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93991e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "upl.groupby('treatment')['conversion'].agg(['mean','sum','count'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f016fa",
   "metadata": {},
   "source": [
    "### A simple uplift scoring and Qini/uplift@K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4672addb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# We'll fit two separate logistic models (T-learner style) just for a ranking score:\n",
    "# P(y|X, T=1) and P(y|X, T=0). Uplift score ~ p1 - p0.\n",
    "# NOTE: Only for demonstration; production uplift uses stronger learners & CV.\n",
    "\n",
    "# Use numeric features only\n",
    "feat_cols = [c for c in upl.columns if c not in ('treatment','conversion')]\n",
    "X = upl[feat_cols].select_dtypes(include=[np.number]).fillna(0.0).values\n",
    "y = upl['conversion'].values\n",
    "t = upl['treatment'].values\n",
    "\n",
    "X1, y1 = X[t==1], y[t==1]\n",
    "X0, y0 = X[t==0], y[t==0]\n",
    "\n",
    "clf1 = LogisticRegression(max_iter=1000)\n",
    "clf0 = LogisticRegression(max_iter=1000)\n",
    "clf1.fit(X1, y1)\n",
    "clf0.fit(X0, y0)\n",
    "\n",
    "p1 = clf1.predict_proba(X)[:,1]\n",
    "p0 = clf0.predict_proba(X)[:,1]\n",
    "uplift_score = p1 - p0\n",
    "\n",
    "# Rank by uplift score desc and compute uplift@k curve\n",
    "order = np.argsort(-uplift_score)\n",
    "conv = y[order]\n",
    "t_ord = t[order]\n",
    "\n",
    "# Compute cumulative treatment vs control conversions as we include top-k users\n",
    "cum_treat = np.cumsum((t_ord==1) * conv)\n",
    "cum_ctrl  = np.cumsum((t_ord==0) * conv)\n",
    "\n",
    "# Normalize by group counts in prefix to approximate incremental conversions\n",
    "cnt_treat = np.cumsum((t_ord==1).astype(int))\n",
    "cnt_ctrl  = np.cumsum((t_ord==0).astype(int))\n",
    "\n",
    "# Avoid division by zero\n",
    "rate_treat = np.where(cnt_treat>0, cum_treat/np.maximum(cnt_treat,1), 0.0)\n",
    "rate_ctrl  = np.where(cnt_ctrl>0,  cum_ctrl/np.maximum(cnt_ctrl,1),  0.0)\n",
    "\n",
    "uplift_at_k = rate_treat - rate_ctrl\n",
    "\n",
    "# Qini-like area (simple discrete sum)\n",
    "qini = float(np.trapz(uplift_at_k, dx=1.0/len(uplift_at_k)))\n",
    "\n",
    "len(uplift_at_k), qini\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3682e8",
   "metadata": {},
   "source": [
    "**Plot uplift@K (percentile on x-axis)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4be1760",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k = len(uplift_at_k)\n",
    "x = np.linspace(0, 100, num=k)\n",
    "plt.figure()\n",
    "plt.plot(x, uplift_at_k)\n",
    "plt.title(\"Uplift@K curve (T-learner logistic)\")\n",
    "plt.xlabel(\"Top-K% (ranked by uplift score)\")\n",
    "plt.ylabel(\"Estimated uplift (Δconv rate)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d4b93d",
   "metadata": {},
   "source": [
    "\n",
    "**Interpretation.** If the curve is above zero for the top-K%, targeting those users would **increase** conversions relative to control.  \n",
    "The **Qini-like area** summarizes this curve; higher is better.\n",
    "\n",
    "> In production, prefer robust uplift estimators (e.g., DR-Learner, X-Learner) and cross-validation; consider constraints (budget, exposure).\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}