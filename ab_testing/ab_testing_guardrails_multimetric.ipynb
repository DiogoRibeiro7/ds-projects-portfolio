{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75746ef1",
   "metadata": {},
   "source": [
    "\n",
    "# A/B Testing with Guardrail Metrics and Multi-Metric Decision Rules\n",
    "\n",
    "This notebook focuses specifically on **guardrail metrics** and **multi-metric decisions** in A/B tests.\n",
    "\n",
    "We will:\n",
    "\n",
    "1. Simulate an experiment with a primary metric (conversion + revenue).  \n",
    "2. Add realistic **guardrails**: refund rate, support tickets, latency.  \n",
    "3. Define a **frequentist decision rule** that combines primary and guardrails.  \n",
    "4. Define a **Bayesian decision rule** using Beta–Binomial posteriors.  \n",
    "5. Provide a reusable **decision matrix** template.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cf3847",
   "metadata": {},
   "source": [
    "## 0) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617c4e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (7, 4.5)\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PropSummary:\n",
    "    \"\"\"Summary of a Bernoulli proportion.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    p : float\n",
    "        Sample proportion x / n.\n",
    "    n : int\n",
    "        Sample size.\n",
    "    x : int\n",
    "        Number of successes.\n",
    "    \"\"\"\n",
    "    p: float\n",
    "    n: int\n",
    "    x: int\n",
    "\n",
    "\n",
    "def summarize_prop(x: int, n: int) -> PropSummary:\n",
    "    \"\"\"Validate and summarize a proportion sample.\"\"\"\n",
    "    if n <= 0:\n",
    "        raise ValueError(\"n must be positive.\")\n",
    "    if not (0 <= x <= n):\n",
    "        raise ValueError(\"x must satisfy 0 <= x <= n.\")\n",
    "    return PropSummary(p=x / n, n=n, x=x)\n",
    "\n",
    "\n",
    "def sample_posterior_lift(\n",
    "    xA: int,\n",
    "    nA: int,\n",
    "    xB: int,\n",
    "    nB: int,\n",
    "    alpha0: float = 1.0,\n",
    "    beta0: float = 1.0,\n",
    "    n_draws: int = 50_000,\n",
    "    seed: int | None = 1,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Draw from the posterior of Bernoulli rates and their difference.\n",
    "\n",
    "    Beta–Binomial model:\n",
    "\n",
    "    - Prior: p ~ Beta(alpha0, beta0)\n",
    "    - Data: x successes out of n\n",
    "    - Posterior: p | data ~ Beta(alpha0 + x, beta0 + n - x)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xA, nA, xB, nB : int\n",
    "        Successes and sample sizes for control (A) and treatment (B).\n",
    "    alpha0, beta0 : float\n",
    "        Beta prior hyperparameters (shared across arms).\n",
    "    n_draws : int\n",
    "        Number of Monte Carlo draws.\n",
    "    seed : int | None\n",
    "        Random seed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        Columns: pA, pB, lift = pB - pA.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    alphaA = alpha0 + xA\n",
    "    betaA = beta0 + nA - xA\n",
    "    alphaB = alpha0 + xB\n",
    "    betaB = beta0 + nB - xB\n",
    "\n",
    "    pA_draws = rng.beta(alphaA, betaA, size=n_draws)\n",
    "    pB_draws = rng.beta(alphaB, betaB, size=n_draws)\n",
    "    lift = pB_draws - pA_draws\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"pA\": pA_draws,\n",
    "            \"pB\": pB_draws,\n",
    "            \"lift\": lift,\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6868c920",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Simulated experiment with primary metrics\n",
    "\n",
    "We create a simple experiment with:\n",
    "\n",
    "- `group ∈ {control, treatment}`  \n",
    "- `converted` (0/1)  \n",
    "- `revenue` (0 for non-converters)  \n",
    "- `pre_activity` (pre-period user proxy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7a03c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def simulate_experiment(\n",
    "    n: int = 20_000,\n",
    "    p_control: float = 0.10,\n",
    "    lift_treatment: float = 0.02,\n",
    "    mean_revenue: float = 100.0,\n",
    "    revenue_sd: float = 40.0,\n",
    "    seed: int | None = 123,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Simulate a simple online experiment with binary conversion and revenue.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    user_id = np.arange(n)\n",
    "    group_flag = rng.binomial(1, 0.5, size=n)\n",
    "    group = np.where(group_flag == 0, \"control\", \"treatment\")\n",
    "\n",
    "    p_treat = p_control + lift_treatment\n",
    "    p = np.where(group_flag == 0, p_control, p_treat)\n",
    "    converted = rng.binomial(1, p)\n",
    "\n",
    "    # revenue: only for converters, Normal for illustration\n",
    "    rev = rng.normal(loc=mean_revenue, scale=revenue_sd, size=n)\n",
    "    rev = np.where(converted == 1, rev, 0.0)\n",
    "\n",
    "    # pre-activity covariate (correlated with conversion)\n",
    "    pre_activity = rng.normal(loc=0.0, scale=1.0, size=n) + converted * 0.7\n",
    "\n",
    "    df_sim = pd.DataFrame(\n",
    "        {\n",
    "            \"user_id\": user_id,\n",
    "            \"group\": group,\n",
    "            \"converted\": converted.astype(int),\n",
    "            \"revenue\": rev.astype(float),\n",
    "            \"pre_activity\": pre_activity.astype(float),\n",
    "        }\n",
    "    )\n",
    "    return df_sim\n",
    "\n",
    "\n",
    "df = simulate_experiment()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ad3d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Basic primary metrics\n",
    "conv_by_group = (\n",
    "    df.groupby(\"group\")[\"converted\"]\n",
    "      .agg([\"sum\", \"count\", \"mean\"])\n",
    "      .rename(columns={\"sum\": \"x\", \"count\": \"n\", \"mean\": \"rate\"})\n",
    ")\n",
    "rev_by_group = df.groupby(\"group\")[\"revenue\"].agg([\"mean\", \"std\", \"count\"])\n",
    "\n",
    "conv_by_group, rev_by_group\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b416e99",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Adding guardrail metrics\n",
    "\n",
    "We now augment the dataset with three guardrail metrics:\n",
    "\n",
    "- `refund` — only possible for converters, slightly higher in treatment.  \n",
    "- `support_ticket` — higher for low-activity users and in treatment.  \n",
    "- `latency_ms` — slightly larger latency under treatment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d8b0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rng_guard = np.random.default_rng(2025)\n",
    "\n",
    "df = df.copy()\n",
    "\n",
    "# Refunds: only among converters; assume treatment slightly worse\n",
    "mask_conv = df[\"converted\"] == 1\n",
    "mask_control = df[\"group\"] == \"control\"\n",
    "mask_treat = df[\"group\"] == \"treatment\"\n",
    "\n",
    "prob_refund = np.zeros(len(df), dtype=float)\n",
    "prob_refund[mask_conv & mask_control] = 0.04  # ~4% refunds for converters in control\n",
    "prob_refund[mask_conv & mask_treat] = 0.06    # ~6% for converters in treatment\n",
    "\n",
    "df[\"refund\"] = rng_guard.binomial(1, prob_refund)\n",
    "\n",
    "# Support tickets: base + bump for low pre_activity + bump for treatment\n",
    "base_support = 0.03\n",
    "extra_low_activity = 0.02 * (df[\"pre_activity\"] < 0.0).astype(float)\n",
    "extra_treat = 0.01 * (df[\"group\"] == \"treatment\").astype(float)\n",
    "\n",
    "prob_support = base_support + extra_low_activity + extra_treat\n",
    "prob_support = np.clip(prob_support, 0.0, 0.30)\n",
    "df[\"support_ticket\"] = rng_guard.binomial(1, prob_support)\n",
    "\n",
    "# Latency: base 300 ms, treatment adds ~30ms plus noise\n",
    "latency_noise = rng_guard.normal(loc=0.0, scale=30.0, size=len(df))\n",
    "df[\"latency_ms\"] = (\n",
    "    300.0\n",
    "    + 30.0 * (df[\"group\"] == \"treatment\").astype(float)\n",
    "    + latency_noise\n",
    ")\n",
    "\n",
    "guardrail_summary = (\n",
    "    df.groupby(\"group\")[[\"refund\", \"support_ticket\", \"latency_ms\"]]\n",
    "      .agg([\"mean\", \"std\", \"count\"])\n",
    ")\n",
    "guardrail_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b398b6",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Frequentist multi-metric decision rule\n",
    "\n",
    "Assume:\n",
    "\n",
    "- **Primary metric**: revenue per user (RPU).  \n",
    "- **Guardrails**: `refund` and `support_ticket` (both “lower is better”).\n",
    "\n",
    "We define a simple decision rule:\n",
    "\n",
    "> **Ship** treatment if  \n",
    "> 1. RPU difference (treatment − control) is **positive**, and  \n",
    "> 2. Refund rate increase is at most 1 percentage point, and  \n",
    "> 3. Support ticket rate increase is at most 0.5 percentage points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87344bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Primary metric: revenue per user\n",
    "rev_group = (\n",
    "    df.groupby(\"group\")[\"revenue\"]\n",
    "      .agg([\"mean\", \"var\", \"count\"])\n",
    "      .rename(columns={\"mean\": \"mean_revenue\", \"count\": \"n\"})\n",
    ")\n",
    "rev_group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8d4351",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Primary RPU difference\n",
    "mean_rev_ctrl = float(rev_group.loc[\"control\", \"mean_revenue\"])\n",
    "mean_rev_treat = float(rev_group.loc[\"treatment\", \"mean_revenue\"])\n",
    "diff_rpu = mean_rev_treat - mean_rev_ctrl\n",
    "\n",
    "# Guardrail 1: refund rate\n",
    "x_ref_ctrl = int(df.loc[df[\"group\"] == \"control\", \"refund\"].sum())\n",
    "n_ref_ctrl = int(df.loc[df[\"group\"] == \"control\", \"refund\"].count())\n",
    "x_ref_treat = int(df.loc[df[\"group\"] == \"treatment\", \"refund\"].sum())\n",
    "n_ref_treat = int(df.loc[df[\"group\"] == \"treatment\", \"refund\"].count())\n",
    "\n",
    "s_ref_ctrl = summarize_prop(x_ref_ctrl, n_ref_ctrl)\n",
    "s_ref_treat = summarize_prop(x_ref_treat, n_ref_treat)\n",
    "diff_refund = s_ref_treat.p - s_ref_ctrl.p\n",
    "\n",
    "# Guardrail 2: support ticket rate\n",
    "x_sup_ctrl = int(df.loc[df[\"group\"] == \"control\", \"support_ticket\"].sum())\n",
    "n_sup_ctrl = int(df.loc[df[\"group\"] == \"control\", \"support_ticket\"].count())\n",
    "x_sup_treat = int(df.loc[df[\"group\"] == \"treatment\", \"support_ticket\"].sum())\n",
    "n_sup_treat = int(df.loc[df[\"group\"] == \"treatment\", \"support_ticket\"].count())\n",
    "\n",
    "s_sup_ctrl = summarize_prop(x_sup_ctrl, n_sup_ctrl)\n",
    "s_sup_treat = summarize_prop(x_sup_treat, n_sup_treat)\n",
    "diff_support = s_sup_treat.p - s_sup_ctrl.p\n",
    "\n",
    "# Decision thresholds (absolute differences)\n",
    "max_refund_increase = 0.01   # allow up to +1 percentage point\n",
    "max_support_increase = 0.005 # allow up to +0.5 percentage points\n",
    "\n",
    "ship_frequentist = (\n",
    "    (diff_rpu > 0.0)\n",
    "    and (diff_refund <= max_refund_increase)\n",
    "    and (diff_support <= max_support_increase)\n",
    ")\n",
    "\n",
    "{\n",
    "    \"diff_rpu_treat_minus_ctrl\": diff_rpu,\n",
    "    \"diff_refund_rate\": diff_refund,\n",
    "    \"diff_support_rate\": diff_support,\n",
    "    \"max_refund_increase_allowed\": max_refund_increase,\n",
    "    \"max_support_increase_allowed\": max_support_increase,\n",
    "    \"ship_frequentist_rule\": ship_frequentist,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3affbacf",
   "metadata": {},
   "source": [
    "\n",
    "This rule is intentionally simple and transparent.\n",
    "\n",
    "In real experiments you might also require:\n",
    "\n",
    "- RPU improvement to be **statistically significant**, and  \n",
    "- Guardrail degradations to be **not statistically significant** (or below a practical threshold).\n",
    "\n",
    "Next we build a Bayesian version using Beta–Binomial posteriors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74cc2ba",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Bayesian multi-metric decision rule (primary + guardrail)\n",
    "\n",
    "We use the same Beta–Binomial model for:\n",
    "\n",
    "- Primary: conversion (for illustration).  \n",
    "- Guardrail: refund rate (undesirable, lower is better).\n",
    "\n",
    "Decision rule:\n",
    "\n",
    "> **Ship** if  \n",
    "> - \\(P(p_\\text{treat} - p_\\text{control} > 0 \\mid data) > 0.95\\) (treatment increases conversion), **and**  \n",
    "> - \\(P(\\text{refund}_\\text{treat} - \\text{refund}_\\text{control} < 0.01 \\mid data) > 0.90\\)\n",
    ">   (refund rate increase is probably less than 1 percentage point).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afadfa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Conversion counts for primary Bayesian metric\n",
    "conv_by_group = (\n",
    "    df.groupby(\"group\")[\"converted\"]\n",
    "      .agg([\"sum\", \"count\"])\n",
    "      .rename(columns={\"sum\": \"x\", \"count\": \"n\"})\n",
    ")\n",
    "xA = int(conv_by_group.loc[\"control\", \"x\"])\n",
    "nA = int(conv_by_group.loc[\"control\", \"n\"])\n",
    "xB = int(conv_by_group.loc[\"treatment\", \"x\"])\n",
    "nB = int(conv_by_group.loc[\"treatment\", \"n\"])\n",
    "\n",
    "post_conv = sample_posterior_lift(\n",
    "    xA=xA,\n",
    "    nA=nA,\n",
    "    xB=xB,\n",
    "    nB=nB,\n",
    "    alpha0=1.0,\n",
    "    beta0=1.0,\n",
    "    n_draws=80_000,\n",
    "    seed=2026,\n",
    ")\n",
    "\n",
    "prob_conv_positive = float((post_conv[\"lift\"] > 0.0).mean())\n",
    "conv_lo, conv_hi = np.quantile(post_conv[\"lift\"], [0.025, 0.975])\n",
    "\n",
    "prob_conv_positive, (conv_lo, conv_hi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e597585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Posterior for refund rate lift (guardrail)\n",
    "post_refund = sample_posterior_lift(\n",
    "    xA=x_ref_ctrl,\n",
    "    nA=n_ref_ctrl,\n",
    "    xB=x_ref_treat,\n",
    "    nB=n_ref_treat,\n",
    "    alpha0=1.0,\n",
    "    beta0=1.0,\n",
    "    n_draws=80_000,\n",
    "    seed=2027,\n",
    ")\n",
    "\n",
    "refund_lift = post_refund[\"lift\"]  # treat - control\n",
    "refund_lo, refund_hi = np.quantile(refund_lift, [0.025, 0.975])\n",
    "\n",
    "# Probability that refund increase is less than +1 percentage point\n",
    "bayes_max_refund_increase = 0.01\n",
    "prob_refund_within_band = float((refund_lift < bayes_max_refund_increase).mean())\n",
    "\n",
    "{\n",
    "    \"refund_lift_CI95\": (refund_lo, refund_hi),\n",
    "    \"bayesian_max_refund_increase\": bayes_max_refund_increase,\n",
    "    \"prob_refund_increase_less_than_threshold\": prob_refund_within_band,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a749d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine into a Bayesian decision\n",
    "conv_prob_threshold = 0.95\n",
    "guardrail_prob_threshold = 0.90\n",
    "\n",
    "ship_bayesian = (\n",
    "    (prob_conv_positive > conv_prob_threshold)\n",
    "    and (prob_refund_within_band > guardrail_prob_threshold)\n",
    ")\n",
    "\n",
    "{\n",
    "    \"P(conv_lift > 0)\": prob_conv_positive,\n",
    "    \"P(refund_lift < 0.01)\": prob_refund_within_band,\n",
    "    \"conv_prob_threshold\": conv_prob_threshold,\n",
    "    \"guardrail_prob_threshold\": guardrail_prob_threshold,\n",
    "    \"ship_bayesian_rule\": ship_bayesian,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80faa9e",
   "metadata": {},
   "source": [
    "\n",
    "This Bayesian rule encodes both **upside appetite** and **risk tolerance**:\n",
    "\n",
    "- Large `conv_prob_threshold` ⇒ more demanding on primary impact.  \n",
    "- Large `guardrail_prob_threshold` and small allowed refund increase ⇒ more conservative on risk.\n",
    "\n",
    "You can tune these thresholds per **business line** (e.g., payments vs marketing).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4f27e4",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Decision matrix template\n",
    "\n",
    "You can map experiment results into a **decision matrix** that combines primary and guardrail metrics:\n",
    "\n",
    "| Case | Primary metric (e.g. conversion / RPU) | Guardrails (refund, support, latency) | Suggested action |\n",
    "|------|----------------------------------------|----------------------------------------|------------------|\n",
    "| A    | Clearly improved                       | Not degraded (within tolerances)      | **Ship** and monitor |\n",
    "| B    | Clearly improved                       | Mild degradation but acceptable        | **Ship** with mitigation plan |\n",
    "| C    | Neutral / unclear                      | Clean guardrails                       | **Hold / rerun** or gather more data |\n",
    "| D    | Degraded                               | Clean guardrails                       | **Do not ship** |\n",
    "| E    | Improved                               | Clearly degraded (beyond limits)       | **Do not ship**; investigate root cause |\n",
    "| F    | Degraded                               | Degraded                               | **Do not ship**, consider rollback |\n",
    "\n",
    "The frequentist or Bayesian rules you implement should **pre-map** an experiment into one\n",
    "of these cases, so that decisions are consistent across teams and over time.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}