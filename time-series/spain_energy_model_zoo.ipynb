{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Spanish Energy Load \u2013 Extended Model Zoo\n",
        "\n",
        "This notebook applies **multiple forecasting models** to the Spanish\n",
        "dataset (Hourly energy demand, generation and weather \u2013 Spain):\n",
        "\n",
        "- Na\u00efve & seasonal na\u00efve baselines\n",
        "- Holt\u2013Winters Exponential Smoothing\n",
        "- SARIMAX with exogenous temperature\n",
        "- Linear Regression with lagged load + weather + calendar\n",
        "- Random Forest Regressor\n",
        "- HistGradientBoostingRegressor\n",
        "- GradientBoostingRegressor\n",
        "\n",
        "At the end we build an extended **champion\u2013challenger** comparison.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Load and clean Spanish dataset\n",
        "\n",
        "We first try `data/energy.csv` (cleaned Spanish load + temperature).\n",
        "If missing, we fall back to `data/spain/energy_dataset.csv` and build it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor, GradientBoostingRegressor\n",
        "\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.rcParams[\"figure.figsize\"] = (11, 5)\n",
        "\n",
        "CLEAN_PATH = Path(\"data\") / \"energy.csv\"\n",
        "RAW_PATH = Path(\"data\") / \"spain\" / \"energy_dataset.csv\"\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "def build_spain_energy_frame(raw: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Return cleaned hourly Spanish load + temperature.\n",
        "\n",
        "    Expects:\n",
        "    - 'time' column with timestamps\n",
        "    - 'total load actual' as target\n",
        "    - temperature-like columns (containing 'temp' or 'temperature').\n",
        "    \"\"\"\n",
        "    df = raw.copy()\n",
        "    if \"time\" not in df.columns or \"total load actual\" not in df.columns:\n",
        "        raise ValueError(\"Missing 'time' or 'total load actual' in raw data.\")\n",
        "\n",
        "    df[\"timestamp\"] = pd.to_datetime(df[\"time\"], errors=\"coerce\")\n",
        "    df = df.dropna(subset=[\"timestamp\"]).sort_values(\"timestamp\")\n",
        "    df[\"load\"] = df[\"total load actual\"].astype(float)\n",
        "\n",
        "    temp_cols = [c for c in df.columns if (\"temp\" in c.lower() or \"temperature\" in c.lower())]\n",
        "    if temp_cols:\n",
        "        df[\"temperature\"] = df[temp_cols].astype(float).mean(axis=1)\n",
        "    else:\n",
        "        df[\"temperature\"] = np.nan\n",
        "\n",
        "    df = df.set_index(\"timestamp\").asfreq(\"H\")\n",
        "    df[\"load\"] = df[\"load\"].interpolate(limit_direction=\"both\")\n",
        "    if df[\"temperature\"].notna().any():\n",
        "        df[\"temperature\"] = df[\"temperature\"].interpolate(limit_direction=\"both\")\n",
        "\n",
        "    return df[[\"load\", \"temperature\"]]\n",
        "\n",
        "\n",
        "if CLEAN_PATH.exists():\n",
        "    df = pd.read_csv(CLEAN_PATH, parse_dates=[0], index_col=0)\n",
        "else:\n",
        "    if not RAW_PATH.exists():\n",
        "        raise FileNotFoundError(f\"Neither {CLEAN_PATH} nor {RAW_PATH} were found.\")\n",
        "    raw_df = pd.read_csv(RAW_PATH)\n",
        "    df = build_spain_energy_frame(raw_df)\n",
        "    CLEAN_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
        "    df.to_csv(CLEAN_PATH)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 0.1 Metrics and train\u2013test split\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def rmse(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
        "    \"\"\"Root mean squared error.\"\"\"\n",
        "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
        "\n",
        "\n",
        "def mape(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
        "    \"\"\"Mean absolute percentage error (in %).\"\"\"\n",
        "    y_true_safe = np.clip(y_true, 1e-6, None)\n",
        "    return float(np.mean(np.abs((y_true - y_pred) / y_true_safe)) * 100)\n",
        "\n",
        "\n",
        "horizon_days = 30\n",
        "horizon = 24 * horizon_days\n",
        "if len(df) <= 2 * horizon:\n",
        "    raise ValueError(\"Not enough data for 30-day test horizon.\")\n",
        "\n",
        "train_df = df.iloc[:-horizon].copy()\n",
        "test_df = df.iloc[-horizon:].copy()\n",
        "\n",
        "y_train = train_df[\"load\"].to_numpy()\n",
        "y_test = test_df[\"load\"].to_numpy()\n",
        "\n",
        "print(\"Train:\", train_df.index.min(), \"\u2192\", train_df.index.max())\n",
        "print(\"Test: \", test_df.index.min(), \"\u2192\", test_df.index.max())\n",
        "print(\"Train size:\", len(train_df), \"Test size:\", len(test_df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Baselines & Holt\u2013Winters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "seasonal_period = 24\n",
        "\n",
        "# Na\u00efve\n",
        "naive_forecast = np.repeat(y_train[-1], len(y_test))\n",
        "\n",
        "# Seasonal na\u00efve (repeat last day pattern)\n",
        "last_day_pattern = train_df[\"load\"].iloc[-seasonal_period:].to_numpy()\n",
        "seasonal_naive_forecast = np.tile(\n",
        "    last_day_pattern,\n",
        "    int(np.ceil(len(y_test) / seasonal_period)),\n",
        ")[: len(y_test)]\n",
        "\n",
        "print(\"Naive RMSE:         \", rmse(y_test, naive_forecast))\n",
        "print(\"Seasonal naive RMSE:\", rmse(y_test, seasonal_naive_forecast))\n",
        "\n",
        "# Holt\u2013Winters (Exponential Smoothing)\n",
        "hw_model = ExponentialSmoothing(\n",
        "    train_df[\"load\"],\n",
        "    trend=\"add\",\n",
        "    seasonal=\"add\",\n",
        "    seasonal_periods=seasonal_period,\n",
        ")\n",
        "hw_fit = hw_model.fit(optimized=True)\n",
        "hw_forecast = hw_fit.forecast(steps=len(test_df))\n",
        "\n",
        "print(\"Holt\u2013Winters RMSE:  \", rmse(y_test, hw_forecast.to_numpy()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. SARIMAX with exogenous temperature\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def fit_sarimax(train: pd.DataFrame, test: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"Fit SARIMAX on Spanish load with optional temperature.\"\"\"\n",
        "    endog_train = train[\"load\"].astype(float)\n",
        "    exog_cols: List[str] = []\n",
        "    if train[\"temperature\"].notna().any():\n",
        "        exog_cols = [\"temperature\"]\n",
        "    exog_train = train[exog_cols] if exog_cols else None\n",
        "    exog_test = test[exog_cols] if exog_cols else None\n",
        "\n",
        "    model = SARIMAX(\n",
        "        endog_train,\n",
        "        exog=exog_train,\n",
        "        order=(1, 0, 2),\n",
        "        seasonal_order=(1, 1, 1, 24),\n",
        "        enforce_stationarity=False,\n",
        "        enforce_invertibility=False,\n",
        "    )\n",
        "    res = model.fit(disp=False)\n",
        "    fitted = res.fittedvalues.to_numpy()\n",
        "    forecast = res.forecast(steps=len(test), exog=exog_test).to_numpy()\n",
        "    return fitted, forecast\n",
        "\n",
        "\n",
        "sarimax_fitted, sarimax_forecast = fit_sarimax(train_df, test_df)\n",
        "\n",
        "print(\"SARIMAX train RMSE:\", rmse(train_df[\"load\"].to_numpy(), sarimax_fitted))\n",
        "print(\"SARIMAX test RMSE: \", rmse(test_df[\"load\"].to_numpy(), sarimax_forecast))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Lagged feature matrix (load + temperature + calendar)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def make_lagged_features(df_in: pd.DataFrame, n_lags: int = 24) -> pd.DataFrame:\n",
        "    \"\"\"Create lag, calendar and temperature features for ML models.\"\"\"\n",
        "    df_feat = df_in.copy()\n",
        "    for lag in range(1, n_lags + 1):\n",
        "        df_feat[f\"lag_{lag}\"] = df_feat[\"load\"].shift(lag)\n",
        "    df_feat[\"hour\"] = df_feat.index.hour\n",
        "    df_feat[\"dayofweek\"] = df_feat.index.dayofweek\n",
        "    if df_feat[\"temperature\"].notna().any():\n",
        "        df_feat[\"temperature\"] = df_feat[\"temperature\"].interpolate(limit_direction=\"both\")\n",
        "    return df_feat.dropna()\n",
        "\n",
        "\n",
        "lagged_df = make_lagged_features(df, n_lags=24)\n",
        "lagged_train = lagged_df.loc[train_df.index.intersection(lagged_df.index)]\n",
        "lagged_test = lagged_df.loc[test_df.index.intersection(lagged_df.index)]\n",
        "\n",
        "feature_cols = [c for c in lagged_train.columns if c != \"load\"]\n",
        "X_train = lagged_train[feature_cols].to_numpy()\n",
        "y_train_lag = lagged_train[\"load\"].to_numpy()\n",
        "X_test = lagged_test[feature_cols].to_numpy()\n",
        "y_test_lag = lagged_test[\"load\"].to_numpy()\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. ML models on lagged features\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Linear Regression\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train, y_train_lag)\n",
        "y_pred_lin = lin_reg.predict(X_test)\n",
        "\n",
        "print(\"LinearReg RMSE:\", rmse(y_test_lag, y_pred_lin))\n",
        "print(\"LinearReg MAE: \", mean_absolute_error(y_test_lag, y_pred_lin))\n",
        "print(\"LinearReg MAPE:\", mape(y_test_lag, y_pred_lin))\n",
        "\n",
        "# Random Forest\n",
        "rf_model = RandomForestRegressor(\n",
        "    n_estimators=300,\n",
        "    max_depth=None,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    n_jobs=-1,\n",
        "    random_state=RANDOM_STATE,\n",
        ")\n",
        "rf_model.fit(X_train, y_train_lag)\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "print(\"RandomForest RMSE:\", rmse(y_test_lag, y_pred_rf))\n",
        "print(\"RandomForest MAE: \", mean_absolute_error(y_test_lag, y_pred_rf))\n",
        "print(\"RandomForest MAPE:\", mape(y_test_lag, y_pred_rf))\n",
        "\n",
        "# HistGradientBoosting\n",
        "hgb_model = HistGradientBoostingRegressor(\n",
        "    learning_rate=0.05,\n",
        "    max_depth=7,\n",
        "    max_iter=300,\n",
        "    random_state=RANDOM_STATE,\n",
        ")\n",
        "hgb_model.fit(X_train, y_train_lag)\n",
        "y_pred_hgb = hgb_model.predict(X_test)\n",
        "\n",
        "print(\"HistGB RMSE:\", rmse(y_test_lag, y_pred_hgb))\n",
        "print(\"HistGB MAE: \", mean_absolute_error(y_test_lag, y_pred_hgb))\n",
        "print(\"HistGB MAPE:\", mape(y_test_lag, y_pred_hgb))\n",
        "\n",
        "# GradientBoostingRegressor\n",
        "gbr_model = GradientBoostingRegressor(\n",
        "    random_state=RANDOM_STATE,\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=3,\n",
        ")\n",
        "gbr_model.fit(X_train, y_train_lag)\n",
        "y_pred_gbr = gbr_model.predict(X_test)\n",
        "\n",
        "print(\"GBR RMSE:\", rmse(y_test_lag, y_pred_gbr))\n",
        "print(\"GBR MAE: \", mean_absolute_error(y_test_lag, y_pred_gbr))\n",
        "print(\"GBR MAPE:\", mape(y_test_lag, y_pred_gbr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Extended champion\u2013challenger table\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "common_index = test_df.index.intersection(lagged_test.index)\n",
        "y_true_common = test_df.loc[common_index, \"load\"].to_numpy()\n",
        "\n",
        "def as_series(pred: np.ndarray, index: pd.Index) -> pd.Series:\n",
        "    return pd.Series(pred, index=index)\n",
        "\n",
        "# Baselines and classical models on test_df.index\n",
        "naive_series = as_series(naive_forecast, test_df.index).loc[common_index].to_numpy()\n",
        "seasonal_naive_series = as_series(seasonal_naive_forecast, test_df.index).loc[common_index].to_numpy()\n",
        "hw_series = as_series(hw_forecast.to_numpy(), test_df.index).loc[common_index].to_numpy()\n",
        "sarimax_series = as_series(sarimax_forecast, test_df.index).loc[common_index].to_numpy()\n",
        "\n",
        "# ML models on lagged_test.index\n",
        "gbr_series = as_series(y_pred_gbr, lagged_test.index).loc[common_index].to_numpy()\n",
        "lin_series = as_series(y_pred_lin, lagged_test.index).loc[common_index].to_numpy()\n",
        "rf_series = as_series(y_pred_rf, lagged_test.index).loc[common_index].to_numpy()\n",
        "hgb_series = as_series(y_pred_hgb, lagged_test.index).loc[common_index].to_numpy()\n",
        "\n",
        "rows: List[Dict[str, float | str]] = []\n",
        "\n",
        "def add_metrics(name: str, y_true: np.ndarray, y_pred: np.ndarray) -> None:\n",
        "    rows.append(\n",
        "        {\n",
        "            \"model\": name,\n",
        "            \"rmse\": rmse(y_true, y_pred),\n",
        "            \"mae\": mean_absolute_error(y_true, y_pred),\n",
        "            \"mape\": mape(y_true, y_pred),\n",
        "        }\n",
        "    )\n",
        "\n",
        "add_metrics(\"NaiveLast\",        y_true_common, naive_series)\n",
        "add_metrics(\"SeasonalNaive_24\", y_true_common, seasonal_naive_series)\n",
        "add_metrics(\"HoltWinters\",      y_true_common, hw_series)\n",
        "add_metrics(\"SARIMAX\",          y_true_common, sarimax_series)\n",
        "add_metrics(\"GBR\",              y_true_common, gbr_series)\n",
        "add_metrics(\"LinearReg\",        y_true_common, lin_series)\n",
        "add_metrics(\"RandomForest\",     y_true_common, rf_series)\n",
        "add_metrics(\"HistGB\",           y_true_common, hgb_series)\n",
        "\n",
        "champion_df = pd.DataFrame(rows).set_index(\"model\").sort_values(\"rmse\")\n",
        "champion_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "champion_df[\"rmse\"].plot(kind=\"bar\")\n",
        "plt.title(\"Spanish load \u2013 extended champion\u2013challenger (RMSE, lower is better)\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}