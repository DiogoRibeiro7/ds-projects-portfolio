{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e790d3a",
   "metadata": {},
   "source": [
    "\n",
    "# E‑commerce A/B Testing Playbook — New vs Old Landing Page\n",
    "\n",
    "This notebook walks through a **complete analysis** of an A/B test from an e‑commerce website.\n",
    "The company experimented with a **new landing page** and wants to know whether to:\n",
    "\n",
    "- ship the new page,\n",
    "- keep the old page,\n",
    "- or keep testing because results are still too uncertain.\n",
    "\n",
    "All narration is in **English**, and the notebook is meant to be run end‑to‑end.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc18f3a",
   "metadata": {},
   "source": [
    "\n",
    "## 0) Data and context\n",
    "\n",
    "We will use the widely known **Udacity e‑commerce A/B test dataset** (`ab_data.csv`), which appears in many\n",
    "tutorials and Kaggle projects.\n",
    "\n",
    "Typical structure:\n",
    "\n",
    "- `user_id` — unique visitor ID (integer).  \n",
    "- `timestamp` — time of page view.  \n",
    "- `group` — `\"control\"` or `\"treatment\"`.  \n",
    "- `landing_page` — `\"old_page\"` or `\"new_page\"`.  \n",
    "- `converted` — 1 if the visitor converted (paid), 0 otherwise.\n",
    "\n",
    "Optionally, there is a `countries.csv` file with:\n",
    "\n",
    "- `user_id`, `country` ∈ { `\"US\"`, `\"CA\"`, `\"UK\"` }.\n",
    "\n",
    "> **Goal:** quantify the impact of the new page on **conversion rate**, explore **heterogeneity by country**,\n",
    "> and provide a **decision recommendation** using both frequentist and Bayesian perspectives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7160aa29",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Setup\n",
    "\n",
    "We use `numpy`, `pandas`, `matplotlib` and a few simple helper functions for proportions and tests.\n",
    "For part of the analysis we also use `statsmodels` for logistic regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76d1904",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (7, 4.5)\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "\n",
    "# Optional: used for GLM (logit)\n",
    "try:\n",
    "    import statsmodels.api as sm  # type: ignore\n",
    "except Exception as e:  # pragma: no cover\n",
    "    sm = None\n",
    "    print(\"statsmodels not available; GLM cells will be skipped.\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1e7057",
   "metadata": {},
   "source": [
    "\n",
    "### 1.1 Helper functions (proportions, z-test, CIs, power)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c361da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass(frozen=True)\n",
    "class PropSummary:\n",
    "    \"\"\"Summary of a Bernoulli proportion.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    p : float\n",
    "        Sample proportion \\(x / n\\).\n",
    "    n : int\n",
    "        Sample size.\n",
    "    x : int\n",
    "        Number of successes.\n",
    "    \"\"\"\n",
    "    p: float\n",
    "    n: int\n",
    "    x: int\n",
    "\n",
    "\n",
    "def summarize_prop(x: int, n: int) -> PropSummary:\n",
    "    \"\"\"Validate and summarize a proportion sample.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : int\n",
    "        Number of successes (must be in [0, n]).\n",
    "    n : int\n",
    "        Total sample size (must be positive).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    PropSummary\n",
    "        Dataclass with p, n, x.\n",
    "    \"\"\"\n",
    "    if n <= 0:\n",
    "        raise ValueError(\"n must be positive.\")\n",
    "    if not (0 <= x <= n):\n",
    "        raise ValueError(\"x must satisfy 0 <= x <= n.\")\n",
    "    return PropSummary(p=x / n, n=n, x=x)\n",
    "\n",
    "\n",
    "def invPhi(u: float) -> float:\n",
    "    \"\"\"Inverse standard normal CDF using erfcinv.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    u : float\n",
    "        Probability in (0, 1).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        z such that Phi(z) = u.\n",
    "    \"\"\"\n",
    "    if not 0.0 < u < 1.0:\n",
    "        raise ValueError(\"u must be in (0,1).\")\n",
    "    return math.sqrt(2.0) * math.erfcinv(2.0 * (1.0 - u))\n",
    "\n",
    "\n",
    "def two_prop_ztest(\n",
    "    x1: int,\n",
    "    n1: int,\n",
    "    x2: int,\n",
    "    n2: int,\n",
    "    two_sided: bool = True,\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"Two-sample z-test for proportions with pooled variance.\n",
    "\n",
    "    Tests H0: p1 = p2 vs H1: p1 != p2 (two-sided by default).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x1, n1, x2, n2 : int\n",
    "        Success counts and sample sizes for groups 1 and 2.\n",
    "    two_sided : bool\n",
    "        If True, compute a two-sided p-value. If False, right-sided (p2 > p1).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    z : float\n",
    "        z-statistic (signed).\n",
    "    p_value : float\n",
    "        Corresponding p-value.\n",
    "    \"\"\"\n",
    "    s1, s2 = summarize_prop(x1, n1), summarize_prop(x2, n2)\n",
    "    p_pool = (s1.x + s2.x) / (s1.n + s2.n)\n",
    "    se = math.sqrt(p_pool * (1.0 - p_pool) * (1.0 / s1.n + 1.0 / s2.n))\n",
    "    if se == 0.0:\n",
    "        raise ZeroDivisionError(\"Standard error is zero; check inputs.\")\n",
    "    z = (s2.p - s1.p) / se\n",
    "    # standard normal tail via erf\n",
    "    if two_sided:\n",
    "        p = 2.0 * (1.0 - 0.5 * (1.0 + math.erf(abs(z) / math.sqrt(2.0))))\n",
    "    else:\n",
    "        p = 1.0 - 0.5 * (1.0 + math.erf(z / math.sqrt(2.0)))\n",
    "    return float(z), float(p)\n",
    "\n",
    "\n",
    "def chisq_srm(nA: int, nB: int) -> float:\n",
    "    \"\"\"Chi-square SRM (sample ratio mismatch) test for a 50/50 split.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nA, nB : int\n",
    "        Sample sizes for arms A and B.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Approximate two-sided p-value for chi-square(1) test.\n",
    "    \"\"\"\n",
    "    n = nA + nB\n",
    "    exp = [n / 2.0, n / 2.0]\n",
    "    obs = [nA, nB]\n",
    "    chi2 = sum((o - e) ** 2 / e for o, e in zip(obs, exp))\n",
    "    # Approximate tail via normal on sqrt(chi2)\n",
    "    z = math.sqrt(chi2)\n",
    "    p = 2.0 * (1.0 - 0.5 * (1.0 + math.erf(z / math.sqrt(2.0))))\n",
    "    return float(p)\n",
    "\n",
    "\n",
    "def mde_for_n(\n",
    "    p_baseline: float,\n",
    "    n_per_arm: int,\n",
    "    alpha: float = 0.05,\n",
    "    power: float = 0.8,\n",
    "    two_sided: bool = True,\n",
    ") -> float:\n",
    "    \"\"\"Compute absolute MDE for a given baseline and sample size per arm.\n",
    "\n",
    "    Uses normal approximation for two-sample proportion test.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    p_baseline : float\n",
    "        Baseline conversion rate (between 0 and 1).\n",
    "    n_per_arm : int\n",
    "        Sample size per arm.\n",
    "    alpha : float\n",
    "        Significance level.\n",
    "    power : float\n",
    "        Desired power (1 - beta).\n",
    "    two_sided : bool\n",
    "        If True, uses two-sided z_{alpha/2}.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Approximate minimal detectable effect (absolute difference in p).\n",
    "    \"\"\"\n",
    "    if not 0.0 < p_baseline < 1.0:\n",
    "        raise ValueError(\"p_baseline must be in (0,1).\")\n",
    "    if n_per_arm <= 0:\n",
    "        raise ValueError(\"n_per_arm must be positive.\")\n",
    "\n",
    "    z_alpha = abs(invPhi(1.0 - alpha / 2.0)) if two_sided else abs(invPhi(1.0 - alpha))\n",
    "    z_beta = abs(invPhi(power))\n",
    "    se = math.sqrt(2.0 * p_baseline * (1.0 - p_baseline))\n",
    "    return float((z_alpha + z_beta) * se / math.sqrt(n_per_arm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2786199f",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Load and clean the e‑commerce A/B dataset\n",
    "\n",
    "You need the classic `ab_data.csv` file in the working directory.\n",
    "\n",
    "> If you do not have it yet, you can download it from:\n",
    "> - Udacity's Data Analyst Nanodegree project, or\n",
    "> - Multiple Kaggle notebooks that mirror the same CSV.\n",
    "\n",
    "We will:\n",
    "\n",
    "1. Read the CSV.  \n",
    "2. Remove rows where **group** and **landing_page** do not match (data issue in the original file).  \n",
    "3. Drop duplicate `user_id` rows.  \n",
    "4. Confirm the group labels and page labels are as expected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140608cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path(\"ab_data.csv\")\n",
    "\n",
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        \"ab_data.csv not found in the current directory.\n",
    "\"\n",
    "        \"Place the Udacity e-commerce A/B dataset here and re-run this cell.\"\n",
    "    )\n",
    "\n",
    "df_raw = pd.read_csv(DATA_PATH)\n",
    "df_raw.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95865bd8",
   "metadata": {},
   "source": [
    "\n",
    "### 2.1 Data cleaning and SRM\n",
    "\n",
    "We keep only rows where:\n",
    "\n",
    "- `control` users see the `old_page`, and  \n",
    "- `treatment` users see the `new_page`.\n",
    "\n",
    "Then we check for duplicate users and run an **SRM test** on the group sizes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd4e340",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df_raw.copy()\n",
    "\n",
    "# Filter valid combinations: control-old_page, treatment-new_page\n",
    "mask_valid = (\n",
    "    ((df[\"group\"] == \"control\") & (df[\"landing_page\"] == \"old_page\"))\n",
    "    | ((df[\"group\"] == \"treatment\") & (df[\"landing_page\"] == \"new_page\"))\n",
    ")\n",
    "df = df.loc[mask_valid].copy()\n",
    "\n",
    "# Drop duplicate user_id if any (keep first occurrence)\n",
    "df = df.drop_duplicates(subset=[\"user_id\"], keep=\"first\").reset_index(drop=True)\n",
    "\n",
    "# Basic checks\n",
    "print(\"Unique groups:\", df[\"group\"].unique())\n",
    "print(\"Unique landing_page:\", df[\"landing_page\"].unique())\n",
    "\n",
    "n_control = (df[\"group\"] == \"control\").sum()\n",
    "n_treat = (df[\"group\"] == \"treatment\").sum()\n",
    "p_srm = chisq_srm(n_control, n_treat)\n",
    "\n",
    "n_control, n_treat, p_srm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e8ff6b",
   "metadata": {},
   "source": [
    "\n",
    "**Reading SRM.**\n",
    "\n",
    "- If the SRM p-value is very small (e.g., < 0.01), the 50/50 split may be compromised (bug in randomization or logging).  \n",
    "- For this dataset, the split is typically close to 50/50 and SRM is not a concern.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5724e10",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Primary metric: conversion rate (frequentist view)\n",
    "\n",
    "Our primary metric is the **conversion rate**:\n",
    "\n",
    "\\[\n",
    "\\text{CR} = \\mathbb{P}(\\text{converted} = 1).\n",
    "\\]\n",
    "\n",
    "We compare `control` (old page) vs `treatment` (new page) using:\n",
    "\n",
    "- A **two-proportion z-test**.  \n",
    "- A **normal-approximation CI** around the difference in conversion rates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34efdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Aggregate conversions by group\n",
    "conv_summary = (\n",
    "    df.groupby(\"group\")[\"converted\"]\n",
    "    .agg([\"sum\", \"count\", \"mean\"])\n",
    "    .rename(columns={\"sum\": \"x\", \"count\": \"n\", \"mean\": \"rate\"})\n",
    ")\n",
    "conv_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d046c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract A (control) and B (treatment)\n",
    "xA = int(conv_summary.loc[\"control\", \"x\"])\n",
    "nA = int(conv_summary.loc[\"control\", \"n\"])\n",
    "xB = int(conv_summary.loc[\"treatment\", \"x\"])\n",
    "nB = int(conv_summary.loc[\"treatment\", \"n\"])\n",
    "\n",
    "sA = summarize_prop(xA, nA)\n",
    "sB = summarize_prop(xB, nB)\n",
    "\n",
    "z, p = two_prop_ztest(xA, nA, xB, nB, two_sided=True)\n",
    "\n",
    "# Normal-approximation CI for the difference (B - A)\n",
    "diff = sB.p - sA.p\n",
    "alpha = 0.05\n",
    "z_alpha = abs(invPhi(1.0 - alpha / 2.0))\n",
    "se_diff = math.sqrt(\n",
    "    (sA.p * (1.0 - sA.p)) / sA.n + (sB.p * (1.0 - sB.p)) / sB.n\n",
    ")\n",
    "ci_lo = diff - z_alpha * se_diff\n",
    "ci_hi = diff + z_alpha * se_diff\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"arm\": [\"control\", \"treatment\"],\n",
    "        \"n\": [sA.n, sB.n],\n",
    "        \"x\": [sA.x, sB.x],\n",
    "        \"rate\": [sA.p, sB.p],\n",
    "        \"diff_B_minus_A\": [diff, diff],\n",
    "        \"diff_CI95_lo\": [ci_lo, ci_lo],\n",
    "        \"diff_CI95_hi\": [ci_hi, ci_hi],\n",
    "        \"z_stat\": [z, z],\n",
    "        \"p_value\": [p, p],\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bbdfbe",
   "metadata": {},
   "source": [
    "\n",
    "**Interpretation.**\n",
    "\n",
    "- The difference column (`diff_B_minus_A`) shows the **absolute lift** in conversion rate of the new page vs the old page.  \n",
    "- The 95% CI tells us which lifts are compatible with the data under the normal approximation.  \n",
    "- The p-value is the usual frequentist test of H0: *no difference* vs H1: *some difference*.\n",
    "\n",
    "Next we cross‑check this with a **logistic regression** that can include **country** as a covariate if we have that file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146ddc40",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Logistic regression with country (if available)\n",
    "\n",
    "If `countries.csv` is present, we will:\n",
    "\n",
    "1. Merge it on `user_id`.  \n",
    "2. Fit a logistic regression of `converted ~ treatment + country`.  \n",
    "3. Interpret the coefficient on the `treatment` indicator and country interactions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b47a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "countries_path = Path(\"countries.csv\")\n",
    "if countries_path.exists():\n",
    "    countries = pd.read_csv(countries_path)\n",
    "    df_merged = df.merge(countries, on=\"user_id\", how=\"left\")\n",
    "    print(df_merged[\"country\"].value_counts(dropna=False))\n",
    "else:\n",
    "    df_merged = df.copy()\n",
    "    df_merged[\"country\"] = \"UNKNOWN\"\n",
    "    print(\"countries.csv not found; using a single dummy country 'UNKNOWN'.\")\n",
    "\n",
    "df_merged.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2115e431",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if sm is None:\n",
    "    print(\"statsmodels not available; skipping logistic regression.\")\n",
    "else:\n",
    "    # Build design matrix\n",
    "    df_glm = df_merged.copy()\n",
    "    df_glm[\"treatment\"] = (df_glm[\"group\"] == \"treatment\").astype(int)\n",
    "    # One-hot encode country, drop first to avoid collinearity\n",
    "    X = pd.get_dummies(df_glm[[\"treatment\", \"country\"]], drop_first=True).astype(float)\n",
    "    X = sm.add_constant(X)\n",
    "    y = df_glm[\"converted\"].astype(int)\n",
    "\n",
    "    logit_model = sm.Logit(y, X).fit(disp=False)\n",
    "    logit_model.summary2().tables[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7bd507",
   "metadata": {},
   "source": [
    "\n",
    "**Reading the logistic regression.**\n",
    "\n",
    "- The coefficient on `treatment` (in log-odds) indicates the **direction** and strength of the new page effect.  \n",
    "- If you have multiple countries, the country dummies capture **baseline differences** across markets.  \n",
    "- You can also add interaction terms (e.g., `treatment × country`) to explore **heterogeneous effects**.\n",
    "\n",
    "Next we complement the frequentist view with a **Bayesian Beta–Binomial** analysis of conversion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d09558d",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Bayesian A/B — Beta–Binomial model\n",
    "\n",
    "For conversion data, a natural Bayesian model is:\n",
    "\n",
    "- Likelihood: \\(X_A \\sim \\text{Binomial}(n_A, p_A)\\), \\(X_B \\sim \\text{Binomial}(n_B, p_B)\\).  \n",
    "- Prior: \\(p_A, p_B \\sim \\text{Beta}(1,1)\\) (uniform).\n",
    "\n",
    "Conjugacy gives posteriors:\n",
    "\n",
    "\\[\n",
    "p_A \\mid \\text{data} \\sim \\text{Beta}(1 + x_A, 1 + n_A - x_A),\\\\\n",
    "p_B \\mid \\text{data} \\sim \\text{Beta}(1 + x_B, 1 + n_B - x_B).\n",
    "\\]\n",
    "\n",
    "We can sample from these posteriors to estimate quantities like:\n",
    "\n",
    "- \\(\\mathbb{P}(p_B > p_A \\mid \\text{data})\\)  \n",
    "- Distribution of the **lift** \\(p_B - p_A\\).  \n",
    "- Risk metrics (probability that the lift is below a threshold, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f9619a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def beta_posterior_params(x: int, n: int, a_prior: float = 1.0, b_prior: float = 1.0) -> Tuple[float, float]:\n",
    "    \"\"\"Posterior Beta parameters for a Binomial count with Beta(a_prior, b_prior) prior.\"\"\"\n",
    "    if n < 0 or x < 0:\n",
    "        raise ValueError(\"x and n must be non-negative.\")\n",
    "    if x > n:\n",
    "        raise ValueError(\"x must be <= n.\")\n",
    "    return a_prior + x, b_prior + (n - x)\n",
    "\n",
    "\n",
    "def sample_posterior_lift(\n",
    "    xA: int,\n",
    "    nA: int,\n",
    "    xB: int,\n",
    "    nB: int,\n",
    "    n_draws: int = 100000,\n",
    "    seed: int | None = 123,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Sample from the Beta posteriors for pA and pB and compute lifts.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xA, nA, xB, nB : int\n",
    "        Success counts and sample sizes for A and B.\n",
    "    n_draws : int\n",
    "        Number of Monte Carlo draws.\n",
    "    seed : int | None\n",
    "        Random seed for reproducibility.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        Columns: pA, pB, lift (pB - pA).\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    aA, bA = beta_posterior_params(xA, nA)\n",
    "    aB, bB = beta_posterior_params(xB, nB)\n",
    "\n",
    "    pA_draws = rng.beta(aA, bA, size=n_draws)\n",
    "    pB_draws = rng.beta(aB, bB, size=n_draws)\n",
    "    lift = pB_draws - pA_draws\n",
    "\n",
    "    return pd.DataFrame({\"pA\": pA_draws, \"pB\": pB_draws, \"lift\": lift})\n",
    "\n",
    "\n",
    "post_samples = sample_posterior_lift(xA, nA, xB, nB, n_draws=50000, seed=42)\n",
    "post_samples.describe(percentiles=[0.025, 0.5, 0.975])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eed064a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Posterior probability that new page is better\n",
    "prob_B_better = float((post_samples[\"lift\"] > 0).mean())\n",
    "\n",
    "# 95% credible interval for lift\n",
    "ci_lo_bayes, ci_hi_bayes = np.quantile(post_samples[\"lift\"], [0.025, 0.975])\n",
    "\n",
    "# Plot posterior lift distribution\n",
    "plt.figure()\n",
    "plt.hist(post_samples[\"lift\"], bins=60, density=True)\n",
    "plt.axvline(0.0, linestyle=\"--\")\n",
    "plt.title(\"Posterior distribution of lift (p_B - p_A)\")\n",
    "plt.xlabel(\"lift\")\n",
    "plt.ylabel(\"density\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "{\n",
    "    \"posterior_prob_new_better\": prob_B_better,\n",
    "    \"lift_cred_int_95\": (ci_lo_bayes, ci_hi_bayes),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2415c9",
   "metadata": {},
   "source": [
    "\n",
    "**Bayesian reading.**\n",
    "\n",
    "- `posterior_prob_new_better` is \\(\\mathbb{P}(p_B > p_A \\mid \\text{data})\\).  \n",
    "- The **credible interval** on the lift can be directly interpreted as:\n",
    "  “given data and prior, there is 95% probability the true lift lies in this interval”.  \n",
    "- This view is often easier to communicate to non‑statisticians than p-values.\n",
    "\n",
    "Next we connect the statistical results to **business impact**, using a simple revenue model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cadcfa3",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Business framing: revenue and decision rule\n",
    "\n",
    "Assume:\n",
    "\n",
    "- Average **revenue per conversion**: `rev_per_conv`.  \n",
    "- Number of users exposed per day: `users_per_day`.  \n",
    "- Horizon of interest: `H` days.  \n",
    "\n",
    "If we ship the new page, the expected **incremental revenue** over horizon H is roughly:\n",
    "\n",
    "\\[\n",
    "\\Delta R \\approx H \\cdot \\text{users_per_day} \\cdot \\mathbb{E}[p_B - p_A].\n",
    "\\]\n",
    "\n",
    "We can compute this under the **Bayesian posterior** as the mean of the sampled lifts.\n",
    "We also look at **downside risk** (e.g., probability the lift is negative).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d0b9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simple business parameters (edit as needed)\n",
    "rev_per_conv = 50.0      # revenue per conversion in your currency\n",
    "users_per_day = 20000    # daily traffic eligible for the test\n",
    "H = 30                   # horizon in days\n",
    "\n",
    "mean_lift = float(post_samples[\"lift\"].mean())\n",
    "prob_lift_negative = float((post_samples[\"lift\"] < 0).mean())\n",
    "\n",
    "# Expected incremental revenue over horizon H\n",
    "delta_R = H * users_per_day * mean_lift * rev_per_conv\n",
    "\n",
    "{\n",
    "    \"mean_lift\": mean_lift,\n",
    "    \"prob_lift_negative\": prob_lift_negative,\n",
    "    \"expected_delta_revenue_H\": delta_R,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e0aafc",
   "metadata": {},
   "source": [
    "\n",
    "**Decision sketch.**\n",
    "\n",
    "You could define a decision rule such as:\n",
    "\n",
    "- **Ship new page** if\n",
    "  - posterior_prob_new_better > 0.95, and  \n",
    "  - expected_delta_revenue_H is significantly positive, and  \n",
    "  - downside risk (probability of negative lift) is below some tolerance (say < 0.1).\n",
    "\n",
    "Otherwise you **hold** (or keep testing) until uncertainty shrinks or the effect becomes clearer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ed8edc",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Power and MDE recap\n",
    "\n",
    "Finally, we sanity‑check whether the test is able to detect **business‑relevant** effects.\n",
    "\n",
    "We use the baseline conversion rate of the control group and the realized sample size per arm\n",
    "to compute the **MDE** at 80% power and 5% two‑sided alpha.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2041f6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p_baseline = sA.p  # control conversion rate\n",
    "n_per_arm = min(sA.n, sB.n)\n",
    "mde_80 = mde_for_n(p_baseline, n_per_arm, alpha=0.05, power=0.8, two_sided=True)\n",
    "\n",
    "{\n",
    "    \"baseline_rate_control\": p_baseline,\n",
    "    \"n_per_arm\": n_per_arm,\n",
    "    \"MDE_abs_at_80pct_power\": mde_80,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76a67c1",
   "metadata": {},
   "source": [
    "\n",
    "If the observed posterior lift and frequentist CI are both well **within ±MDE**, the experiment may be\n",
    "**underpowered** to detect the kind of changes you care about. In that case you might:\n",
    "\n",
    "- run the test longer,  \n",
    "- aggregate more traffic, or  \n",
    "- shift to more sensitive proxies (e.g. lead form submissions) if the outcome is truly rare.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c9584a",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Executive summary template\n",
    "\n",
    "Use this structure when writing up the final decision:\n",
    "\n",
    "1. **Sanity checks**\n",
    "   - SRM p-value, data cleaning decisions (invalid rows, duplicates).\n",
    "\n",
    "2. **Main effect**\n",
    "   - Conversion rates for control and treatment.  \n",
    "   - Frequentist difference with 95% CI and p-value.  \n",
    "   - Bayesian posterior probability that new page is better and 95% credible interval.\n",
    "\n",
    "3. **Heterogeneity**\n",
    "   - Any notable differences across countries or segments (if `countries.csv` was available).\n",
    "\n",
    "4. **Business impact**\n",
    "   - Approximate expected incremental revenue over H days.  \n",
    "   - Discussion of downside risk (probability of harm).\n",
    "\n",
    "5. **Decision**\n",
    "   - Ship / hold / roll back and why.  \n",
    "   - If ship: ramp plan (e.g., 25% → 50% → 100%) and monitoring.  \n",
    "   - If hold: what additional data or changes are needed.\n",
    "\n",
    "This keeps the analysis **decision‑oriented** rather than purely statistical.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}