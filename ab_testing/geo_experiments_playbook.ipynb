{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d81134d2",
   "metadata": {},
   "source": [
    "\n",
    "# Geo Experiments for Incrementality Measurement\n",
    "\n",
    "This notebook is a **playbook for geo experiments** (a.k.a. geographic lift tests).\n",
    "\n",
    "Instead of randomizing at the **user** level, we randomize at the **geo / market / region**\n",
    "level (e.g., cities, DMAs, countries) and measure incremental impact on an aggregate KPI.\n",
    "\n",
    "We cover:\n",
    "\n",
    "1. Simulating geo-level time series data (pre and post period).  \n",
    "2. Simple geo **difference-in-differences** (DiD) estimator.  \n",
    "3. Geo-level **regression adjustment** for more power.  \n",
    "4. Basic **power analysis via simulation**.  \n",
    "5. Practical notes on when and how to use geo experiments.\n",
    "\n",
    "All code is typed, documented, and designed to be adapted to your own geo datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c347aa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Dict, Any\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 4.5)\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1) Simulated geo-level panel data\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "@dataclass\n",
    "class GeoSimConfig:\n",
    "    \"\"\"Configuration for simulating a geo experiment panel.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    n_geos : int\n",
    "        Number of geos (clusters).\n",
    "    pre_days : int\n",
    "        Length of the pre period in days.\n",
    "    post_days : int\n",
    "        Length of the post period in days.\n",
    "    baseline_mean : float\n",
    "        Average baseline KPI per geo per day.\n",
    "    baseline_geo_sd : float\n",
    "        Standard deviation for geo-level baseline heterogeneity.\n",
    "    day_noise_sd : float\n",
    "        Standard deviation for day-to-day noise around each geo's baseline.\n",
    "    treatment_uplift : float\n",
    "        Multiplicative uplift in the post period for treatment geos\n",
    "        (e.g., 0.05 means +5%).\n",
    "    trend_per_day : float\n",
    "        Optional linear time trend (same for all geos).\n",
    "    \"\"\"\n",
    "    n_geos: int = 40\n",
    "    pre_days: int = 28\n",
    "    post_days: int = 14\n",
    "    baseline_mean: float = 1000.0\n",
    "    baseline_geo_sd: float = 400.0\n",
    "    day_noise_sd: float = 250.0\n",
    "    treatment_uplift: float = 0.05\n",
    "    trend_per_day: float = 0.0\n",
    "\n",
    "\n",
    "def simulate_geo_panel(\n",
    "    config: GeoSimConfig,\n",
    "    seed: int | None = 123,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Simulate geo-level daily KPI panel data for a geo experiment.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    config : GeoSimConfig\n",
    "        Simulation configuration.\n",
    "    seed : int | None\n",
    "        Random seed for reproducibility.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        Columns: geo_id, group, day, period, kpi.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    G = config.n_geos\n",
    "    pre_days = config.pre_days\n",
    "    post_days = config.post_days\n",
    "\n",
    "    # Geo-level baselines\n",
    "    geo_ids = np.arange(G)\n",
    "    geo_baseline = rng.normal(\n",
    "        loc=config.baseline_mean,\n",
    "        scale=config.baseline_geo_sd,\n",
    "        size=G,\n",
    "    )\n",
    "\n",
    "    # Assign half of geos to treatment\n",
    "    rng.shuffle(geo_ids)\n",
    "    treat_geos = set(geo_ids[: G // 2])\n",
    "    groups = np.array([\"control\"] * G, dtype=object)\n",
    "    for g in treat_geos:\n",
    "        groups[g] = \"treatment\"\n",
    "\n",
    "    records: list[dict[str, Any]] = []\n",
    "\n",
    "    # Pre period\n",
    "    for t in range(pre_days):\n",
    "        trend_factor = 1.0 + config.trend_per_day * t\n",
    "        for geo in geo_ids:\n",
    "            mu = geo_baseline[geo] * trend_factor\n",
    "            y = rng.normal(loc=mu, scale=config.day_noise_sd)\n",
    "            records.append(\n",
    "                {\n",
    "                    \"geo_id\": int(geo),\n",
    "                    \"group\": str(groups[geo]),\n",
    "                    \"day\": int(t),\n",
    "                    \"period\": \"pre\",\n",
    "                    \"kpi\": float(y),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # Post period\n",
    "    for t in range(pre_days, pre_days + post_days):\n",
    "        trend_factor = 1.0 + config.trend_per_day * t\n",
    "        for geo in geo_ids:\n",
    "            uplift = config.treatment_uplift if groups[geo] == \"treatment\" else 0.0\n",
    "            mu = geo_baseline[geo] * (1.0 + uplift) * trend_factor\n",
    "            y = rng.normal(loc=mu, scale=config.day_noise_sd)\n",
    "            records.append(\n",
    "                {\n",
    "                    \"geo_id\": int(geo),\n",
    "                    \"group\": str(groups[geo]),\n",
    "                    \"day\": int(t),\n",
    "                    \"period\": \"post\",\n",
    "                    \"kpi\": float(y),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    df = pd.DataFrame.from_records(records)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Example config and data\n",
    "config = GeoSimConfig(\n",
    "    n_geos=40,\n",
    "    pre_days=28,\n",
    "    post_days=14,\n",
    "    baseline_mean=1000.0,\n",
    "    baseline_geo_sd=400.0,\n",
    "    day_noise_sd=250.0,\n",
    "    treatment_uplift=0.08,\n",
    "    trend_per_day=0.001,\n",
    ")\n",
    "\n",
    "df = simulate_geo_panel(config)\n",
    "display(df.head())\n",
    "\n",
    "display(\n",
    "    df.groupby([\"group\", \"period\"])[\"kpi\"].agg([\"mean\", \"std\", \"count\"])\n",
    ")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2) Geo-level pre/post aggregation\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "def aggregate_geo_pre_post(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Aggregate daily panel to geo-level pre/post metrics.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Input with columns geo_id, group, period, kpi.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        One row per geo with columns:\n",
    "        - geo_id, group\n",
    "        - kpi_pre_mean, kpi_post_mean\n",
    "        - kpi_pre_total, kpi_post_total\n",
    "        - delta_mean = post_mean - pre_mean\n",
    "        - delta_total = post_total - pre_total\n",
    "    \"\"\"\n",
    "    grp = (\n",
    "        df.groupby([\"geo_id\", \"group\", \"period\"])[\"kpi\"]\n",
    "          .agg([\"mean\", \"sum\", \"count\"])\n",
    "          .rename(columns={\"mean\": \"kpi_mean\", \"sum\": \"kpi_total\"})\n",
    "          .reset_index()\n",
    "    )\n",
    "\n",
    "    pre = grp[grp[\"period\"] == \"pre\"].copy()\n",
    "    post = grp[grp[\"period\"] == \"post\"].copy()\n",
    "\n",
    "    merged = pre.merge(\n",
    "        post,\n",
    "        on=[\"geo_id\", \"group\"],\n",
    "        suffixes=(\"_pre\", \"_post\"),\n",
    "        validate=\"one_to_one\",\n",
    "    )\n",
    "\n",
    "    merged[\"delta_mean\"] = merged[\"kpi_mean_post\"] - merged[\"kpi_mean_pre\"]\n",
    "    merged[\"delta_total\"] = merged[\"kpi_total_post\"] - merged[\"kpi_total_pre\"]\n",
    "\n",
    "    return merged[\n",
    "        [\n",
    "            \"geo_id\",\n",
    "            \"group\",\n",
    "            \"kpi_mean_pre\",\n",
    "            \"kpi_mean_post\",\n",
    "            \"kpi_total_pre\",\n",
    "            \"kpi_total_post\",\n",
    "            \"delta_mean\",\n",
    "            \"delta_total\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "\n",
    "geo_agg = aggregate_geo_pre_post(df)\n",
    "display(geo_agg.head())\n",
    "\n",
    "display(\n",
    "    geo_agg.groupby(\"group\")[\n",
    "        [\"kpi_mean_pre\", \"kpi_mean_post\", \"delta_mean\"]\n",
    "    ].agg([\"mean\", \"std\", \"count\"])\n",
    ")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3) Geo-level DiD estimator\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "@dataclass\n",
    "class DiDResult:\n",
    "    estimate: float\n",
    "    se: float\n",
    "    ci_low: float\n",
    "    ci_high: float\n",
    "    dof: float\n",
    "    p_value: float\n",
    "\n",
    "\n",
    "def two_sample_ttest_from_groups(\n",
    "    x_treat: np.ndarray,\n",
    "    x_ctrl: np.ndarray,\n",
    "    alpha: float = 0.05,\n",
    ") -> DiDResult:\n",
    "    \"\"\"Welch two-sample t-test for difference in means (treat - control).\"\"\"\n",
    "    x_treat = np.asarray(x_treat, dtype=float)\n",
    "    x_ctrl = np.asarray(x_ctrl, dtype=float)\n",
    "\n",
    "    n_t = x_treat.size\n",
    "    n_c = x_ctrl.size\n",
    "\n",
    "    mean_t = float(x_treat.mean())\n",
    "    mean_c = float(x_ctrl.mean())\n",
    "\n",
    "    var_t = float(x_treat.var(ddof=1)) if n_t > 1 else 0.0\n",
    "    var_c = float(x_ctrl.var(ddof=1)) if n_c > 1 else 0.0\n",
    "\n",
    "    se = math.sqrt(var_t / n_t + var_c / n_c) if n_t > 0 and n_c > 0 else float(\"nan\")\n",
    "\n",
    "    num = (var_t / n_t + var_c / n_c) ** 2\n",
    "    den = (var_t ** 2) / (n_t ** 2 * (n_t - 1)) + (var_c ** 2) / (n_c ** 2 * (n_c - 1))\n",
    "    dof = num / den if den > 0 else float(\"nan\")\n",
    "\n",
    "    diff = mean_t - mean_c\n",
    "    t_stat = diff / se if se > 0 else float(\"nan\")\n",
    "\n",
    "    cdf = 0.5 * (1.0 + math.erf(t_stat / math.sqrt(2.0)))\n",
    "    p_two_sided = 2.0 * min(cdf, 1.0 - cdf)\n",
    "\n",
    "    z = 1.96 if abs(dof) > 30 else 1.96\n",
    "    ci_low = diff - z * se\n",
    "    ci_high = diff + z * se\n",
    "\n",
    "    return DiDResult(\n",
    "        estimate=diff,\n",
    "        se=se,\n",
    "        ci_low=ci_low,\n",
    "        ci_high=ci_high,\n",
    "        dof=dof,\n",
    "        p_value=p_two_sided,\n",
    "    )\n",
    "\n",
    "\n",
    "def geo_did_from_agg(\n",
    "    geo_agg: pd.DataFrame,\n",
    "    value_col: str = \"delta_mean\",\n",
    "    alpha: float = 0.05,\n",
    ") -> DiDResult:\n",
    "    \"\"\"Run a geo-level DiD (difference-in-means on per-geo deltas).\"\"\"\n",
    "    treat_vals = geo_agg.loc[geo_agg[\"group\"] == \"treatment\", value_col].to_numpy()\n",
    "    ctrl_vals = geo_agg.loc[geo_agg[\"group\"] == \"control\", value_col].to_numpy()\n",
    "    return two_sample_ttest_from_groups(treat_vals, ctrl_vals, alpha=alpha)\n",
    "\n",
    "\n",
    "did_res = geo_did_from_agg(geo_agg, value_col=\"delta_mean\", alpha=0.05)\n",
    "display(did_res)\n",
    "\n",
    "pre_overall = float(geo_agg[\"kpi_mean_pre\"].mean())\n",
    "rel_uplift = did_res.estimate / pre_overall\n",
    "display({\n",
    "    \"abs_lift\": did_res.estimate,\n",
    "    \"rel_lift\": rel_uplift,\n",
    "    \"ci_rel_low\": did_res.ci_low / pre_overall,\n",
    "    \"ci_rel_high\": did_res.ci_high / pre_overall,\n",
    "})\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 4) Geo-level regression adjustment\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "@dataclass\n",
    "class OLSResult:\n",
    "    coef: np.ndarray\n",
    "    se: np.ndarray\n",
    "    ci_low: np.ndarray\n",
    "    ci_high: np.ndarray\n",
    "\n",
    "\n",
    "def ols_with_intercept(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    alpha: float = 0.05,\n",
    ") -> OLSResult:\n",
    "    \"\"\"Simple OLS with intercept using normal theory.\"\"\"\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    y = np.asarray(y, dtype=float)\n",
    "\n",
    "    n, p = X.shape\n",
    "    X1 = np.column_stack([np.ones(n), X])\n",
    "\n",
    "    XtX = X1.T @ X1\n",
    "    XtX_inv = np.linalg.inv(XtX)\n",
    "    beta_hat = XtX_inv @ (X1.T @ y)\n",
    "\n",
    "    residuals = y - X1 @ beta_hat\n",
    "    dof = n - (p + 1)\n",
    "    sigma2_hat = float((residuals @ residuals) / dof)\n",
    "\n",
    "    cov_beta = sigma2_hat * XtX_inv\n",
    "    se_beta = np.sqrt(np.diag(cov_beta))\n",
    "\n",
    "    z = 1.96 if dof > 30 else 1.96\n",
    "    ci_low = beta_hat - z * se_beta\n",
    "    ci_high = beta_hat + z * se_beta\n",
    "\n",
    "    return OLSResult(\n",
    "        coef=beta_hat,\n",
    "        se=se_beta,\n",
    "        ci_low=ci_low,\n",
    "        ci_high=ci_high,\n",
    "    )\n",
    "\n",
    "\n",
    "def geo_regression_adjustment(\n",
    "    geo_agg: pd.DataFrame,\n",
    "    alpha: float = 0.05,\n",
    ") -> Tuple[OLSResult, Dict[str, Any]]:\n",
    "    \"\"\"Run a simple geo-level regression with pre KPI adjustment.\"\"\"\n",
    "    df = geo_agg.copy()\n",
    "    df[\"treat_flag\"] = (df[\"group\"] == \"treatment\").astype(float)\n",
    "\n",
    "    y = df[\"delta_mean\"].to_numpy()\n",
    "    X = df[[\"treat_flag\", \"kpi_mean_pre\"]].to_numpy()\n",
    "\n",
    "    ols_res = ols_with_intercept(X, y, alpha=alpha)\n",
    "\n",
    "    beta0, beta1, beta2 = ols_res.coef\n",
    "    se0, se1, se2 = ols_res.se\n",
    "    ci1_low, ci1_high = ols_res.ci_low[1], ols_res.ci_high[1]\n",
    "\n",
    "    pre_overall = float(df[\"kpi_mean_pre\"].mean())\n",
    "    rel_lift = beta1 / pre_overall\n",
    "    rel_low = ci1_low / pre_overall\n",
    "    rel_high = ci1_high / pre_overall\n",
    "\n",
    "    info = {\n",
    "        \"beta1_treat_effect\": beta1,\n",
    "        \"beta1_se\": se1,\n",
    "        \"beta1_ci_low\": ci1_low,\n",
    "        \"beta1_ci_high\": ci1_high,\n",
    "        \"rel_lift\": rel_lift,\n",
    "        \"rel_ci_low\": rel_low,\n",
    "        \"rel_ci_high\": rel_high,\n",
    "    }\n",
    "    return ols_res, info\n",
    "\n",
    "\n",
    "ols_res, adj_info = geo_regression_adjustment(geo_agg, alpha=0.05)\n",
    "display(adj_info)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 5) Power analysis via simulation\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "def simulate_geo_power(\n",
    "    config: GeoSimConfig,\n",
    "    n_sims: int = 500,\n",
    "    alpha: float = 0.05,\n",
    "    seed: int | None = 999,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Estimate power of the geo DiD test via simulation.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    rejections = 0\n",
    "    ests: list[float] = []\n",
    "\n",
    "    for _ in range(n_sims):\n",
    "        s = int(rng.integers(0, 1_000_000))\n",
    "        df_sim = simulate_geo_panel(config, seed=s)\n",
    "        geo_agg_sim = aggregate_geo_pre_post(df_sim)\n",
    "        did = geo_did_from_agg(geo_agg_sim, value_col=\"delta_mean\", alpha=alpha)\n",
    "        ests.append(did.estimate)\n",
    "\n",
    "        if did.p_value < alpha:\n",
    "            rejections += 1\n",
    "\n",
    "    power_hat = rejections / n_sims\n",
    "    return {\n",
    "        \"power_hat\": power_hat,\n",
    "        \"mean_estimate\": float(np.mean(ests)),\n",
    "        \"sd_estimate\": float(np.std(ests, ddof=1)),\n",
    "    }\n",
    "\n",
    "\n",
    "power_summary = simulate_geo_power(\n",
    "    config=config,\n",
    "    n_sims=200,\n",
    "    alpha=0.05,\n",
    "    seed=2025,\n",
    ")\n",
    "display(power_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a134dfc5",
   "metadata": {},
   "source": [
    "\n",
    "## Practical notes for real geo experiments\n",
    "\n",
    "1. **Cluster randomization**\n",
    "   - Randomize at the geo level, not at the user level.  \n",
    "   - Make sure treatment and control geos are balanced in terms of baseline KPI and other covariates.\n",
    "\n",
    "2. **Pre-period is crucial**\n",
    "   - Use a sufficiently long pre-period to measure baseline differences.  \n",
    "   - Use pre-period KPI as a covariate (regression) or for matching / stratification.\n",
    "\n",
    "3. **Analysis at the geo level**\n",
    "   - Respect the unit of randomization: geos are the experimental units.  \n",
    "   - Perform inference at the geo level (e.g., t-test on geo-level deltas).\n",
    "\n",
    "4. **Guardrails and multiple metrics**\n",
    "   - You can define geo-level guardrail metrics (e.g., refund rate, visits) and apply\n",
    "     the same multi-metric decision rules as in user-level A/B tests.\n",
    "\n",
    "5. **Extensions**\n",
    "   - More advanced methods include synthetic control or Bayesian hierarchical models\n",
    "     for geo experiments. This notebook stays with simple, transparent estimators that\n",
    "     are often enough for many practical use cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e48758",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Matching / stratified randomization by pre-KPI\n",
    "\n",
    "In real geo experiments you rarely just flip a coin for each geo.\n",
    "\n",
    "A common pattern is **stratified randomization**:\n",
    "\n",
    "1. Use pre-period KPI to build a baseline score per geo.  \n",
    "2. Sort geos by this baseline.  \n",
    "3. Form small blocks (pairs or quadruples).  \n",
    "4. Randomize treatment vs control **within each block**.\n",
    "\n",
    "This keeps treatment and control balanced on past performance.\n",
    "We will implement a simple **pair-matching by pre-KPI** helper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddefa9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Sequence\n",
    "\n",
    "def assign_geos_stratified_by_pre_kpi(\n",
    "    pre_df: pd.DataFrame,\n",
    "    geo_col: str = \"geo_id\",\n",
    "    kpi_col: str = \"kpi_mean_pre\",\n",
    "    rng_seed: int | None = 2024,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Assign treatment/control using stratified randomization on pre KPI.\n",
    "    \n",
    "    Steps:\n",
    "    - Take one row per geo with baseline KPI.\n",
    "    - Sort geos by baseline.\n",
    "    - Form pairs (blocks of size 2).\n",
    "    - Within each pair, randomly assign one to treatment, one to control.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pre_df : DataFrame\n",
    "        Must contain columns [geo_col, kpi_col].\n",
    "    geo_col : str\n",
    "        Name of the geo id column.\n",
    "    kpi_col : str\n",
    "        Column storing the pre-period KPI per geo.\n",
    "    rng_seed : int | None\n",
    "        Random seed for reproducibility.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        With columns [geo_col, 'group'] where group ∈ {'treatment', 'control'}.\n",
    "    \"\"\"\n",
    "    df = pre_df[[geo_col, kpi_col]].drop_duplicates().copy()\n",
    "    df = df.sort_values(kpi_col).reset_index(drop=True)\n",
    "    \n",
    "    rng = np.random.default_rng(rng_seed)\n",
    "    groups: list[str] = [\"\"] * len(df)\n",
    "    \n",
    "    # Pair geos: (0,1), (2,3), ...\n",
    "    for i in range(0, len(df), 2):\n",
    "        block_indices = list(range(i, min(i + 2, len(df))))\n",
    "        # Randomly assign within block\n",
    "        perm = rng.permutation(block_indices)\n",
    "        if len(perm) == 1:\n",
    "            # Odd geo out: assign randomly\n",
    "            groups[perm[0]] = rng.choice([\"treatment\", \"control\"])\n",
    "        else:\n",
    "            groups[perm[0]] = \"treatment\"\n",
    "            groups[perm[1]] = \"control\"\n",
    "    \n",
    "    df[\"group\"] = groups\n",
    "    return df[[geo_col, \"group\"]]\n",
    "\n",
    "\n",
    "# Example: design a stratified assignment using the geo_agg pre means\n",
    "pre_baseline = geo_agg[[\"geo_id\", \"kpi_mean_pre\"]].copy()\n",
    "assignments = assign_geos_stratified_by_pre_kpi(pre_baseline)\n",
    "assignments.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cff13c8",
   "metadata": {},
   "source": [
    "\n",
    "You would use this **before** running the experiment:\n",
    "\n",
    "1. Use historical data to build `kpi_mean_pre` per geo.  \n",
    "2. Call `assign_geos_stratified_by_pre_kpi`.  \n",
    "3. Feed the assigned `group` into your ad server / experiment system.\n",
    "\n",
    "In our simulation, we generated `group` internally, but this section shows how you would\n",
    "design a geo experiment prospectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574c939a",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Synthetic control flavour (per-geo)\n",
    "\n",
    "Synthetic control methods build a **weighted combination of control geos** that mimics\n",
    "the pre-period trajectory of each treated geo.\n",
    "\n",
    "Here we implement a simple flavour:\n",
    "\n",
    "- Let \\(Y^{(T)}_{g,t}\\) be the KPI of treated geo \\(g\\) in the pre period.  \n",
    "- Let \\(C_t\\) be the matrix of control geo KPIs (columns = control geos).  \n",
    "- For each treated geo, we find weights \\(w_g\\) such that:\n",
    "  \\(C w_g \\approx Y^{(T)}_{g}\\) in least-squares sense.  \n",
    "- We then use \\(C_{\\text{post}} w_g\\) as a **synthetic control series** in the post period.\n",
    "\n",
    "This is not a full constrained synthetic control (e.g. non-negative weights,\n",
    "sum-to-one), but a readable starting point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a731552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_synthetic_control_weights(\n",
    "    df: pd.DataFrame,\n",
    "    treated_geo: int,\n",
    "    period_pre: str = \"pre\",\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Compute synthetic control weights for one treated geo using OLS.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Panel with columns [geo_id, group, period, day, kpi].\n",
    "    treated_geo : int\n",
    "        Geo id of the treated geo.\n",
    "    period_pre : str\n",
    "        Label for the pre period.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    (weights, ctrl_geos, days_pre)\n",
    "        weights: np.ndarray of shape (n_ctrl,)\n",
    "        ctrl_geos: np.ndarray of control geo ids\n",
    "        days_pre: np.ndarray of day indices used in the fit\n",
    "    \"\"\"\n",
    "    # Pre-period data\n",
    "    pre = df[df[\"period\"] == period_pre].copy()\n",
    "    \n",
    "    # Identify control geos\n",
    "    ctrl_geos = (\n",
    "        pre.loc[pre[\"group\"] == \"control\", \"geo_id\"]\n",
    "        .drop_duplicates()\n",
    "        .to_numpy()\n",
    "    )\n",
    "    \n",
    "    # Treated geo series\n",
    "    y_pre = (\n",
    "        pre.loc[pre[\"geo_id\"] == treated_geo]\n",
    "        .sort_values(\"day\")[\"kpi\"]\n",
    "        .to_numpy()\n",
    "    )\n",
    "    days_pre = (\n",
    "        pre.loc[pre[\"geo_id\"] == treated_geo]\n",
    "        .sort_values(\"day\")[\"day\"]\n",
    "        .to_numpy()\n",
    "    )\n",
    "    \n",
    "    # Control matrix: for each control geo, align on same days\n",
    "    ctrl_series = []\n",
    "    for g in ctrl_geos:\n",
    "        s = (\n",
    "            pre.loc[pre[\"geo_id\"] == g]\n",
    "            .sort_values(\"day\")[\"kpi\"]\n",
    "            .to_numpy()\n",
    "        )\n",
    "        ctrl_series.append(s)\n",
    "    C = np.column_stack(ctrl_series)  # shape (T_pre, n_ctrl)\n",
    "    \n",
    "    # OLS: minimize ||C w - y||^2 -> w = (C^T C)^{-1} C^T y\n",
    "    CtC = C.T @ C\n",
    "    CtY = C.T @ y_pre\n",
    "    weights = np.linalg.pinv(CtC) @ CtY  # use pseudoinverse for robustness\n",
    "    \n",
    "    return weights, ctrl_geos, days_pre\n",
    "\n",
    "\n",
    "def synthetic_control_post_series(\n",
    "    df: pd.DataFrame,\n",
    "    weights: np.ndarray,\n",
    "    ctrl_geos: np.ndarray,\n",
    "    period_post: str = \"post\",\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Build synthetic control post-period series for a treated geo.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Panel with columns [geo_id, group, period, day, kpi].\n",
    "    weights : np.ndarray\n",
    "        Weights for each control geo (shape (n_ctrl,)).\n",
    "    ctrl_geos : np.ndarray\n",
    "        Control geo ids corresponding to the weights.\n",
    "    period_post : str\n",
    "        Label for the post period.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    (days_post, y_synth_post)\n",
    "        days_post: day indices for the post period.\n",
    "        y_synth_post: synthetic control KPI series for those days.\n",
    "    \"\"\"\n",
    "    post = df[df[\"period\"] == period_post].copy()\n",
    "    days_post = (\n",
    "        post.loc[post[\"geo_id\"] == int(ctrl_geos[0])]\n",
    "        .sort_values(\"day\")[\"day\"]\n",
    "        .to_numpy()\n",
    "    )\n",
    "    \n",
    "    ctrl_post_series = []\n",
    "    for g in ctrl_geos:\n",
    "        s = (\n",
    "            post.loc[post[\"geo_id\"] == g]\n",
    "            .sort_values(\"day\")[\"kpi\"]\n",
    "            .to_numpy()\n",
    "        )\n",
    "        ctrl_post_series.append(s)\n",
    "    C_post = np.column_stack(ctrl_post_series)  # shape (T_post, n_ctrl)\n",
    "    \n",
    "    y_synth_post = C_post @ weights\n",
    "    return days_post, y_synth_post\n",
    "\n",
    "\n",
    "# Example: synthetic control for the first treated geo\n",
    "treated_geos = (\n",
    "    df.loc[df[\"group\"] == \"treatment\", \"geo_id\"]\n",
    "    .drop_duplicates()\n",
    "    .sort_values()\n",
    "    .to_numpy()\n",
    ")\n",
    "\n",
    "example_treated = int(treated_geos[0])\n",
    "w_sc, ctrl_ids, days_pre = build_synthetic_control_weights(df, treated_geo=example_treated)\n",
    "days_post, y_synth_post = synthetic_control_post_series(df, w_sc, ctrl_ids)\n",
    "\n",
    "# Extract true treated geo post-period series\n",
    "treated_post = (\n",
    "    df[(df[\"geo_id\"] == example_treated) & (df[\"period\"] == \"post\")]\n",
    "    .sort_values(\"day\")\n",
    ")\n",
    "y_treated_post = treated_post[\"kpi\"].to_numpy()\n",
    "days_post_true = treated_post[\"day\"].to_numpy()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(days_post_true, y_treated_post, label=f\"Treated geo {example_treated}\")\n",
    "plt.plot(days_post, y_synth_post, label=\"Synthetic control\", linestyle=\"--\")\n",
    "plt.xlabel(\"day\")\n",
    "plt.ylabel(\"kpi\")\n",
    "plt.title(\"Synthetic control flavour: treated vs synthetic control (post period)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d508a7",
   "metadata": {},
   "source": [
    "\n",
    "This plot gives a **per-geo counterfactual trajectory** suggestion for what would have\n",
    "happened in that treated geo if it had followed a combination of control geos that\n",
    "matches its pre-period behaviour.\n",
    "\n",
    "You can summarize impact as, for example, the **difference in average post-period KPI**\n",
    "between treated and synthetic control for each treated geo, and then aggregate across them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19811953",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Bayesian hierarchical geo model (partial pooling)\n",
    "\n",
    "We can also analyze geo experiments with a simple **Bayesian hierarchical model** that\n",
    "partially pools information across geos.\n",
    "\n",
    "Here we take a lightweight Normal–Normal model on the **per-geo changes**:\n",
    "\n",
    "- For control geos: \\(D_g^{(C)} \\sim \\mathcal{N}(\\mu_C, \\sigma_C^2)\\).  \n",
    "- For treatment geos: \\(D_g^{(T)} \\sim \\mathcal{N}(\\mu_T, \\sigma_T^2)\\).  \n",
    "\n",
    "We place vague Normal priors on the group means:\n",
    "\n",
    "\\[\n",
    "\\mu_C \\sim \\mathcal{N}(m_0, s_0^2), \\quad\n",
    "\\mu_T \\sim \\mathcal{N}(m_0, s_0^2).\n",
    "\\]\n",
    "\n",
    "Given observed \\(D_g\\), the posteriors \\(p(\\mu_C \\mid D)\\) and \\(p(\\mu_T \\mid D)\\)\n",
    "are also Normal (conjugate).\n",
    "\n",
    "We can then derive the posterior for the **lift**:\n",
    "\n",
    "\\[\n",
    "\\Delta = \\mu_T - \\mu_C\n",
    "\\]\n",
    "\n",
    "which is Normal with closed-form mean and variance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a3ef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class BayesGeoPosterior:\n",
    "    mu_t_mean: float\n",
    "    mu_t_sd: float\n",
    "    mu_c_mean: float\n",
    "    mu_c_sd: float\n",
    "    delta_mean: float\n",
    "    delta_sd: float\n",
    "    prob_delta_gt_0: float\n",
    "    ci_low: float\n",
    "    ci_high: float\n",
    "\n",
    "\n",
    "def bayes_geo_hierarchical_normal(\n",
    "    geo_agg: pd.DataFrame,\n",
    "    value_col: str = \"delta_mean\",\n",
    "    prior_mean: float = 0.0,\n",
    "    prior_sd: float = 100.0,\n",
    "    alpha: float = 0.05,\n",
    ") -> BayesGeoPosterior:\n",
    "    \"\"\"Simple Normal–Normal hierarchical model on per-geo changes.\n",
    "\n",
    "    We approximate within-group variance by the sample variance of `value_col`\n",
    "    in treatment and control geos.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    geo_agg : DataFrame\n",
    "        Geo-level aggregated data with columns ['group', value_col].\n",
    "    value_col : str\n",
    "        Column storing per-geo changes (e.g. delta_mean).\n",
    "    prior_mean : float\n",
    "        Prior mean m0 for both group means.\n",
    "    prior_sd : float\n",
    "        Prior standard deviation s0 for both group means.\n",
    "    alpha : float\n",
    "        Credible interval size (1 - alpha).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    BayesGeoPosterior\n",
    "        Posterior summaries for mu_T, mu_C and delta = mu_T - mu_C.\n",
    "    \"\"\"\n",
    "    df = geo_agg[[\"group\", value_col]].copy()\n",
    "\n",
    "    d_t = df.loc[df[\"group\"] == \"treatment\", value_col].to_numpy()\n",
    "    d_c = df.loc[df[\"group\"] == \"control\", value_col].to_numpy()\n",
    "\n",
    "    n_t = d_t.size\n",
    "    n_c = d_c.size\n",
    "\n",
    "    mean_t = float(d_t.mean())\n",
    "    mean_c = float(d_c.mean())\n",
    "\n",
    "    # Plug-in estimates of group variances (treated as known)\n",
    "    var_t = float(d_t.var(ddof=1)) if n_t > 1 else 1.0\n",
    "    var_c = float(d_c.var(ddof=1)) if n_c > 1 else 1.0\n",
    "\n",
    "    s0_sq = prior_sd**2\n",
    "\n",
    "    # Posterior for mu_T: Normal(mn_t, sn_t^2)\n",
    "    sn_t_sq = 1.0 / (1.0 / s0_sq + n_t / var_t)\n",
    "    mn_t = sn_t_sq * (prior_mean / s0_sq + n_t * mean_t / var_t)\n",
    "\n",
    "    # Posterior for mu_C: Normal(mn_c, sn_c^2)\n",
    "    sn_c_sq = 1.0 / (1.0 / s0_sq + n_c / var_c)\n",
    "    mn_c = sn_c_sq * (prior_mean / s0_sq + n_c * mean_c / var_c)\n",
    "\n",
    "    # Delta = mu_T - mu_C ~ Normal(mn_t - mn_c, sn_t^2 + sn_c^2)\n",
    "    delta_mean = mn_t - mn_c\n",
    "    delta_var = sn_t_sq + sn_c_sq\n",
    "    delta_sd = math.sqrt(delta_var)\n",
    "\n",
    "    # Posterior probability that delta > 0\n",
    "    z = delta_mean / delta_sd if delta_sd > 0 else 0.0\n",
    "    cdf = 0.5 * (1.0 + math.erf(z / math.sqrt(2.0)))\n",
    "    prob_delta_gt_0 = cdf\n",
    "\n",
    "    # Symmetric (1 - alpha) credible interval\n",
    "    from scipy.stats import norm  # type: ignore\n",
    "\n",
    "    z_ci = norm.ppf(1.0 - alpha / 2.0)\n",
    "    ci_low = delta_mean - z_ci * delta_sd\n",
    "    ci_high = delta_mean + z_ci * delta_sd\n",
    "\n",
    "    return BayesGeoPosterior(\n",
    "        mu_t_mean=mn_t,\n",
    "        mu_t_sd=math.sqrt(sn_t_sq),\n",
    "        mu_c_mean=mn_c,\n",
    "        mu_c_sd=math.sqrt(sn_c_sq),\n",
    "        delta_mean=delta_mean,\n",
    "        delta_sd=delta_sd,\n",
    "        prob_delta_gt_0=prob_delta_gt_0,\n",
    "        ci_low=ci_low,\n",
    "        ci_high=ci_high,\n",
    "    )\n",
    "\n",
    "\n",
    "try:\n",
    "    bayes_post = bayes_geo_hierarchical_normal(\n",
    "        geo_agg,\n",
    "        value_col=\"delta_mean\",\n",
    "        prior_mean=0.0,\n",
    "        prior_sd=100.0,\n",
    "        alpha=0.05,\n",
    "    )\n",
    "    bayes_post\n",
    "except Exception as e:\n",
    "    print(\"Bayesian geo model skipped (scipy not available):\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0b802e",
   "metadata": {},
   "source": [
    "\n",
    "This model:\n",
    "\n",
    "- **Pools information across geos** within each group to estimate group means \\(\\mu_T\\) and \\(\\mu_C\\).  \n",
    "- Produces a posterior for the **lift** \\(\\Delta = \\mu_T - \\mu_C\\) with:\n",
    "  - mean and standard deviation,  \n",
    "  - probability that lift is positive,  \n",
    "  - a credible interval.\n",
    "\n",
    "You can combine this with the decision rules from the other notebooks, e.g.:\n",
    "\n",
    "- Ship if \\(P(\\Delta > 0) > 0.9\\) and geo-level guardrails are acceptable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cf5d09",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Per-geo posterior effects (shrunken deltas)\n",
    "\n",
    "The group-level Bayesian model gives us a posterior for the **average** lift across\n",
    "treatment geos. Sometimes we also want **per-geo effects**, but with some **shrinkage**\n",
    "towards the group average to avoid over-reacting to noisy geos.\n",
    "\n",
    "Here we build a simple empirical-Bayes shrinker for per-geo deltas:\n",
    "\n",
    "For each group separately (treatment or control):\n",
    "\n",
    "- Let \\(D_g\\) be the raw delta for geo \\(g\\) (e.g. `delta_mean`).  \n",
    "- Let \\(\\bar D\\) and \\(s^2\\) be the sample mean and variance of \\(D_g\\) across geos.  \n",
    "- Place a Normal prior on the geo's true effect \\(\\theta_g\\):  \n",
    "  \\(\\theta_g \\sim \\mathcal{N}(\\bar D, s_0^2)\\) with some prior variance \\(s_0^2\\).  \n",
    "- Assume the observation noise variance is approximately \\(s^2\\).  \n",
    "\n",
    "Then the posterior mean for \\(\\theta_g\\) is:\n",
    "\n",
    "\\[\n",
    "\\mathbb{E}[\\theta_g \\mid D_g] = w D_g + (1 - w) \\bar D, \\quad\n",
    "w = \\frac{s_0^2}{s_0^2 + s^2}.\n",
    "\\]\n",
    "\n",
    "Each geo's delta is **shrunk** towards its group average by the same weight \\(w\\).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba715d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ShrunkenGeoEffects:\n",
    "    df: pd.DataFrame\n",
    "    shrink_weight_treat: float\n",
    "    shrink_weight_control: float\n",
    "\n",
    "\n",
    "def compute_shrunken_geo_deltas(\n",
    "    geo_agg: pd.DataFrame,\n",
    "    value_col: str = \"delta_mean\",\n",
    "    prior_sd: float = 100.0,\n",
    ") -> ShrunkenGeoEffects:\n",
    "    \"\"\"Compute shrunken per-geo deltas within each group (empirical Bayes).\n",
    "    \n",
    "    For each group (treatment/control), we shrink raw per-geo deltas towards the\n",
    "    group's mean delta by a weight w:\n",
    "    \n",
    "        w = s0^2 / (s0^2 + s^2)\n",
    "    \n",
    "    where:\n",
    "    - s0^2 is a prior variance (prior_sd^2),\n",
    "    - s^2 is the sample variance of the per-geo deltas in that group.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    geo_agg : DataFrame\n",
    "        Geo-level aggregated data, with columns ['group', value_col].\n",
    "    value_col : str\n",
    "        Column containing per-geo effects (e.g., delta_mean).\n",
    "    prior_sd : float\n",
    "        Prior standard deviation for the group mean around the empirical mean.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ShrunkenGeoEffects\n",
    "        DataFrame with added columns 'delta_shrunken' and shrink weights.\n",
    "    \"\"\"\n",
    "    df = geo_agg.copy()\n",
    "    df[\"delta_raw\"] = df[value_col]\n",
    "    \n",
    "    s0_sq = prior_sd ** 2\n",
    "    \n",
    "    shrink_weights: dict[str, float] = {}\n",
    "    \n",
    "    for grp in [\"control\", \"treatment\"]:\n",
    "        mask = df[\"group\"] == grp\n",
    "        d = df.loc[mask, \"delta_raw\"].to_numpy()\n",
    "        if d.size <= 1:\n",
    "            # Nothing to shrink\n",
    "            shrink_weights[grp] = 1.0\n",
    "            df.loc[mask, \"delta_shrunken\"] = d\n",
    "            continue\n",
    "        \n",
    "        mean_d = float(d.mean())\n",
    "        var_d = float(d.var(ddof=1))\n",
    "        if var_d <= 0.0:\n",
    "            shrink_weights[grp] = 1.0\n",
    "            df.loc[mask, \"delta_shrunken\"] = d\n",
    "            continue\n",
    "        \n",
    "        w = s0_sq / (s0_sq + var_d)\n",
    "        shrink_weights[grp] = w\n",
    "        \n",
    "        df.loc[mask, \"delta_shrunken\"] = w * d + (1.0 - w) * mean_d\n",
    "    \n",
    "    return ShrunkenGeoEffects(\n",
    "        df=df,\n",
    "        shrink_weight_treat=shrink_weights.get(\"treatment\", 1.0),\n",
    "        shrink_weight_control=shrink_weights.get(\"control\", 1.0),\n",
    "    )\n",
    "\n",
    "\n",
    "shrunken = compute_shrunken_geo_deltas(geo_agg, value_col=\"delta_mean\", prior_sd=100.0)\n",
    "shrunken.df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224e7462",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot per-geo raw vs shrunken deltas, colored by group\n",
    "df_plot = shrunken.df.sort_values(\"delta_shrunken\").reset_index(drop=True)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "colors = df_plot[\"group\"].map({\"control\": \"C0\", \"treatment\": \"C1\"})\n",
    "plt.scatter(df_plot.index, df_plot[\"delta_raw\"], label=\"raw delta\", alpha=0.4, marker=\"o\")\n",
    "plt.scatter(df_plot.index, df_plot[\"delta_shrunken\"], label=\"shrunken delta\", alpha=0.8, marker=\"x\", c=colors)\n",
    "plt.axhline(0.0, color=\"black\", linewidth=1, linestyle=\"--\")\n",
    "plt.xlabel(\"geo (sorted by shrunken delta)\")\n",
    "plt.ylabel(\"delta_mean\")\n",
    "plt.title(\"Per-geo raw vs shrunken deltas\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "shrunken.shrink_weight_treat, shrunken.shrink_weight_control\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeff0ff",
   "metadata": {},
   "source": [
    "\n",
    "This plot gives you a sense of which geos have extreme raw deltas that get pulled back\n",
    "towards their group averages. You can use the **shrunken deltas** for:\n",
    "\n",
    "- Ranking geos by performance while de-emphasizing noise.  \n",
    "- Identifying outlier geos that still look strong/weak **after** shrinkage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6511fbb5",
   "metadata": {},
   "source": [
    "\n",
    "## 10) Decision layer: Bayesian geo model + guardrail rules\n",
    "\n",
    "We now add a small **decision layer** that combines:\n",
    "\n",
    "- The Bayesian geo model for the **primary metric lift** \\(\\Delta\\).  \n",
    "- A simple **guardrail** constraint for another metric (e.g. refund rate, complaints).\n",
    "\n",
    "The idea is to encode something like:\n",
    "\n",
    "> Ship if P(primary lift > 0) ≥ 0.9 **and** guardrail not degraded beyond threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f70fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class GeoDecisionConfig:\n",
    "    main_prob_threshold: float      # e.g. 0.9\n",
    "    min_abs_lift: float | None     # e.g. 5.0 (units of delta_mean), or None for no size check\n",
    "    guardrail_max_degradation: float  # maximum allowed degradation (absolute units)\n",
    "    guardrail_direction: str       # 'lower_is_better' or 'higher_is_better'\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GeoDecisionOutcome:\n",
    "    decision: str       # 'ship', 'hold', 'do_not_ship'\n",
    "    reason: str\n",
    "    details: Dict[str, float]\n",
    "\n",
    "\n",
    "def decide_geo_bayes_with_guardrail(\n",
    "    bayes_post: \"BayesGeoPosterior\",\n",
    "    guardrail_estimate: float,\n",
    "    guardrail_ci_high: float,\n",
    "    config: GeoDecisionConfig,\n",
    ") -> GeoDecisionOutcome:\n",
    "    \"\"\"Combine Bayesian lift and a guardrail rule into a simple decision.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bayes_post : BayesGeoPosterior\n",
    "        Posterior summary for the primary metric lift (delta).\n",
    "    guardrail_estimate : float\n",
    "        Estimated change in guardrail (e.g. +0.005 absolute).\n",
    "    guardrail_ci_high : float\n",
    "        Upper bound of a CI or a conservative bound on guardrail change.\n",
    "    config : GeoDecisionConfig\n",
    "        Decision thresholds.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    GeoDecisionOutcome\n",
    "        Decision ('ship', 'hold', 'do_not_ship'), reason, and numeric details.\n",
    "    \"\"\"\n",
    "    # Primary metric checks\n",
    "    prob_ok = bayes_post.prob_delta_gt_0 >= config.main_prob_threshold\n",
    "    size_ok = True\n",
    "    if config.min_abs_lift is not None:\n",
    "        size_ok = abs(bayes_post.delta_mean) >= config.min_abs_lift\n",
    "\n",
    "    # Guardrail check: interpret degradation depending on direction\n",
    "    if config.guardrail_direction == \"lower_is_better\":\n",
    "        # Degradation is positive increase\n",
    "        guardrail_ok = guardrail_ci_high <= config.guardrail_max_degradation\n",
    "    elif config.guardrail_direction == \"higher_is_better\":\n",
    "        # Degradation is negative decrease\n",
    "        guardrail_ok = guardrail_ci_high >= -config.guardrail_max_degradation\n",
    "    else:\n",
    "        raise ValueError(\"guardrail_direction must be 'lower_is_better' or 'higher_is_better'.\")\n",
    "\n",
    "    details = {\n",
    "        \"delta_mean\": bayes_post.delta_mean,\n",
    "        \"delta_sd\": bayes_post.delta_sd,\n",
    "        \"prob_delta_gt_0\": bayes_post.prob_delta_gt_0,\n",
    "        \"guardrail_estimate\": guardrail_estimate,\n",
    "        \"guardrail_ci_high\": guardrail_ci_high,\n",
    "    }\n",
    "\n",
    "    if prob_ok and size_ok and guardrail_ok:\n",
    "        return GeoDecisionOutcome(\n",
    "            decision=\"ship\",\n",
    "            reason=(\n",
    "                \"Primary metric shows positive lift with high posterior probability, \"\n",
    "                \"and guardrail is within acceptable degradation.\"\n",
    "            ),\n",
    "            details=details,\n",
    "        )\n",
    "\n",
    "    if prob_ok and size_ok and not guardrail_ok:\n",
    "        return GeoDecisionOutcome(\n",
    "            decision=\"hold\",\n",
    "            reason=(\n",
    "                \"Primary metric looks good, but guardrail may be degraded beyond the \"\n",
    "                \"acceptable threshold. Investigate or adjust before rolling out.\"\n",
    "            ),\n",
    "            details=details,\n",
    "        )\n",
    "\n",
    "    return GeoDecisionOutcome(\n",
    "        decision=\"do_not_ship\",\n",
    "        reason=(\n",
    "            \"Primary metric lift is not sufficiently positive or not large enough in magnitude \"\n",
    "            \"given the configured thresholds.\"\n",
    "        ),\n",
    "        details=details,\n",
    "    )\n",
    "\n",
    "\n",
    "# Example: mock guardrail effect and decision\n",
    "try:\n",
    "    _ = bayes_post  # type: ignore[name-defined]\n",
    "except NameError:\n",
    "    print(\"bayes_post is not available; run the Bayesian geo model cell first.\")\n",
    "else:\n",
    "    # Suppose guardrail is 'refund_rate' (lower is better)\n",
    "    guardrail_estimate = 0.005    # +0.5pp\n",
    "    guardrail_ci_high = 0.015     # worst-case +1.5pp\n",
    "\n",
    "    dec_config = GeoDecisionConfig(\n",
    "        main_prob_threshold=0.9,\n",
    "        min_abs_lift=None,            # no minimum absolute size check here\n",
    "        guardrail_max_degradation=0.02,  # allow up to +2pp\n",
    "        guardrail_direction=\"lower_is_better\",\n",
    "    )\n",
    "\n",
    "    decision = decide_geo_bayes_with_guardrail(\n",
    "        bayes_post=bayes_post,      # from the Bayesian geo model\n",
    "        guardrail_estimate=guardrail_estimate,\n",
    "        guardrail_ci_high=guardrail_ci_high,\n",
    "        config=dec_config,\n",
    "    )\n",
    "    decision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce5aa59",
   "metadata": {},
   "source": [
    "\n",
    "This gives you a small, explicit **decision object** summarizing:\n",
    "\n",
    "- Whether to **ship**, **hold**, or **not ship**.  \n",
    "- A human-readable reason string.  \n",
    "- Numeric details: posterior lift stats and guardrail summary.\n",
    "\n",
    "You can hook this into the **story-layer notebook** we built earlier to auto-generate\n",
    "a decision memo for geo experiments as well (primary effect, guardrails, and rollout plan).\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}