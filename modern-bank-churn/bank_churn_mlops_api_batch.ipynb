{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# MLOps-Flavoured Churn Project \u2013 API + Batch Scoring\n\nThis notebook turns a churn model into something closer to a **real service**:\n\n- Train a churn model on the **Bank Customer Churn** dataset.\n- Package the model as a reusable **scikit-learn pipeline**.\n- **Persist** the model artifact to disk (for reuse outside the notebook).\n- Sketch a small **FastAPI** service to serve online predictions.\n- Implement a simple **batch scoring** script for CSV files.\n\nThe goal is not full production MLOps, but to get a clean, realistic\n**deployment-ready shape** you can extend later (e.g. Docker, CI/CD, monitoring).\n\nWe assume the dataset is available at:\n\n```text\ndata/Churn_Modelling.csv\n```\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1. Imports and configuration\n\nWe will use:\n\n- `pandas`, `numpy` \u2013 data handling.\n- `scikit-learn` \u2013 model and pipeline.\n- `joblib` \u2013 model persistence.\n- `FastAPI`, `pydantic` \u2013 API sketch (code as text you can move into a .py file).\n\nOnly scikit-learn and joblib are strictly required to run this notebook; the\nFastAPI code here is **example code** to be used in a separate service.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "from __future__ import annotations\n\nfrom pathlib import Path\nfrom typing import Dict, List\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.base import BaseEstimator\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\n\nimport joblib\n\n# Optional: only needed if you want to run the API code from this notebook\ntry:  # noqa: SIM105\n    import fastapi  # type: ignore[import]\n    import pydantic  # type: ignore[import]\nexcept ImportError:\n    fastapi = None\n    pydantic = None\n\nRANDOM_STATE: int = 42\nnp.random.seed(RANDOM_STATE)\n\nDATA_PATH: Path = Path(\"data\") / \"Churn_Modelling.csv\"\nARTIFACTS_DIR: Path = Path(\"artifacts\")\nMODEL_PATH: Path = ARTIFACTS_DIR / \"bank_churn_model.joblib\"\n\nif not DATA_PATH.exists():\n    raise FileNotFoundError(\n        f\"Data file not found at {DATA_PATH.resolve()}. \"\n        \"Please download the Bank Customer Churn CSV and place it under the 'data/' directory.\"\n    )\n\nARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2. Load and clean the churn dataset\n\nWe reuse the **Bank Customer Churn** dataset used in previous projects.\n\nColumns (typical):\n\n- IDs: `RowNumber`, `CustomerId`, `Surname`.\n- Features: `CreditScore`, `Geography`, `Gender`, `Age`, `Tenure`,\n  `Balance`, `NumOfProducts`, `HasCrCard`, `IsActiveMember`, `EstimatedSalary`.\n- Target: `Exited` (1 = churn, 0 = stayed).\n\nFor the model we:\n\n- Drop pure identifier columns.\n- Make sure `Exited` is integer 0/1.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def load_bank_churn_data(path: Path) -> pd.DataFrame:\n    \"\"\"Load the bank customer churn dataset.\n\n    Args:\n        path: Path to the CSV file.\n\n    Returns:\n        DataFrame with the bank churn data.\n    \"\"\"\n    if not path.exists():\n        raise FileNotFoundError(f\"File not found: {path!s}\")\n\n    df: pd.DataFrame = pd.read_csv(path)\n    if df.empty:\n        raise ValueError(f\"Loaded DataFrame is empty: {path!s}\")\n\n    return df\n\n\ndef clean_bank_churn_data(raw_df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Clean the bank churn dataset.\n\n    - Drop identifier columns (if present).\n    - Ensure `Exited` exists and is integer 0/1.\n\n    Args:\n        raw_df: Raw bank churn DataFrame.\n\n    Returns:\n        Cleaned DataFrame.\n    \"\"\"\n    df = raw_df.copy()\n\n    id_cols: List[str] = [\"RowNumber\", \"CustomerId\", \"Surname\"]\n    drop_cols: List[str] = [c for c in id_cols if c in df.columns]\n\n    if drop_cols:\n        df = df.drop(columns=drop_cols)\n        print(f\"Dropped identifier columns: {drop_cols}\")\n\n    if \"Exited\" not in df.columns:\n        raise ValueError(\"Target column 'Exited' not found in DataFrame.\")\n\n    df[\"Exited\"] = df[\"Exited\"].astype(int)\n\n    return df\n\n\nraw_df: pd.DataFrame = load_bank_churn_data(DATA_PATH)\ndf: pd.DataFrame = clean_bank_churn_data(raw_df)\n\nprint(\"Shape:\", df.shape)\ndisplay(df.head())\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3. Define the training pipeline\n\nWe build a scikit-learn **Pipeline** that includes:\n\n- Preprocessing:\n  - `StandardScaler` for numeric features.\n  - `OneHotEncoder` for categorical features (`Geography`, `Gender`).\n- Model:\n  - `RandomForestClassifier` as a solid baseline.\n\nWe keep everything inside a single pipeline so it can be saved and loaded\nas **one artifact**.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "TARGET_COL: str = \"Exited\"\n\nif TARGET_COL not in df.columns:\n    raise KeyError(f\"Target column {TARGET_COL!r} not found in DataFrame.\")\n\nX: pd.DataFrame = df.drop(columns=[TARGET_COL])\ny: pd.Series = df[TARGET_COL]\n\ncategorical_cols: List[str] = [c for c in [\"Geography\", \"Gender\"] if c in X.columns]\nnumeric_cols: List[str] = [c for c in X.columns if c not in categorical_cols]\n\nprint(\"Categorical columns:\", categorical_cols)\nprint(\"Numeric columns:\", numeric_cols)\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X,\n    y,\n    test_size=0.2,\n    stratify=y,\n    random_state=RANDOM_STATE,\n)\n\nprint(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n\nnumeric_transformer = Pipeline(\n    steps=[(\"scaler\", StandardScaler())]\n)\n\ncategorical_transformer = Pipeline(\n    steps=[(\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))]\n)\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num\", numeric_transformer, numeric_cols),\n        (\"cat\", categorical_transformer, categorical_cols),\n    ]\n)\n\nmodel = RandomForestClassifier(\n    n_estimators=300,\n    max_depth=None,\n    min_samples_split=4,\n    min_samples_leaf=2,\n    random_state=RANDOM_STATE,\n    n_jobs=-1,\n)\n\nchurn_pipeline: Pipeline = Pipeline(\n    steps=[\n        (\"preprocess\", preprocessor),\n        (\"clf\", model),\n    ]\n)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 3.1 Train and evaluate\n\nWe fit the pipeline and compute simple metrics:\n\n- Accuracy.\n- ROC-AUC.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "churn_pipeline.fit(X_train, y_train)\n\ny_pred_test = churn_pipeline.predict(X_test)\ny_proba_test = churn_pipeline.predict_proba(X_test)[:, 1]\n\nacc: float = accuracy_score(y_test, y_pred_test)\nroc_auc: float = roc_auc_score(y_test, y_proba_test)\n\nprint(f\"Test accuracy: {acc:.3f}\")\nprint(f\"Test ROC-AUC:  {roc_auc:.3f}\")\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "The exact numbers are not the main focus here; our goal is a **reasonable**\nmodel with a clean deployment shape.\n\nNext we **persist** the pipeline as a single artifact.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4. Persisting the model artifact\n\nWe save the entire `churn_pipeline` using `joblib`:\n\n- This includes preprocessing and model.\n- It can be loaded later by any Python process that has the same library versions.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def save_model(model: BaseEstimator, path: Path) -> None:\n    \"\"\"Save a scikit-learn model or pipeline to disk using joblib.\n\n    Args:\n        model: Fitted estimator or pipeline.\n        path: File path to save the artifact.\n    \"\"\"\n    path.parent.mkdir(parents=True, exist_ok=True)\n    joblib.dump(model, path)\n    print(f\"Model saved to {path.resolve()}\")\n\n\ndef load_model(path: Path) -> BaseEstimator:\n    \"\"\"Load a scikit-learn model or pipeline from disk.\n\n    Args:\n        path: Path to the joblib artifact.\n\n    Returns:\n        Loaded estimator.\n    \"\"\"\n    if not path.exists():\n        raise FileNotFoundError(f\"Model file not found: {path!s}\")\n    loaded = joblib.load(path)\n    return loaded\n\n\nsave_model(churn_pipeline, MODEL_PATH)\n\n# Quick smoke test: load and predict\nloaded_pipeline = load_model(MODEL_PATH)\nproba_check = loaded_pipeline.predict_proba(X_test.iloc[:5])[:, 1]\nprint(\"Sample predicted churn probabilities (loaded model):\", proba_check)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "At this point we have a **portable artifact**:\n\n```text\nartifacts/bank_churn_model.joblib\n```\n\nEverything else (API, batch scoring, etc.) should consume this artifact,\nnot retrain the model.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5. Sketching an online API with FastAPI\n\nWe now sketch a minimal **FastAPI** service that:\n\n- Loads `bank_churn_model.joblib` at startup.\n- Exposes a `/predict` endpoint.\n- Accepts a **single customer** or a **list of customers** as JSON.\n- Returns churn probabilities.\n\n> The API code below is provided as a **string** so you can write it to\n> `app/main.py` in a separate project, then run with `uvicorn`.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "api_code = '''\nfrom __future__ import annotations\n\nfrom pathlib import Path\nfrom typing import List\n\nimport joblib\nimport pandas as pd\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel\n\n# Paths\nARTIFACTS_DIR = Path(\"artifacts\")\nMODEL_PATH = ARTIFACTS_DIR / \"bank_churn_model.joblib\"\n\n# Load model at startup\nif not MODEL_PATH.exists():\n    raise FileNotFoundError(f\"Model artifact not found at {MODEL_PATH.resolve()}\")\n\nmodel = joblib.load(MODEL_PATH)\n\napp = FastAPI(title=\"Bank Churn Prediction API\")\n\n\nclass CustomerFeatures(BaseModel):\n    CreditScore: float\n    Geography: str\n    Gender: str\n    Age: int\n    Tenure: int\n    Balance: float\n    NumOfProducts: int\n    HasCrCard: int\n    IsActiveMember: int\n    EstimatedSalary: float\n\n\nclass PredictionResponse(BaseModel):\n    churn_proba: float\n\n\n@app.get(\"/health\")\nasync def health() -> dict:\n    \"\"\"Health check endpoint.\"\"\"\n    return {\"status\": \"ok\"}\n\n\n@app.post(\"/predict\", response_model=List[PredictionResponse])\nasync def predict(customers: List[CustomerFeatures]) -> List[PredictionResponse]:\n    \"\"\"Predict churn probability for one or more customers.\n\n    Args:\n        customers: List of customer feature payloads.\n\n    Returns:\n        List of PredictionResponse objects with churn probabilities.\n    \"\"\"\n    # Convert list of Pydantic models to DataFrame\n    data = [c.dict() for c in customers]\n    df = pd.DataFrame(data)\n\n    proba = model.predict_proba(df)[:, 1]\n\n    return [PredictionResponse(churn_proba=float(p)) for p in proba]\n\n'''\n\nprint(api_code)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 5.1 How to use this API code\n\n1. Create a small project structure, for example:\n\n```text\nbank-churn-service/\n\u251c\u2500\u2500 app/\n\u2502   \u2514\u2500\u2500 main.py          # paste the FastAPI code here\n\u251c\u2500\u2500 artifacts/\n\u2502   \u2514\u2500\u2500 bank_churn_model.joblib\n\u2514\u2500\u2500 requirements.txt\n```\n\n2. Save the printed `api_code` into `app/main.py`.\n3. Install dependencies (example):\n\n```bash\npip install fastapi uvicorn joblib scikit-learn pandas\n```\n\n4. Run the API:\n\n```bash\nuvicorn app.main:app --reload --port 8000\n```\n\n5. Example request (JSON body for `/predict`):\n\n```json\n[\n  {\n    \"CreditScore\": 600,\n    \"Geography\": \"France\",\n    \"Gender\": \"Male\",\n    \"Age\": 40,\n    \"Tenure\": 3,\n    \"Balance\": 60000.0,\n    \"NumOfProducts\": 2,\n    \"HasCrCard\": 1,\n    \"IsActiveMember\": 1,\n    \"EstimatedSalary\": 50000.0\n  }\n]\n```\n\nResponse (example):\n\n```json\n[\n  {\"churn_proba\": 0.27}\n]\n```\n\nFrom here you can add:\n\n- Request logging.\n- Input validation / defaults.\n- Authentication.\n- Monitoring hooks.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6. Batch scoring script\n\nIn many churn use cases you want to score **batches of customers** offline.\n\nWe implement a simple function that:\n\n- Reads a CSV file with the same feature columns used in training.\n- Loads the persisted pipeline.\n- Adds predicted churn probabilities.\n- Writes a new CSV with results.\n\nThis is the basis for a **daily churn scoring job**.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def batch_score_csv(\n    model_path: Path,\n    input_csv: Path,\n    output_csv: Path,\n    id_column: str | None = None,\n) -> pd.DataFrame:\n    \"\"\"Score a batch of customers in a CSV file using a saved churn model.\n\n    Args:\n        model_path: Path to the joblib model artifact.\n        input_csv: Path to the input CSV with customer features.\n        output_csv: Path where the output CSV will be saved.\n        id_column: Optional name of an identifier column to keep.\n\n    Returns:\n        DataFrame with predictions (also saved to `output_csv`).\n    \"\"\"\n    if not input_csv.exists():\n        raise FileNotFoundError(f\"Input CSV not found: {input_csv!s}\")\n\n    model: BaseEstimator = load_model(model_path)\n\n    data = pd.read_csv(input_csv)\n\n    # Optionally separate out id column\n    id_series = None\n    if id_column is not None and id_column in data.columns:\n        id_series = data[id_column]\n\n    X_batch = data.copy()\n    if TARGET_COL in X_batch.columns:\n        X_batch = X_batch.drop(columns=[TARGET_COL])\n\n    proba = model.predict_proba(X_batch)[:, 1]\n\n    result_df = pd.DataFrame({\"churn_proba\": proba})\n\n    if id_series is not None:\n        result_df.insert(0, id_column, id_series)\n\n    output_csv.parent.mkdir(parents=True, exist_ok=True)\n    result_df.to_csv(output_csv, index=False)\n\n    print(f\"Saved batch predictions to {output_csv.resolve()}\")\n    return result_df\n\n\n# Example usage (uncomment and adjust paths when running in your environment):\n# input_demo = Path(\"data\") / \"Churn_Modelling.csv\"\n# output_demo = Path(\"data\") / \"Churn_Modelling_scored.csv\"\n# scored_batch_df = batch_score_csv(MODEL_PATH, input_demo, output_demo, id_column=\"CustomerId\")\n# display(scored_batch_df.head())\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "You can schedule this script as a **cron job** or orchestrate it with tools\nlike Airflow, Prefect, or any workflow system.\n\nThe key point: it **loads** the model artifact instead of retraining, giving\nyou a stable scoring behaviour across runs.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 7. Minimal project layout suggestion\n\nPutting everything together, a minimal MLOps-ish project structure could be:\n\n```text\nbank-churn-mlops/\n\u251c\u2500\u2500 data/\n\u2502   \u2514\u2500\u2500 Churn_Modelling.csv           # training data (usually not in prod image)\n\u251c\u2500\u2500 artifacts/\n\u2502   \u2514\u2500\u2500 bank_churn_model.joblib       # trained model artifact\n\u251c\u2500\u2500 notebooks/\n\u2502   \u2514\u2500\u2500 01_train_and_export.ipynb     # this notebook, or similar\n\u251c\u2500\u2500 app/\n\u2502   \u2514\u2500\u2500 main.py                       # FastAPI service using the artifact\n\u251c\u2500\u2500 batch/\n\u2502   \u2514\u2500\u2500 score_churn.py                # wrapper around batch_score_csv\n\u251c\u2500\u2500 requirements.txt\n\u2514\u2500\u2500 README.md\n```\n\nTypical lifecycle:\n\n1. **Training phase** (offline / dev or scheduled):\n   - Run the training notebook or script \u2192 update `bank_churn_model.joblib`.\n2. **Serving phase**:\n   - FastAPI service loads the latest artifact at startup.\n   - Batch jobs call the same artifact for offline scoring.\n3. **Monitoring phase**:\n   - Track model performance over time (not covered here, but natural next step).\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 8. Next possible extensions\n\nTo turn this into a more complete MLOps project you could add:\n\n- **Versioning** of model artifacts (timestamps, MLflow, or simple naming).\n- **Config management** (YAML/JSON for paths, model hyperparameters, etc.).\n- **Dockerfile** to containerise the FastAPI app and model artifact.\n- **CI/CD** to:\n  - Run tests.\n  - Rebuild and deploy the service when a new model is pushed.\n- **Monitoring & logging**:\n  - Log input distributions and prediction summaries.\n  - Monitor drift and performance degradation.\n\nThis notebook gives you a **starting point**: a clean pipeline, a persisted\nartifact, an example API, and a batch scoring path you can plug into your own\nstack.\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}