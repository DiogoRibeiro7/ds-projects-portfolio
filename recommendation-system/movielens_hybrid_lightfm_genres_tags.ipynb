{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Hybrid MovieLens Recommender \u2013 LightFM with Genres & Tags\n\nThis notebook extends the previous MovieLens recommenders by building a\n**hybrid model**:\n\n- We still use **collaborative signals** (user\u2013item interactions).\n- We now add **content features** from `movies.csv` and `tags.csv`:\n  - Genres as item features.\n  - User-generated tags as item features.\n\nWe will:\n\n1. Load MovieLens ratings, movies and tags.\n2. Build an **implicit feedback** interaction matrix from ratings.\n3. Construct item features from **genres + tags**.\n4. Train two LightFM models:\n   - Model A: **interactions only**.\n   - Model B: **interactions + item features (genres + tags)**.\n5. Compare their performance with **precision@K** and **recall@K**.\n6. Inspect item features and latent neighbourhoods for a sample movie.\n\nAssumed files (MovieLens `ml-latest-small`):\n\n```text\ndata/ml-latest-small/ratings.csv\ndata/ml-latest-small/movies.csv\ndata/ml-latest-small/tags.csv\n```"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 0. Environment setup (outside this notebook)\n\nBefore running this notebook you need to install LightFM:\n\n```bash\npip install lightfm\n```\n\nOr with conda:\n\n```bash\nconda install -c conda-forge lightfm\n```\n\nWe only rely on `lightfm` and standard scientific Python libraries.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1. Imports and configuration\n\nWe will use:\n\n- `pandas`, `numpy` \u2013 data handling.\n- `scipy.sparse` \u2013 sparse matrices.\n- `matplotlib`, `seaborn` \u2013 visualisations.\n- `lightfm` \u2013 hybrid recommender model.\n\nWe treat MovieLens ratings as **implicit feedback** by thresholding the\nrating: rating \u2265 4.0 \u2192 positive interaction.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "from __future__ import annotations\n\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import Dict, Iterable, List, Sequence, Tuple, Set\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom scipy import sparse\n\nfrom lightfm import LightFM\nfrom lightfm.data import Dataset as LFMDataset\nfrom lightfm.evaluation import precision_at_k as lfm_precision_at_k, recall_at_k as lfm_recall_at_k\nfrom lightfm.cross_validation import random_train_test_split\n\nsns.set(style=\"whitegrid\")\nplt.rcParams[\"figure.figsize\"] = (8, 5)\n\nRANDOM_STATE: int = 42\nnp.random.seed(RANDOM_STATE)\n\nDATA_DIR: Path = Path(\"data\") / \"ml-latest-small\"\nRATINGS_PATH: Path = DATA_DIR / \"ratings.csv\"\nMOVIES_PATH: Path = DATA_DIR / \"movies.csv\"\nTAGS_PATH: Path = DATA_DIR / \"tags.csv\"\n\nfor p in [RATINGS_PATH, MOVIES_PATH, TAGS_PATH]:\n    if not p.exists():\n        raise FileNotFoundError(\n            f\"Required file not found: {p.resolve()}. \"\n            \"Please ensure you have the 'ml-latest-small' MovieLens dataset under data/ml-latest-small/.\"\n        )\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2. Load data and quick EDA\n\nWe load:\n\n- `ratings.csv` \u2013 userId, movieId, rating, timestamp.\n- `movies.csv` \u2013 movieId, title, genres.\n- `tags.csv` \u2013 userId, movieId, tag, timestamp.\n\nWe keep EDA light here, since detailed analysis already exists in previous\nnotebooks.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "ratings_df = pd.read_csv(RATINGS_PATH)\nmovies_df = pd.read_csv(MOVIES_PATH)\ntags_df = pd.read_csv(TAGS_PATH)\n\nprint(\"Ratings:\", ratings_df.shape)\nprint(\"Movies:\", movies_df.shape)\nprint(\"Tags:   \", tags_df.shape)\n\nratings_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "n_users: int = ratings_df[\"userId\"].nunique()\nn_items: int = ratings_df[\"movieId\"].nunique()\n\nprint(f\"Users: {n_users}, Movies (in ratings): {n_items}, Ratings: {len(ratings_df)}\")\nprint(f\"Density: {len(ratings_df) / (n_users * n_items):.6f}\")\n\nsns.histplot(ratings_df[\"rating\"], bins=10)\nplt.title(\"Rating distribution\")\nplt.xlabel(\"Rating\")\nplt.show()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3. Build implicit feedback interactions\n\nWe convert ratings into implicit interactions:\n\n- If `rating >= 4.0` \u2192 positive interaction (1).\n- Otherwise \u2192 no interaction (0).\n\nThis is a simple heuristic, but often used for MovieLens\u2013LightFM examples.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "POS_THRESH: float = 4.0\n\nimplicit_df = ratings_df.copy()\nimplicit_df[\"interaction\"] = (implicit_df[\"rating\"] >= POS_THRESH).astype(int)\n\nprint(implicit_df[\"interaction\"].value_counts(normalize=True))\n\n# Filter only positive interactions for LightFM interactions matrix\npos_df = implicit_df.loc[implicit_df[\"interaction\"] == 1, [\"userId\", \"movieId\"]].copy()\nprint(\"Positive interactions:\", pos_df.shape[0])\npos_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4. Build item features from genres and tags\n\nWe want **string features** per item so that LightFM can treat them as\nhigh-cardinality sparse features.\n\n### 4.1 Genres as features\n\nFrom `movies.csv` we have a `genres` column with pipe-separated genres,\nfor example:\n\n```text\nAdventure|Comedy|Sci-Fi\n```\n\nWe turn each genre into a feature token of the form `\"genre:Comedy\"`.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def extract_genre_features(movies: pd.DataFrame) -> Dict[int, List[str]]:\n    \"\"\"Extract genre-based feature tokens per movie.\n\n    Args:\n        movies: DataFrame with at least columns movieId, genres.\n\n    Returns:\n        Mapping from movieId to list of genre feature tokens.\n    \"\"\"\n    features: Dict[int, List[str]] = {}\n    for row in movies.itertuples(index=False):\n        movie_id = int(row.movieId)\n        genres_str: str = row.genres if isinstance(row.genres, str) else \"\"\n        if genres_str == \"(no genres listed)\" or genres_str == \"No Genres Listed\":\n            genres_list: List[str] = []\n        else:\n            genres_list = [g.strip() for g in genres_str.split(\"|\") if g.strip()]\n        tokens = [f\"genre:{g}\" for g in genres_list]\n        features[movie_id] = tokens\n    return features\n\n\ngenre_features = extract_genre_features(movies_df)\n\n# Quick sanity check\nsample_movie = movies_df.sample(1, random_state=RANDOM_STATE).iloc[0]\nprint(\"Sample movie:\", sample_movie[\"movieId\"], sample_movie[\"title\"], sample_movie[\"genres\"])\nprint(\"Genre feature tokens:\", genre_features[int(sample_movie[\"movieId\"])] )\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 4.2 Tags as features\n\n`tags.csv` contains user-generated free text tags per `(userId, movieId)`.\n\nWe:\n\n1. Lowercase and strip tags.\n2. Aggregate all tags per movie.\n3. Turn them into tokens like `\"tag:space-travel\"`.\n\nTo keep feature space under control, we can:\n\n- Optionally filter very rare tags.\n- Or cap the number of tags per movie.\n\nHere we keep it simple but add a frequency filter.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def extract_tag_features(\n    tags: pd.DataFrame,\n    min_tag_freq: int = 5,\n    max_tags_per_movie: int = 20,\n) -> Dict[int, List[str]]:\n    \"\"\"Extract tag-based feature tokens per movie.\n\n    Args:\n        tags: DataFrame with columns userId, movieId, tag.\n        min_tag_freq: Minimum global frequency to keep a tag.\n        max_tags_per_movie: Maximum number of tags per movie to retain.\n\n    Returns:\n        Mapping from movieId to list of tag feature tokens.\n    \"\"\"\n    tags = tags.copy()\n    tags[\"tag_clean\"] = tags[\"tag\"].astype(str).str.lower().str.strip()\n\n    # Filter extremely rare tags\n    tag_counts = tags[\"tag_clean\"].value_counts()\n    frequent_tags = set(tag_counts[tag_counts >= min_tag_freq].index)\n\n    tags = tags[tags[\"tag_clean\"].isin(frequent_tags)]\n\n    movie_to_tags: Dict[int, List[str]] = {}\n\n    for movie_id, grp in tags.groupby(\"movieId\"):\n        unique_tags = list(dict.fromkeys(grp[\"tag_clean\"]))  # preserve order, deduplicate\n        limited_tags = unique_tags[:max_tags_per_movie]\n        tokens = [f\"tag:{t}\" for t in limited_tags]\n        movie_to_tags[int(movie_id)] = tokens\n\n    return movie_to_tags\n\n\ntag_features = extract_tag_features(tags_df, min_tag_freq=3, max_tags_per_movie=20)\n\nprint(\"Number of movies with at least one tag feature:\", len(tag_features))\n\n# Inspect features for the same sample movie (if present)\nmovie_id_sample = int(sample_movie[\"movieId\"])\nprint(\"Tag feature tokens for sample (if any):\", tag_features.get(movie_id_sample, []))\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 4.3 Combine genre and tag features per movie\n\nFor each `movieId` we combine:\n\n- `genre:*` tokens.\n- `tag:*` tokens (when available).\n\nWe will later pass these as item features into the LightFM `Dataset`.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def combine_item_features(\n    movies: pd.DataFrame,\n    genre_feat: Dict[int, List[str]],\n    tag_feat: Dict[int, List[str]],\n) -> Dict[int, List[str]]:\n    \"\"\"Combine genre and tag features for each movie.\n\n    Args:\n        movies: Movies DataFrame with movieId.\n        genre_feat: Genre feature tokens per movieId.\n        tag_feat: Tag feature tokens per movieId.\n\n    Returns:\n        Mapping from movieId to combined feature token list.\n    \"\"\"\n    combined: Dict[int, List[str]] = {}\n    for row in movies.itertuples(index=False):\n        movie_id = int(row.movieId)\n        g_tokens = genre_feat.get(movie_id, [])\n        t_tokens = tag_feat.get(movie_id, [])\n        tokens = g_tokens + t_tokens\n        # Ensure at least one feature; if none, add a dummy token\n        if not tokens:\n            tokens = [\"bias:item\"]\n        combined[movie_id] = tokens\n    return combined\n\n\nitem_features_tokens = combine_item_features(movies_df, genre_features, tag_features)\n\n# Feature counts per movie for a quick visual\nfeat_counts = pd.Series({mid: len(feats) for mid, feats in item_features_tokens.items()})\n\nsns.histplot(feat_counts, bins=20)\nplt.title(\"Number of features per movie (genres + tags)\")\nplt.xlabel(\"# features\")\nplt.show()\n\nfeat_counts.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5. Build LightFM Dataset and interactions\n\nWe now create a `Dataset` for LightFM and build:\n\n- User and item ID mappings.\n- Interaction matrix from positive events.\n- Item feature matrix from our tokens.\n\nWe will train **two models** on the same interactions:\n\n- Model A: without item features.\n- Model B: with item features.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Collect full sets of user and item ids\nall_users: np.ndarray = ratings_df[\"userId\"].unique()\nall_items: np.ndarray = movies_df[\"movieId\"].unique()\n\n# Collect all unique feature tokens\nall_tokens: Set[str] = set()\nfor feats in item_features_tokens.values():\n    all_tokens.update(feats)\n\nprint(\"# users:\", len(all_users), \"# items:\", len(all_items), \"# feature tokens:\", len(all_tokens))\n\nlfm_dataset = LFMDataset()\nlfm_dataset.fit(\n    users=all_users,\n    items=all_items,\n    item_features=list(all_tokens),\n)\n\n# Build interactions (positive events only)\n\n(interactions, weights) = lfm_dataset.build_interactions(\n    (int(row.userId), int(row.movieId)) for row in pos_df.itertuples(index=False)\n)\n\nprint(\"Interactions shape:\", interactions.shape)\nprint(\"# positive interactions:\", interactions.getnnz())\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Build item feature matrix\n\nitem_features_list: List[Tuple[int, List[str]]] = [\n    (int(mid), feats) for mid, feats in item_features_tokens.items()\n]\n\nitem_features_matrix = lfm_dataset.build_item_features(item_features_list)\n\nprint(\"Item features matrix shape:\", item_features_matrix.shape)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6. Train/test split for implicit data\n\nWe perform a random train/test split on the interaction matrix using\nLightFM's `random_train_test_split` helper.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "train_interactions, test_interactions = random_train_test_split(\n    interactions,\n    test_percentage=0.2,\n    random_state=np.random.RandomState(RANDOM_STATE),\n)\n\nprint(\"Train interactions:\", train_interactions.getnnz())\nprint(\"Test interactions: \", test_interactions.getnnz())\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 7. Train LightFM models\n\nWe train two LightFM models with the same hyperparameters:\n\n- **Model A (no features)** \u2013 only interactions.\n- **Model B (with features)** \u2013 interactions + item feature matrix.\n\nWe use the **BPR** loss, a common choice for implicit feedback ranking.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "@dataclass\nclass LightFMConfig:\n    no_components: int = 40\n    learning_rate: float = 0.05\n    loss: str = \"bpr\"\n    epochs: int = 25\n    num_threads: int = 4\n\n\nconfig = LightFMConfig()\n\n# Model A: interactions only\n\nmodel_no_features = LightFM(\n    no_components=config.no_components,\n    learning_rate=config.learning_rate,\n    loss=config.loss,\n    random_state=RANDOM_STATE,\n)\n\nmodel_no_features.fit(\n    train_interactions,\n    epochs=config.epochs,\n    num_threads=config.num_threads,\n    verbose=True,\n)\n\n# Model B: interactions + item features\n\nmodel_with_features = LightFM(\n    no_components=config.no_components,\n    learning_rate=config.learning_rate,\n    loss=config.loss,\n    random_state=RANDOM_STATE,\n)\n\nmodel_with_features.fit(\n    train_interactions,\n    item_features=item_features_matrix,\n    epochs=config.epochs,\n    num_threads=config.num_threads,\n    verbose=True,\n)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 8. Evaluate with precision@K and recall@K\n\nWe compare the two models using LightFM's evaluation functions.\n\nWe pass `train_interactions` so that already-seen interactions are not\nrecommended as positives.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def evaluate_lightfm_models(\n    model_a: LightFM,\n    model_b: LightFM,\n    train: sparse.spmatrix,\n    test: sparse.spmatrix,\n    item_features: sparse.spmatrix,\n    k: int = 10,\n    num_threads: int = 4,\n) -> pd.DataFrame:\n    \"\"\"Evaluate two LightFM models with and without item features.\n\n    Args:\n        model_a: Model trained without item features.\n        model_b: Model trained with item features.\n        train: Train interaction matrix.\n        test: Test interaction matrix.\n        item_features: Item feature matrix.\n        k: Cutoff for precision@k and recall@k.\n        num_threads: Number of threads for LightFM evaluation.\n\n    Returns:\n        DataFrame with precision@k and recall@k for both models.\n    \"\"\"\n    prec_a = lfm_precision_at_k(\n        model_a,\n        test,\n        train_interactions=train,\n        k=k,\n        num_threads=num_threads,\n    ).mean()\n\n    rec_a = lfm_recall_at_k(\n        model_a,\n        test,\n        train_interactions=train,\n        k=k,\n        num_threads=num_threads,\n    ).mean()\n\n    prec_b = lfm_precision_at_k(\n        model_b,\n        test,\n        train_interactions=train,\n        k=k,\n        num_threads=num_threads,\n        item_features=item_features,\n    ).mean()\n\n    rec_b = lfm_recall_at_k(\n        model_b,\n        test,\n        train_interactions=train,\n        k=k,\n        num_threads=num_threads,\n        item_features=item_features,\n    ).mean()\n\n    results = pd.DataFrame(\n        {\n            \"model\": [\"LightFM (no features)\", \"LightFM (genres+tags)\"],\n            f\"precision@{k}\": [prec_a, prec_b],\n            f\"recall@{k}\": [rec_a, rec_b],\n        }\n    )\n    return results\n\n\nk_eval = 10\nresults_df = evaluate_lightfm_models(\n    model_a=model_no_features,\n    model_b=model_with_features,\n    train=train_interactions,\n    test=test_interactions,\n    item_features=item_features_matrix,\n    k=k_eval,\n    num_threads=config.num_threads,\n)\n\nresults_df\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Visual comparison\n\nresults_melt = results_df.melt(id_vars=\"model\", var_name=\"metric\", value_name=\"value\")\n\nsns.barplot(data=results_melt, x=\"metric\", y=\"value\", hue=\"model\")\nplt.ylim(0, 1)\nplt.title(\"LightFM \u2013 impact of item features (genres + tags)\")\nplt.ylabel(\"Score\")\nplt.show()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "If the item features are informative, we often see an improvement in\nprecision@K and/or recall@K when using them, especially for **cold or\nsparse items**.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 9. Inspecting recommendations and features for a sample user\n\nWe now:\n\n1. Pick a random user.\n2. Generate top-N recommendations with the **feature-aware** model.\n3. Join with movie titles for readability.\n4. Show the content features for a recommended movie.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def get_id_mappings(dataset: LFMDataset) -> Tuple[Dict[int, int], Dict[int, int]]:\n    \"\"\"Return user and item external\u2192internal id mappings from a Dataset.\n\n    Args:\n        dataset: LightFM Dataset instance.\n\n    Returns:\n        Tuple of (user_id_to_internal, item_id_to_internal).\n    \"\"\"\n    user_id_mapping, _, item_id_mapping, _ = dataset.mapping()\n    # mapping() returns dicts: user_id_mapping, user_feature_mapping,\n    # item_id_mapping, item_feature_mapping.\n    return user_id_mapping, item_id_mapping\n\n\nuser_id_map, item_id_map = get_id_mappings(lfm_dataset)\n\n# Reverse mappings\ninternal_to_user = {internal: uid for uid, internal in user_id_map.items()}\ninternal_to_item = {internal: mid for mid, internal in item_id_map.items()}\n\n\ndef recommend_for_user(\n    model: LightFM,\n    dataset: LFMDataset,\n    user_id: int,\n    item_features: sparse.spmatrix | None,\n    n: int = 10,\n) -> pd.DataFrame:\n    \"\"\"Generate top-N recommendations for a given user.\n\n    Args:\n        model: Trained LightFM model.\n        dataset: LightFM Dataset.\n        user_id: External userId.\n        item_features: Item feature matrix, or None.\n        n: Number of recommendations.\n\n    Returns:\n        DataFrame with movieId, score.\n    \"\"\"\n    user_id_map, item_id_map = get_id_mappings(dataset)\n    if user_id not in user_id_map:\n        raise ValueError(f\"User {user_id} not in dataset.\")\n\n    user_internal = user_id_map[user_id]\n\n    n_items_internal = len(item_id_map)\n    item_internal_ids = np.arange(n_items_internal, dtype=np.int64)\n\n    # Predict scores for all items\n    scores = model.predict(\n        user_ids=np.repeat(user_internal, n_items_internal),\n        item_ids=item_internal_ids,\n        item_features=item_features,\n        num_threads=config.num_threads,\n    )\n\n    # Exclude items the user has already interacted with\n    user_rows = interactions.tocsr()[user_internal]\n    already_interacted = set(user_rows.indices)\n\n    candidate_indices = [i for i in item_internal_ids if i not in already_interacted]\n    candidate_scores = scores[candidate_indices]\n\n    top_idx = np.argsort(candidate_scores)[-n:][::-1]\n    top_internal = [candidate_indices[i] for i in top_idx]\n    top_scores = candidate_scores[top_idx]\n\n    movie_ids = [internal_to_item[i] for i in top_internal]\n    recs_df = pd.DataFrame({\"movieId\": movie_ids, \"score\": top_scores})\n    return recs_df\n\n\nsample_user_id: int = int(ratings_df[\"userId\"].sample(1, random_state=RANDOM_STATE).iloc[0])\nprint(\"Sample user:\", sample_user_id)\n\nrecs_df = recommend_for_user(\n    model=model_with_features,\n    dataset=lfm_dataset,\n    user_id=sample_user_id,\n    item_features=item_features_matrix,\n    n=10,\n)\n\nrecs_with_titles = recs_df.merge(movies_df, on=\"movieId\", how=\"left\")\nrecs_with_titles[[\"movieId\", \"title\", \"score\"]]\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 9.1 Inspect content features for one recommended movie\n\nFor one of the top recommendations, we print its genres and tag features\nso you can see what the model had available as side-information.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "if not recs_with_titles.empty:\n    top_movie_id = int(recs_with_titles.iloc[0][\"movieId\"])\n    top_movie_row = movies_df.loc[movies_df[\"movieId\"] == top_movie_id].iloc[0]\n    print(\"Top recommended movie:\")\n    print(top_movie_row[\"movieId\"], top_movie_row[\"title\"], top_movie_row[\"genres\"])\n\n    feats = item_features_tokens.get(top_movie_id, [])\n    print(\"\\nContent feature tokens (genres + tags):\")\n    for f in feats:\n        print(\"-\", f)\nelse:\n    print(\"No recommendations to inspect.\")\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 10. Summary\n\nIn this notebook we built a **hybrid recommender** on MovieLens:\n\n1. Converted ratings to implicit feedback and built an interactions matrix.\n2. Created **item feature tokens** from `movies.csv` and `tags.csv`:\n   - Genres \u2192 `genre:*` features.\n   - Frequent tags \u2192 `tag:*` features.\n3. Constructed a LightFM `Dataset` with both interactions and item features.\n4. Trained two LightFM models:\n   - Interactions only.\n   - Interactions + item features.\n5. Compared their ranking performance (**precision@10**, **recall@10**).\n6. Generated recommended movies for a sample user and inspected the\n   content features used by the hybrid model.\n\nThis gives you a realistic template for **content-aware collaborative\nfiltering** and a natural extension path towards:\n\n- Adding **user features** (demographics, segments).\n- Using richer text features (plot summaries via language models).\n- Deploying the trained model in a real-time inference service.\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}