{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15f080da",
   "metadata": {},
   "source": [
    "\n",
    "# Retention and Survival Analysis for A/B Testing\n",
    "\n",
    "This notebook is a **playbook for experiments on user retention and time-to-event metrics**.\n",
    "\n",
    "Instead of only looking at one-shot outcomes (like `converted`), we consider **when** users churn\n",
    "or perform an action. We cover:\n",
    "\n",
    "1. Simulating a **churn / retention** experiment with censoring.  \n",
    "2. **D+1, D+7, D+30** retention as Bernoulli metrics.  \n",
    "3. **Kaplan–Meier curves** to compare survival / retention over time.  \n",
    "4. The **log-rank test** for equality of survival curves.  \n",
    "5. A brief **Cox proportional hazards** model for covariate adjustment (if `lifelines` is available).\n",
    "\n",
    "All code is typed, documented, and meant to be adapted to real experiment data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e65ce4",
   "metadata": {},
   "source": [
    "## 0) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b853533",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Dict, Any\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (7, 4.5)\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "\n",
    "# Optional: Cox model via lifelines (if installed)\n",
    "try:\n",
    "    from lifelines import CoxPHFitter  # type: ignore\n",
    "except Exception as e:  # pragma: no cover\n",
    "    CoxPHFitter = None\n",
    "    print(\"lifelines not available; Cox model section will be skipped:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc25218",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Simulated retention / churn experiment\n",
    "\n",
    "We simulate an experiment with two arms:\n",
    "\n",
    "- `group ∈ {control, treatment}`.  \n",
    "- Users have a continuous **time-to-churn** (in days) drawn from an exponential distribution.  \n",
    "- We apply **administrative censoring** at a maximum follow-up time `T_max` (e.g. 60 days).  \n",
    "- We also generate a pre-period covariate `pre_activity` which affects the churn rate.\n",
    "\n",
    "Notation:\n",
    "\n",
    "- \\(T_i\\): true time to churn for user \\(i\\).  \n",
    "- \\(C_i\\): censoring time (here, fixed at `T_max`).  \n",
    "- Observed time: \\(Y_i = \\min(T_i, C_i)\\).  \n",
    "- Event indicator: \\(\\delta_i = 1\\{T_i \\le C_i\\}\\).\n",
    "\n",
    "In practice, \\(T_i\\) would be the time from experiment start to churn, and \\(C_i\\)\n",
    "could be the experiment end or last observation time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a632fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def simulate_retention_experiment(\n",
    "    n: int = 20_000,\n",
    "    baseline_hazard_control: float = 1.0 / 30.0,  # ~30-day average lifetime\n",
    "    hazard_ratio_treatment: float = 0.8,          # treatment reduces hazard (better retention)\n",
    "    T_max: float = 60.0,\n",
    "    seed: int | None = 123,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Simulate a retention / churn experiment with exponential hazards and censoring.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        Number of users.\n",
    "    baseline_hazard_control : float\n",
    "        Baseline hazard rate (lambda) in the control arm.\n",
    "    hazard_ratio_treatment : float\n",
    "        Hazard ratio for treatment vs control (< 1 => better retention).\n",
    "    T_max : float\n",
    "        Administrative censoring time (maximum follow-up in days).\n",
    "    seed : int | None\n",
    "        Random seed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        Columns:\n",
    "        - user_id : int\n",
    "        - group : 'control' or 'treatment'\n",
    "        - pre_activity : float (user-level covariate)\n",
    "        - time : float (observed time, in days)\n",
    "        - event : int (1 if churn observed, 0 if censored)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    user_id = np.arange(n)\n",
    "    group_flag = rng.binomial(1, 0.5, size=n)\n",
    "    group = np.where(group_flag == 0, \"control\", \"treatment\")\n",
    "\n",
    "    # Pre-period activity: higher values => more engaged, lower hazard\n",
    "    pre_activity = rng.normal(loc=0.0, scale=1.0, size=n)\n",
    "\n",
    "    # Individual hazards: baseline modified by treatment and pre_activity\n",
    "    # Control hazard:\n",
    "    lambda_control = baseline_hazard_control * np.exp(-0.4 * pre_activity)\n",
    "    # Treatment hazard: apply HR globally but keep covariate effect\n",
    "    lambda_treat = hazard_ratio_treatment * baseline_hazard_control * np.exp(-0.4 * pre_activity)\n",
    "\n",
    "    hazard = np.where(group_flag == 0, lambda_control, lambda_treat)\n",
    "\n",
    "    # Exponential time-to-event: T = -log(U)/lambda\n",
    "    U = rng.uniform(size=n)\n",
    "    true_time = -np.log(U) / hazard\n",
    "\n",
    "    # Administrative censoring at T_max\n",
    "    observed_time = np.minimum(true_time, T_max)\n",
    "    event = (true_time <= T_max).astype(int)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"user_id\": user_id,\n",
    "            \"group\": group,\n",
    "            \"pre_activity\": pre_activity.astype(float),\n",
    "            \"time\": observed_time.astype(float),\n",
    "            \"event\": event.astype(int),\n",
    "        }\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "df = simulate_retention_experiment()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f80a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.groupby(\"group\")[[\"time\", \"event\"]].agg([\"mean\", \"std\", \"sum\", \"count\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47e16fd",
   "metadata": {},
   "source": [
    "\n",
    "## 2) D+1, D+7, D+30 retention as Bernoulli metrics\n",
    "\n",
    "Many product teams track retention as **binary indicators**:\n",
    "\n",
    "- D+1 retention: user is still active at day 1.  \n",
    "- D+7 retention: user is active at day 7.  \n",
    "- D+30 retention: user is active at day 30.\n",
    "\n",
    "Under our churn model, a user is “active at day D” if they **have not churned before day D**.\n",
    "\n",
    "Given (time, event):\n",
    "\n",
    "- If `time > D`, user is retained at D (regardless of event status at later times).  \n",
    "- If `time ≤ D` and `event = 1`, user churned before or at D (not retained).  \n",
    "- If `time ≤ D` and `event = 0`, they are censored before D (we do not know their status at D);\n",
    "  here we treat them as **not retained** for simplicity, but in practice you may exclude them\n",
    "  or handle them carefully.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c50d27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_binary_retention(\n",
    "    df_in: pd.DataFrame,\n",
    "    days: Tuple[int, int, int] = (1, 7, 30),\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Add D+1, D+7, D+30 retention indicators to a survival dataset.\n",
    "\n",
    "    For simplicity, censored before day D are treated as not retained at D.\n",
    "    Adapt this logic if you prefer to drop such users.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_in : DataFrame\n",
    "        Input with columns time (float) and event (0/1).\n",
    "    days : tuple of int\n",
    "        Days at which to compute retention indicators.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        Copy of df_in with new binary columns: retain_D1, retain_D7, retain_D30.\n",
    "    \"\"\"\n",
    "    df = df_in.copy()\n",
    "    for d in days:\n",
    "        col = f\"retain_D{d}\"\n",
    "        df[col] = (df[\"time\"] > float(d)).astype(int)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = add_binary_retention(df)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0966111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ret_cols = [\"retain_D1\", \"retain_D7\", \"retain_D30\"]\n",
    "retention_summary = (\n",
    "    df.groupby(\"group\")[ret_cols]\n",
    "      .agg([\"mean\", \"count\"])\n",
    ")\n",
    "retention_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc440b0",
   "metadata": {},
   "source": [
    "\n",
    "These D+1 / D+7 / D+30 retention rates can be analyzed with the usual **two-sample\n",
    "proportion tests** or Bayesian Beta–Binomial models, just like any other Bernoulli metric.\n",
    "\n",
    "However, this discards the **time-to-event structure** and censoring. For a more complete\n",
    "view of retention dynamics, we now use **Kaplan–Meier curves** and **log-rank tests**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c908524",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Kaplan–Meier survival curves\n",
    "\n",
    "The **Kaplan–Meier (KM) estimator** is a non-parametric estimate of the survival function:\n",
    "\n",
    "\\[\n",
    "\\hat S(t) = \\prod_{t_j \\le t} \\left(1 - \\frac{d_j}{n_j}\\right),\n",
    "\\]\n",
    "\n",
    "where:\n",
    "\n",
    "- \\(t_j\\) are distinct event times,  \n",
    "- \\(d_j\\) is the number of events at \\(t_j\\),  \n",
    "- \\(n_j\\) is the number at risk just before \\(t_j\\).\n",
    "\n",
    "We implement a simple KM estimator and compare curves between control and treatment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958cd3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass(frozen=True)\n",
    "class KMCurve:\n",
    "    \"\"\"Kaplan–Meier survival curve.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    time : np.ndarray\n",
    "        Sorted unique event times where survival changes.\n",
    "    survival : np.ndarray\n",
    "        Estimated survival probabilities at those times.\n",
    "    n_at_risk : np.ndarray\n",
    "        Number of individuals at risk just before each time.\n",
    "    n_events : np.ndarray\n",
    "        Number of events at each time.\n",
    "    \"\"\"\n",
    "    time: np.ndarray\n",
    "    survival: np.ndarray\n",
    "    n_at_risk: np.ndarray\n",
    "    n_events: np.ndarray\n",
    "\n",
    "\n",
    "def kaplan_meier(\n",
    "    time: np.ndarray,\n",
    "    event: np.ndarray,\n",
    ") -> KMCurve:\n",
    "    \"\"\"Compute the Kaplan–Meier survival curve for a single group.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    time : np.ndarray\n",
    "        Observed times (event or censoring).\n",
    "    event : np.ndarray\n",
    "        Event indicators (1 = event, 0 = censored).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    KMCurve\n",
    "        Stepwise survival curve.\n",
    "    \"\"\"\n",
    "    time = np.asarray(time, dtype=float)\n",
    "    event = np.asarray(event, dtype=int)\n",
    "    if time.shape != event.shape:\n",
    "        raise ValueError(\"time and event must have the same shape.\")\n",
    "    if time.size == 0:\n",
    "        raise ValueError(\"Empty input.\")\n",
    "\n",
    "    # Sort by time\n",
    "    order = np.argsort(time)\n",
    "    t_sorted = time[order]\n",
    "    e_sorted = event[order]\n",
    "\n",
    "    unique_times = np.unique(t_sorted[e_sorted == 1])  # event times only\n",
    "    n_times = unique_times.size\n",
    "\n",
    "    if n_times == 0:\n",
    "        # No events: survival is 1 for all times\n",
    "        return KMCurve(\n",
    "            time=np.array([], dtype=float),\n",
    "            survival=np.array([], dtype=float),\n",
    "            n_at_risk=np.array([], dtype=float),\n",
    "            n_events=np.array([], dtype=float),\n",
    "        )\n",
    "\n",
    "    n = time.size\n",
    "    survival = []\n",
    "    n_at_risk = []\n",
    "    n_events = []\n",
    "\n",
    "    S = 1.0\n",
    "    idx = 0  # index over sorted data\n",
    "\n",
    "    for t_j in unique_times:\n",
    "        # number at risk just before t_j\n",
    "        at_risk = np.sum(t_sorted >= t_j)\n",
    "        # events at t_j\n",
    "        d_j = np.sum((t_sorted == t_j) & (e_sorted == 1))\n",
    "\n",
    "        if at_risk <= 0:\n",
    "            continue\n",
    "\n",
    "        S *= (1.0 - d_j / at_risk)\n",
    "\n",
    "        survival.append(S)\n",
    "        n_at_risk.append(float(at_risk))\n",
    "        n_events.append(float(d_j))\n",
    "\n",
    "    return KMCurve(\n",
    "        time=unique_times,\n",
    "        survival=np.asarray(survival, dtype=float),\n",
    "        n_at_risk=np.asarray(n_at_risk, dtype=float),\n",
    "        n_events=np.asarray(n_events, dtype=float),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d76a0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute KM curves by group\n",
    "km_curves: Dict[str, KMCurve] = {}\n",
    "for g in [\"control\", \"treatment\"]:\n",
    "    sub = df[df[\"group\"] == g]\n",
    "    km_curves[g] = kaplan_meier(\n",
    "        time=sub[\"time\"].to_numpy(),\n",
    "        event=sub[\"event\"].to_numpy(),\n",
    "    )\n",
    "\n",
    "plt.figure()\n",
    "for g, curve in km_curves.items():\n",
    "    if curve.time.size == 0:\n",
    "        continue\n",
    "    # Stepwise plot: survival holds until next event time\n",
    "    plt.step(curve.time, curve.survival, where=\"post\", label=g)\n",
    "plt.xlabel(\"time (days)\")\n",
    "plt.ylabel(\"survival / retention S(t)\")\n",
    "plt.title(\"Kaplan–Meier retention curves\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be641446",
   "metadata": {},
   "source": [
    "\n",
    "The curves show **retention over time** for each arm:\n",
    "\n",
    "- Higher curves mean better retention (lower hazard / churn).  \n",
    "- Visual separation suggests a treatment effect on retention, but we need a formal test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ed5f8b",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Log-rank test for equality of survival curves\n",
    "\n",
    "The **log-rank test** compares survival between two groups under the null hypothesis:\n",
    "\n",
    "\\[\n",
    "H_0: S_1(t) = S_2(t) \\quad \\text{for all } t.\n",
    "\\]\n",
    "\n",
    "At each event time (across both groups), we compute:\n",
    "\n",
    "- \\(n_j\\): total at risk just before time \\(t_j\\).  \n",
    "- \\(d_j\\): total events at \\(t_j\\).  \n",
    "- \\(n_{1j}, d_{1j}\\): at risk and events in group 1.  \n",
    "\n",
    "The log-rank statistic is based on:\n",
    "\n",
    "\\[\n",
    "O_1 - E_1 = \\sum_j (d_{1j} - E_{1j}), \\quad\n",
    "E_{1j} = d_j \\frac{n_{1j}}{n_j},\n",
    "\\]\n",
    "\n",
    "and its variance \\(V\\). Under \\(H_0\\),\n",
    "\n",
    "\\[\n",
    "Z = \\frac{O_1 - E_1}{\\sqrt{V}} \\approx \\mathcal{N}(0,1),\n",
    "\\]\n",
    "\n",
    "so \\(Z^2\\) is approximately \\(\\chi^2_1\\). We return a two-sided p-value based on \\(Z\\).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398387d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def logrank_test_two_groups(\n",
    "    time: np.ndarray,\n",
    "    event: np.ndarray,\n",
    "    group: np.ndarray,\n",
    "    group_labels: Tuple[str, str] = (\"control\", \"treatment\"),\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"Perform a log-rank test for equality of survival in two groups.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    time : np.ndarray\n",
    "        Observed times (event or censoring).\n",
    "    event : np.ndarray\n",
    "        Event indicators (1 = event, 0 = censored).\n",
    "    group : np.ndarray\n",
    "        Group labels (must contain exactly the two group_labels).\n",
    "    group_labels : tuple of str\n",
    "        Names of the two groups, e.g. (\"control\", \"treatment\").\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    z_stat : float\n",
    "        Log-rank z-statistic (signed).\n",
    "    p_value : float\n",
    "        Two-sided p-value based on N(0,1).\n",
    "    \"\"\"\n",
    "    time = np.asarray(time, dtype=float)\n",
    "    event = np.asarray(event, dtype=int)\n",
    "    group = np.asarray(group)\n",
    "\n",
    "    g1, g2 = group_labels\n",
    "\n",
    "    # Sort by time\n",
    "    order = np.argsort(time)\n",
    "    t_sorted = time[order]\n",
    "    e_sorted = event[order]\n",
    "    g_sorted = group[order]\n",
    "\n",
    "    # Unique event times across both groups\n",
    "    unique_times = np.unique(t_sorted[e_sorted == 1])\n",
    "\n",
    "    O1_minus_E1 = 0.0\n",
    "    V1 = 0.0\n",
    "\n",
    "    n_total = time.size\n",
    "\n",
    "    for t_j in unique_times:\n",
    "        # At risk just before t_j\n",
    "        at_risk = t_sorted >= t_j\n",
    "        n_j = float(np.sum(at_risk))\n",
    "        if n_j <= 1.0:\n",
    "            continue\n",
    "\n",
    "        # Events at t_j\n",
    "        at_time = (t_sorted == t_j)\n",
    "        d_j = float(np.sum(at_time & (e_sorted == 1)))\n",
    "        if d_j == 0.0:\n",
    "            continue\n",
    "\n",
    "        # Group 1 at risk and events\n",
    "        risk_g1 = at_risk & (g_sorted == g1)\n",
    "        n_1j = float(np.sum(risk_g1))\n",
    "        d_1j = float(np.sum(at_time & (e_sorted == 1) & (g_sorted == g1)))\n",
    "\n",
    "        if n_1j == 0.0 or n_1j == n_j:\n",
    "            continue\n",
    "\n",
    "        # Expected events in group 1 under H0\n",
    "        E_1j = d_j * (n_1j / n_j)\n",
    "\n",
    "        # Variance contribution\n",
    "        V_1j = (\n",
    "            (n_1j * (n_j - n_1j) * d_j * (n_j - d_j))\n",
    "            / (n_j ** 2 * (n_j - 1.0))\n",
    "        )\n",
    "\n",
    "        O1_minus_E1 += (d_1j - E_1j)\n",
    "        V1 += V_1j\n",
    "\n",
    "    if V1 <= 0.0:\n",
    "        raise ValueError(\"Log-rank variance is zero; check data.\")\n",
    "\n",
    "    z = O1_minus_E1 / math.sqrt(V1)\n",
    "\n",
    "    # two-sided p-value via normal approximation\n",
    "    cdf = 0.5 * (1.0 + math.erf(z / math.sqrt(2.0)))\n",
    "    p = 2.0 * min(cdf, 1.0 - cdf)\n",
    "    return float(z), float(p)\n",
    "\n",
    "\n",
    "z_lr, p_lr = logrank_test_two_groups(\n",
    "    time=df[\"time\"].to_numpy(),\n",
    "    event=df[\"event\"].to_numpy(),\n",
    "    group=df[\"group\"].to_numpy(),\n",
    "    group_labels=(\"control\", \"treatment\"),\n",
    ")\n",
    "z_lr, p_lr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289b0905",
   "metadata": {},
   "source": [
    "\n",
    "The log-rank test gives a **global comparison** of survival curves between control and treatment.\n",
    "\n",
    "- Large |z| and small p-value ⇒ evidence that retention differs between the arms.  \n",
    "- It is the standard test used in clinical trials and many production retention experiments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69ed3e2",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Cox proportional hazards model (optional)\n",
    "\n",
    "The **Cox proportional hazards model** is a semi-parametric regression model for survival data:\n",
    "\n",
    "\\[\n",
    "h(t \\mid X) = h_0(t) \\exp(\\beta^\\top X),\n",
    "\\]\n",
    "\n",
    "where:\n",
    "\n",
    "- \\(h_0(t)\\) is an unspecified baseline hazard,  \n",
    "- \\(X\\) are covariates (e.g. treatment arm, pre-activity),  \n",
    "- \\(\\beta\\) are log hazard ratios.\n",
    "\n",
    "This model allows us to:\n",
    "\n",
    "- Adjust for covariates like `pre_activity`, country, device, etc.  \n",
    "- Estimate a **hazard ratio for treatment** while controlling for these factors.\n",
    "\n",
    "Below we fit a Cox model if `lifelines` is available in the environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501701c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if CoxPHFitter is None:\n",
    "    print(\"lifelines not available; skipping Cox model fit.\")\n",
    "else:\n",
    "    df_cox = df.copy()\n",
    "    df_cox[\"treat_flag\"] = (df_cox[\"group\"] == \"treatment\").astype(int)\n",
    "\n",
    "    # Keep only the columns we need for CoxPHFitter\n",
    "    df_cox_input = df_cox[[\"time\", \"event\", \"treat_flag\", \"pre_activity\"]]\n",
    "\n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(df_cox_input, duration_col=\"time\", event_col=\"event\")\n",
    "    cph.print_summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1bf12f",
   "metadata": {},
   "source": [
    "\n",
    "Interpretation of the Cox model:\n",
    "\n",
    "- The coefficient for `treat_flag` corresponds to a **log hazard ratio** between treatment and control,  \n",
    "  *conditional* on `pre_activity`.  \n",
    "- `exp(coef)` is the estimated hazard ratio:\n",
    "  - < 1 ⇒ treatment reduces churn (improves retention).  \n",
    "  - > 1 ⇒ treatment increases churn (worse retention).\n",
    "\n",
    "This is a natural extension of log-rank: when you include only treatment as a covariate,\n",
    "the Cox score test is closely related to the log-rank test; adding extra covariates improves\n",
    "efficiency and controls for imbalances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77863bf7",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Practical notes for real retention experiments\n",
    "\n",
    "When applying this to real data:\n",
    "\n",
    "1. **Data preparation**\n",
    "   - Define a clear **start date** for each user (e.g. experiment exposure).  \n",
    "   - Compute time to churn or last activity, and an event indicator (churn vs censored).  \n",
    "   - Consider multiple churn definitions (e.g. 14 days inactive, 30 days inactive).\n",
    "\n",
    "2. **KM & log-rank first**\n",
    "   - Plot Kaplan–Meier curves by arm, with confidence bands if possible.  \n",
    "   - Run a log-rank test as the primary comparison of retention.\n",
    "\n",
    "3. **Cox model for adjustment**\n",
    "   - Include treatment and key covariates (`pre_activity`, geography, device).  \n",
    "   - Focus on the hazard ratio for treatment with its confidence interval.\n",
    "\n",
    "4. **Connect to D+1 / D+7 / D+30 metrics**\n",
    "   - Use the same survival data to compute binary retention at selected horizons.  \n",
    "   - This makes it easy to communicate results to non-technical stakeholders\n",
    "     while still using proper survival methods under the hood.\n",
    "\n",
    "5. **Guardrails and decisions**\n",
    "   - Combine retention with other metrics (revenue, engagement, complaints) as guardrails.  \n",
    "   - Use the same multi-metric decision patterns you already use for conversion and revenue.\n",
    "\n",
    "This notebook gives you the core building blocks for **“do users stick around?”** experiments\n",
    "with solid survival analysis foundations.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}