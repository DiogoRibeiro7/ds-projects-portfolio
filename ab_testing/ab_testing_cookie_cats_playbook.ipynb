{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "066f77e5",
   "metadata": {},
   "source": [
    "\n",
    "# Cookie Cats A/B Testing Playbook (gate_30 vs gate_40)\n",
    "\n",
    "This notebook is a self‑contained, **professional** A/B testing analysis using the well‑known **Cookie Cats** mobile game dataset.\n",
    "The experiment changes the level at which a gate is introduced (**30 vs 40**) and evaluates impact on **1‑day** and **7‑day** retention.\n",
    "\n",
    "> **Reproducibility:** This notebook is written to be run end‑to‑end. Markdown is in **English** throughout.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8ffeb6",
   "metadata": {},
   "source": [
    "\n",
    "## 0) What you'll learn & do\n",
    "\n",
    "- Load and validate the Cookie Cats A/B dataset.\n",
    "- Sanity checks including **SRM** (sample ratio mismatch).\n",
    "- Explore distributions and retention metrics (1‑day and 7‑day).\n",
    "- Frequentist inference: **two‑proportion z‑tests** and **bootstrap** confidence intervals.\n",
    "- Model‑based view: **GLM (Logit)** with fixed effects.\n",
    "- **CUPED** variance reduction using pre‑outcome covariate (`sum_gamerounds`).\n",
    "- **Power/MDE** planning helpers.\n",
    "- Clean **executive summary** and a **Next steps** section (sequential testing / bandits).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0b4285",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Setup\n",
    "\n",
    "We stick to NumPy, pandas, matplotlib; and use `statsmodels` for logistic regression (industry standard).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba7c16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Iterable\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (7, 4.5)\n",
    "plt.rcParams['axes.grid'] = True\n",
    "\n",
    "# Optional, used for GLM (logit)\n",
    "try:\n",
    "    from statsmodels.api import Logit, add_constant  # type: ignore\n",
    "except Exception as e:\n",
    "    Logit = None\n",
    "    add_constant = None\n",
    "    print(\"statsmodels not available; GLM cells will be skippable.\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4f9d5d",
   "metadata": {},
   "source": [
    "### Helpers (proportions, tests, bootstrap, power/MDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df2c7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass(frozen=True)\n",
    "class PropSummary:\n",
    "    p: float\n",
    "    n: int\n",
    "    x: int\n",
    "\n",
    "def summarize_prop(x: int, n: int) -> PropSummary:\n",
    "    if n <= 0: raise ValueError(\"n must be positive\")\n",
    "    if not (0 <= x <= n): raise ValueError(\"x must be in [0,n]\")\n",
    "    return PropSummary(p=x/n, n=n, x=x)\n",
    "\n",
    "def two_prop_ztest(x1: int, n1: int, x2: int, n2: int, two_sided: bool = True):\n",
    "    s1, s2 = summarize_prop(x1,n1), summarize_prop(x2,n2)\n",
    "    p_pool = (s1.x + s2.x) / (s1.n + s2.n)\n",
    "    se = math.sqrt(p_pool*(1-p_pool)*(1/s1.n + 1/s2.n))\n",
    "    if se == 0.0: raise ZeroDivisionError(\"SE=0; check inputs\")\n",
    "    z = (s2.p - s1.p)/se\n",
    "    p = 2*(1 - 0.5*(1 + math.erf(abs(z)/math.sqrt(2)))) if two_sided else (1 - 0.5*(1 + math.erf(z/math.sqrt(2))))\n",
    "    return z, p\n",
    "\n",
    "def bootstrap_ci_diff(pA: float, pB: float, nA: int, nB: int, B: int = 5000, alpha: float = 0.05):\n",
    "    diffs = np.empty(B, dtype=float)\n",
    "    for b in range(B):\n",
    "        xA = np.random.binomial(nA, pA)\n",
    "        xB = np.random.binomial(nB, pB)\n",
    "        diffs[b] = xB/nB - xA/nA\n",
    "    lo = float(np.quantile(diffs, alpha/2)); hi = float(np.quantile(diffs, 1-alpha/2))\n",
    "    return lo, hi\n",
    "\n",
    "def chisq_srm(nA: int, nB: int) -> float:\n",
    "    n = nA + nB\n",
    "    exp = [n/2, n/2]; obs = [nA, nB]\n",
    "    chi2 = sum((o-e)**2/e for o,e in zip(obs,exp))\n",
    "    return 2 * (1 - 0.5*(1 + math.erf(math.sqrt(chi2)/math.sqrt(2))))\n",
    "\n",
    "def invPhi(u: float) -> float:\n",
    "    return math.sqrt(2) * math.erfcinv(2*(1-u))\n",
    "\n",
    "def required_n_two_proportions(pA: float, pB: float, alpha: float = 0.05, power: float = 0.8, two_sided: bool = True) -> int:\n",
    "    z_alpha = abs(invPhi(1 - alpha/2)) if two_sided else abs(invPhi(1 - alpha))\n",
    "    z_beta = abs(invPhi(power))\n",
    "    pbar = 0.5*(pA+pB)\n",
    "    delta = abs(pB - pA)\n",
    "    if delta == 0.0: raise ValueError(\"delta=0 → infinite n\")\n",
    "    se = math.sqrt(2*pbar*(1-pbar))\n",
    "    n = ((z_alpha + z_beta)*se/delta)**2\n",
    "    return int(math.ceil(n))\n",
    "\n",
    "def mde_for_n(pA: float, n_per_arm: int, alpha: float = 0.05, power: float = 0.8, two_sided: bool = True) -> float:\n",
    "    z_alpha = abs(invPhi(1 - alpha/2)) if two_sided else abs(invPhi(1 - alpha))\n",
    "    z_beta = abs(invPhi(power))\n",
    "    se = math.sqrt(2*pA*(1-pA))\n",
    "    return float((z_alpha + z_beta) * se / math.sqrt(max(n_per_arm,1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f649e03d",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Data: load & validate\n",
    "\n",
    "**Where to get the data:**  \n",
    "The Cookie Cats CSV (`cookie_cats.csv`) is widely mirrored in public repos.  \n",
    "- If you have it locally, put it under `data/cookie_cats.csv`.  \n",
    "- Otherwise, set `REMOTE_URL` to a raw CSV URL you trust (e.g., a public GitHub mirror).\n",
    "\n",
    "**Expected columns (typical):**\n",
    "- `userid` (unique player ID)\n",
    "- `version` (`gate_30` or `gate_40`)\n",
    "- `sum_gamerounds` (number of game rounds during observation window)\n",
    "- `retention_1` (1‑day retention, 0/1)\n",
    "- `retention_7` (7‑day retention, 0/1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feb3370",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "LOCAL_PATHS = [Path(\"data/cookie_cats.csv\"), Path(\"cookie_cats.csv\")]\n",
    "REMOTE_URL = None  # e.g., \"https://raw.githubusercontent.com/....../cookie_cats.csv\"\n",
    "\n",
    "def load_cookie_cats() -> pd.DataFrame:\n",
    "    for p in LOCAL_PATHS:\n",
    "        if p.exists():\n",
    "            return pd.read_csv(p)\n",
    "    if REMOTE_URL:\n",
    "        return pd.read_csv(REMOTE_URL)\n",
    "    raise FileNotFoundError(\"Provide cookie_cats.csv locally (data/ or CWD) or set REMOTE_URL.\")\n",
    "\n",
    "df = load_cookie_cats()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09e37c8",
   "metadata": {},
   "source": [
    "### 2.1 Basic hygiene & SRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbf77cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.drop_duplicates(subset=[\"userid\"], keep=\"first\").copy()\n",
    "assert set(df[\"version\"].unique()) <= {\"gate_30\",\"gate_40\"}, \"Unexpected version labels.\"\n",
    "nA = (df[\"version\"]==\"gate_30\").sum()\n",
    "nB = (df[\"version\"]==\"gate_40\").sum()\n",
    "p_srm = chisq_srm(nA, nB)\n",
    "nA, nB, p_srm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397a3852",
   "metadata": {},
   "source": [
    "\n",
    "## 3) EDA & Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c115834",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summ = df.groupby(\"version\")[[\"retention_1\",\"retention_7\",\"sum_gamerounds\"]].agg([\"mean\",\"median\",\"std\",\"count\"])\n",
    "summ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fa43a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "for v in [\"gate_30\",\"gate_40\"]:\n",
    "    vals = df.loc[df[\"version\"]==v, \"sum_gamerounds\"].values\n",
    "    plt.hist(vals, bins=40, alpha=0.5, label=v)\n",
    "plt.title(\"sum_gamerounds by version\")\n",
    "plt.xlabel(\"sum_gamerounds\"); plt.ylabel(\"count\"); plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f1206b",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Primary inference: 1‑day & 7‑day retention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b8afe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def proportion_table(df: pd.DataFrame, col: str) -> pd.DataFrame:\n",
    "    grp = df.groupby(\"version\")[col].agg([\"sum\",\"count\",\"mean\"]).rename(columns={\"sum\":\"x\",\"count\":\"n\",\"mean\":\"rate\"})\n",
    "    A = summarize_prop(int(grp.loc[\"gate_30\",\"x\"]), int(grp.loc[\"gate_30\",\"n\"]))\n",
    "    B = summarize_prop(int(grp.loc[\"gate_40\",\"x\"]), int(grp.loc[\"gate_40\",\"n\"]))\n",
    "    z, p = two_prop_ztest(A.x, A.n, B.x, B.n, two_sided=True)\n",
    "    lo, hi = bootstrap_ci_diff(A.p, B.p, A.n, B.n, B=3000, alpha=0.05)\n",
    "    abs_lift = B.p - A.p\n",
    "    out = pd.DataFrame({\n",
    "        \"metric\":[col, col],\n",
    "        \"arm\":[\"gate_30\",\"gate_40\"],\n",
    "        \"n\":[A.n, B.n],\n",
    "        \"x\":[A.x, B.x],\n",
    "        \"rate\":[A.p, B.p],\n",
    "        \"ztest_pvalue\":[p, p],\n",
    "        \"abs_lift_B_minus_A\":[abs_lift, abs_lift],\n",
    "        \"boot95_lo\":[lo, lo],\n",
    "        \"boot95_hi\":[hi, hi],\n",
    "    })\n",
    "    return out\n",
    "\n",
    "t1 = proportion_table(df, \"retention_1\")\n",
    "t7 = proportion_table(df, \"retention_7\")\n",
    "t1, t7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22500ae2",
   "metadata": {},
   "source": [
    "### 4.1 GLM (logit) perspective (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86ab5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if Logit is not None and add_constant is not None:\n",
    "    df_glm = df.copy()\n",
    "    df_glm[\"treatment\"] = (df_glm[\"version\"]==\"gate_40\").astype(int)\n",
    "    df_glm[\"rounds_bin\"] = pd.qcut(df_glm[\"sum_gamerounds\"], q=10, duplicates=\"drop\")\n",
    "    X = pd.get_dummies(df_glm[[\"treatment\",\"rounds_bin\"]], drop_first=True).astype(float)\n",
    "    Xc = add_constant(X)\n",
    "    y1 = df_glm[\"retention_1\"].astype(int).to_numpy()\n",
    "    y7 = df_glm[\"retention_7\"].astype(int).to_numpy()\n",
    "    mdl1 = Logit(y1, Xc).fit(disp=False)\n",
    "    mdl7 = Logit(y7, Xc).fit(disp=False)\n",
    "    coef_t1 = mdl1.params.get(\"treatment\", float(\"nan\")); se_t1 = mdl1.bse.get(\"treatment\", float(\"nan\"))\n",
    "    z_t1 = coef_t1 / se_t1 if se_t1 not in (0.0, float(\"nan\")) else float(\"nan\")\n",
    "    p_t1 = 2*(1 - 0.5*(1 + math.erf(abs(z_t1)/math.sqrt(2)))) if not math.isnan(z_t1) else float(\"nan\")\n",
    "    coef_t7 = mdl7.params.get(\"treatment\", float(\"nan\")); se_t7 = mdl7.bse.get(\"treatment\", float(\"nan\"))\n",
    "    z_t7 = coef_t7 / se_t7 if se_t7 not in (0.0, float(\"nan\")) else float(\"nan\")\n",
    "    p_t7 = 2*(1 - 0.5*(1 + math.erf(abs(z_t7)/math.sqrt(2)))) if not math.isnan(z_t7) else float(\"nan\")\n",
    "    pd.DataFrame({\"metric\":[\"retention_1\",\"retention_7\"],\n",
    "                  \"coef_treatment\":[coef_t1, coef_t7],\n",
    "                  \"se\":[se_t1, se_t7],\n",
    "                  \"z\":[z_t1, z_t7],\n",
    "                  \"p_value\":[p_t1, p_t7]})\n",
    "else:\n",
    "    print(\"statsmodels not available; skip GLM cells.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc075b38",
   "metadata": {},
   "source": [
    "## 5) CUPED (variance reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9bc465",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cuped_adjust(y: np.ndarray, x: np.ndarray):\n",
    "    y = np.asarray(y, dtype=float); x = np.asarray(x, dtype=float)\n",
    "    if y.shape != x.shape: raise ValueError(\"y and x must have same shape\")\n",
    "    vx = np.var(x)\n",
    "    if vx == 0.0: return y.copy(), 0.0\n",
    "    theta = float(np.cov(y, x, ddof=1)[0,1] / vx)\n",
    "    x_centered = x - float(np.mean(x))\n",
    "    return y - theta * x_centered, theta\n",
    "\n",
    "def cuped_on_metric(df: pd.DataFrame, metric: str, covariate: str = \"sum_gamerounds\") -> pd.DataFrame:\n",
    "    d = df[[\"version\", metric, covariate]].dropna().copy()\n",
    "    y_adj, theta = cuped_adjust(d[metric].to_numpy().astype(float), d[covariate].to_numpy().astype(float))\n",
    "    d[\"y_adj\"] = y_adj\n",
    "    grp = d.groupby(\"version\")[\"y_adj\"].agg([\"mean\",\"count\"])\n",
    "    A_mean, A_n = float(grp.loc[\"gate_30\",\"mean\"]), int(grp.loc[\"gate_30\",\"count\"])\n",
    "    B_mean, B_n = float(grp.loc[\"gate_40\",\"mean\"]), int(grp.loc[\"gate_40\",\"count\"])\n",
    "    pooled_var = float(np.var(y_adj, ddof=1))\n",
    "    se = math.sqrt(pooled_var*(1/A_n + 1/B_n))\n",
    "    z = (B_mean - A_mean)/se if se>0 else float(\"nan\")\n",
    "    p = 2*(1 - 0.5*(1 + math.erf(abs(z)/math.sqrt(2)))) if not math.isnan(z) else float(\"nan\")\n",
    "    return pd.DataFrame({\"metric\":[metric],\"theta\":[theta],\"A_mean_adj\":[A_mean],\"B_mean_adj\":[B_mean],\"z\":[z],\"p_value\":[p]})\n",
    "\n",
    "cuped_1 = cuped_on_metric(df, \"retention_1\")\n",
    "cuped_7 = cuped_on_metric(df, \"retention_7\")\n",
    "cuped_1, cuped_7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ed00c8",
   "metadata": {},
   "source": [
    "## 6) Power & MDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d8fde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pA_1 = df.loc[df[\"version\"]==\"gate_30\",\"retention_1\"].mean()\n",
    "pA_7 = df.loc[df[\"version\"]==\"gate_30\",\"retention_7\"].mean()\n",
    "n_per_arm_1 = min((df[\"version\"]==\"gate_30\").sum(), (df[\"version\"]==\"gate_40\").sum())\n",
    "mde_1 = mde_for_n(pA_1, n_per_arm_1)\n",
    "mde_7 = mde_for_n(pA_7, n_per_arm_1)\n",
    "pd.DataFrame({\"metric\":[\"retention_1\",\"retention_7\"],\n",
    "              \"baseline_rate(A)\":[pA_1, pA_7],\n",
    "              \"n_per_arm\":[n_per_arm_1, n_per_arm_1],\n",
    "              \"MDE_abs_at_80%_power\":[mde_1, mde_7]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcecaee7",
   "metadata": {},
   "source": [
    "## 7) Executive summary (for decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e37941a",
   "metadata": {},
   "source": [
    "## 8) Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092f0410",
   "metadata": {},
   "source": [
    "\n",
    "### 5.1 Sequential testing (Pocock / O'Brien–Fleming)\n",
    "\n",
    "In mobile A/B tests, it is very common to **peek** at the results every day.\n",
    "If you keep using a fixed two-sided 0.05 threshold at every look, you inflate your **Type I error**.\n",
    "\n",
    "Group-sequential methods (e.g., **Pocock**, **O'Brien–Fleming**) give you a **schedule of critical z-values**\n",
    "for a fixed number of planned looks. This lets you:\n",
    "\n",
    "- Inspect results mid-test without losing Type I control.\n",
    "- Possibly stop early for strong wins or clear losses.\n",
    "\n",
    "Here we construct critical |z| boundaries for O'Brien–Fleming and Pocock for a few information fractions.\n",
    "You can think of information fractions as “percentage of the total planned information / sample size”\n",
    "if the allocation is reasonably stable over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b372e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "from typing import List\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def Phi(z: float) -> float:\n",
    "    \"\"\"Standard normal CDF.\"\"\"\n",
    "    return 0.5 * (1.0 + math.erf(z / math.sqrt(2.0)))\n",
    "\n",
    "def Phi_inv(p: float) -> float:\n",
    "    \"\"\"Inverse standard normal CDF using erfcinv.\"\"\"\n",
    "    if not 0.0 < p < 1.0:\n",
    "        raise ValueError(\"p must be in (0,1)\")\n",
    "    return math.sqrt(2.0) * math.erfcinv(2.0 * (1.0 - p))\n",
    "\n",
    "def obrien_fleming_boundaries(info_fracs: List[float], alpha: float = 0.05) -> List[float]:\n",
    "    \"\"\"\n",
    "    Two-sided O'Brien–Fleming boundaries:\n",
    "    critical |z_i| = z_alpha / sqrt(t_i), where t_i is the information fraction of look i.\n",
    "    Very conservative early (higher |z|), more permissive near the final look.\n",
    "    \"\"\"\n",
    "    if not info_fracs:\n",
    "        raise ValueError(\"info_fracs must be a non-empty list.\")\n",
    "    if not all(0.0 < t <= 1.0 for t in info_fracs):\n",
    "        raise ValueError(\"All information fractions must be in (0,1].\")\n",
    "\n",
    "    z_alpha = Phi_inv(1.0 - alpha / 2.0)  # two-sided\n",
    "    return [float(z_alpha / math.sqrt(t)) for t in info_fracs]\n",
    "\n",
    "def pocock_boundaries(K: int, alpha: float = 0.05) -> List[float]:\n",
    "    \"\"\"\n",
    "    Two-sided Pocock boundaries (approximation).\n",
    "    Uses a constant critical |z| for all looks.\n",
    "    For alpha=0.05 and 2 <= K <= 10, the critical |z| is ~2.414.\n",
    "    \"\"\"\n",
    "    if not (2 <= K <= 10):\n",
    "        raise ValueError(\"K must be between 2 and 10 for this approximation.\")\n",
    "    crit = 2.414  # tabulated approximate value for two-sided alpha=0.05\n",
    "    return [crit] * K\n",
    "\n",
    "# Example: 4 looks at 25%, 50%, 75%, 100% of total information\n",
    "info_fracs = [0.25, 0.50, 0.75, 1.00]\n",
    "obf_crit = obrien_fleming_boundaries(info_fracs, alpha=0.05)\n",
    "poc_crit = pocock_boundaries(len(info_fracs), alpha=0.05)\n",
    "\n",
    "# Plot the boundaries\n",
    "plt.figure()\n",
    "plt.plot(info_fracs, obf_crit, marker=\"o\", label=\"O'Brien–Fleming |z|\")\n",
    "plt.plot(info_fracs, poc_crit, marker=\"s\", label=\"Pocock |z|\")\n",
    "plt.title(\"Critical |z| by information fraction (two-sided α=0.05)\")\n",
    "plt.xlabel(\"Information fraction\")\n",
    "plt.ylabel(\"Critical |z|\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"look\": range(1, len(info_fracs) + 1),\n",
    "        \"info_fraction\": info_fracs,\n",
    "        \"OBF_crit_z\": obf_crit,\n",
    "        \"Pocock_crit_z\": poc_crit,\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4447b8f",
   "metadata": {},
   "source": [
    "\n",
    "**How to use this in practice**\n",
    "\n",
    "- Choose in advance how many **looks** you want (for example, 4 looks at days 3, 5, 7, and 10).\n",
    "  Map those to **information fractions** (e.g. 0.25, 0.5, 0.75, 1.0).\n",
    "- At each look, compute your usual z-statistic for the primary metric, but compare `|z|`\n",
    "  to the **look-specific** threshold instead of 1.96.\n",
    "- With O'Brien–Fleming you almost never stop at very early looks unless the effect is very large.\n",
    "- Pocock uses a constant threshold, so it is more willing to stop early and slightly less powerful\n",
    "  at the final look.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88574db",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Bandits vs static A/B — Thompson Sampling (simulation)\n",
    "\n",
    "So far in this notebook, we assumed a **static 50/50 split** between `gate_30` and `gate_40`.\n",
    "\n",
    "Sometimes you want to **optimize reward during the test**, not just at the end.\n",
    "A popular approach is a **multi-armed bandit**, such as **Thompson Sampling** for Bernoulli rewards:\n",
    "\n",
    "- Arms = variants (e.g., `gate_30`, `gate_40`).\n",
    "- Reward = retention or conversion (0/1 per user).\n",
    "- At each step, sample a parameter for each arm from its posterior and choose the arm with the largest sample.\n",
    "- This automatically trades off exploration and exploitation.\n",
    "\n",
    "Below we simulate Thompson Sampling in a toy setting, not with the real Cookie Cats data\n",
    "(because the real experiment was not run as a bandit).\n",
    "The goal is to understand the mechanics and the **regret** comparison versus a fixed 50/50 policy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98629d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def simulate_thompson_two_arms(\n",
    "    pA: float,\n",
    "    pB: float,\n",
    "    T: int = 8000,\n",
    "    seed: int | None = 7,\n",
    ") -> Tuple[np.ndarray, np.ndarray, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Simulate Thompson Sampling for two Bernoulli arms (A and B).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pA, pB : float\n",
    "        True success probabilities for arm A and arm B.\n",
    "    T : int\n",
    "        Number of rounds (users) to simulate.\n",
    "    seed : int | None\n",
    "        Random seed for reproducibility.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    regret_ts : np.ndarray\n",
    "        Cumulative regret under Thompson Sampling.\n",
    "    regret_fixed : np.ndarray\n",
    "        Cumulative regret under a static 50/50 policy.\n",
    "    log_df : pd.DataFrame\n",
    "        A log of the TS run with columns:\n",
    "        - t: time step (0..T-1)\n",
    "        - arm: 0 or 1\n",
    "        - reward: 0 or 1\n",
    "        - prop: estimated propensity of chosen arm at that step.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Beta(1,1) priors for each arm\n",
    "    aA = bA = 1.0\n",
    "    aB = bB = 1.0\n",
    "\n",
    "    best = max(pA, pB)\n",
    "\n",
    "    regret_ts = np.zeros(T, dtype=float)\n",
    "    regret_fixed = np.zeros(T, dtype=float)\n",
    "    cum_reg_ts = 0.0\n",
    "    cum_reg_fixed = 0.0\n",
    "\n",
    "    rows: list[tuple[int, int, int, float]] = []\n",
    "\n",
    "    for t in range(T):\n",
    "        # Sample one theta from each posterior to choose the arm\n",
    "        thetaA = rng.beta(aA, bA)\n",
    "        thetaB = rng.beta(aB, bB)\n",
    "\n",
    "        # Approximate action probabilities using Monte Carlo under the current posterior\n",
    "        # This is used to estimate propensities for IPW later.\n",
    "        thetasA = rng.beta(aA, bA, size=200)\n",
    "        thetasB = rng.beta(aB, bB, size=200)\n",
    "        p_choose_A = float(np.mean(thetasA >= thetasB))\n",
    "        p_choose_B = 1.0 - p_choose_A\n",
    "\n",
    "        arm = 0 if thetaA >= thetaB else 1\n",
    "\n",
    "        # Draw rewards for each arm for this \"user\"\n",
    "        rewardA = rng.binomial(1, pA)\n",
    "        rewardB = rng.binomial(1, pB)\n",
    "        reward = rewardA if arm == 0 else rewardB\n",
    "\n",
    "        # Update posterior of the chosen arm\n",
    "        if arm == 0:\n",
    "            aA += reward\n",
    "            bA += 1 - reward\n",
    "            prop = p_choose_A\n",
    "        else:\n",
    "            aB += reward\n",
    "            bB += 1 - reward\n",
    "            prop = p_choose_B\n",
    "\n",
    "        # Regret vs always pulling the best arm\n",
    "        chosen_p = pA if arm == 0 else pB\n",
    "        cum_reg_ts += best - chosen_p\n",
    "        regret_ts[t] = cum_reg_ts\n",
    "\n",
    "        # Static 50/50 expected regret\n",
    "        fixed_p = 0.5 * pA + 0.5 * pB\n",
    "        cum_reg_fixed += best - fixed_p\n",
    "        regret_fixed[t] = cum_reg_fixed\n",
    "\n",
    "        rows.append((t, arm, reward, prop))\n",
    "\n",
    "    log_df = pd.DataFrame(rows, columns=[\"t\", \"arm\", \"reward\", \"prop\"])\n",
    "    return regret_ts, regret_fixed, log_df\n",
    "\n",
    "# Example: two variants with a small difference in 7-day retention\n",
    "pA_demo = 0.18\n",
    "pB_demo = 0.20\n",
    "\n",
    "reg_ts, reg_fixed, log_ts = simulate_thompson_two_arms(pA_demo, pB_demo, T=8000, seed=11)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(1, len(reg_ts) + 1), reg_ts, label=\"Thompson Sampling\")\n",
    "plt.plot(np.arange(1, len(reg_fixed) + 1), reg_fixed, label=\"Fixed 50/50\")\n",
    "plt.title(\"Cumulative regret — TS vs static policy\")\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Cumulative regret\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "log_ts.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f53ed3",
   "metadata": {},
   "source": [
    "\n",
    "### 6.1 Inference under adaptive allocation — IPW and DR\n",
    "\n",
    "With **adaptive allocation** (bandits), the probability of receiving each arm depends on time\n",
    "and on past data. If you ignore this and just compute simple differences in means,\n",
    "your estimate of the treatment effect is generally **biased**.\n",
    "\n",
    "Two important tools:\n",
    "\n",
    "- **IPW (Inverse Propensity Weighting)**: reweight each observation by the inverse of the\n",
    "  probability of receiving the arm it actually received.\n",
    "- **DR (Doubly-Robust)**: combines IPW with an **outcome model** and remains consistent if\n",
    "  either the propensity model *or* the outcome model is correctly specified.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4627e2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Dict\n",
    "\n",
    "def ipw_ate_from_log(df: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    IPW estimate of average treatment effect from a bandit log.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Must contain columns:\n",
    "        - arm: 0 or 1\n",
    "        - reward: 0/1\n",
    "        - prop: estimated propensity of the chosen arm at each time step.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Estimated difference in success probabilities (arm 1 minus arm 0).\n",
    "    \"\"\"\n",
    "    required_cols = {\"arm\", \"reward\", \"prop\"}\n",
    "    if not required_cols.issubset(df.columns):\n",
    "        raise ValueError(f\"df must contain columns {required_cols}\")\n",
    "\n",
    "    t = df[\"arm\"].to_numpy()\n",
    "    y = df[\"reward\"].to_numpy()\n",
    "    prop = np.clip(df[\"prop\"].to_numpy(), 1e-6, 1.0)\n",
    "\n",
    "    # Inverse propensity weights\n",
    "    w = 1.0 / prop\n",
    "    w1 = w * t\n",
    "    w0 = w * (1 - t)\n",
    "\n",
    "    p1_hat = (w1 * y).sum() / max(w1.sum(), 1e-12)\n",
    "    p0_hat = (w0 * y).sum() / max(w0.sum(), 1e-12)\n",
    "\n",
    "    return float(p1_hat - p0_hat)\n",
    "\n",
    "def dr_ate_constant(df: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Doubly-Robust ATE with constant outcome models for each arm.\n",
    "\n",
    "    This is the simplest DR version:\n",
    "    - m1(x) = mean reward for arm 1\n",
    "    - m0(x) = mean reward for arm 0\n",
    "    and we combine them with IPW residual corrections.\n",
    "    \"\"\"\n",
    "    required_cols = {\"arm\", \"reward\", \"prop\"}\n",
    "    if not required_cols.issubset(df.columns):\n",
    "        raise ValueError(f\"df must contain columns {required_cols}\")\n",
    "\n",
    "    t = df[\"arm\"].to_numpy()\n",
    "    y = df[\"reward\"].to_numpy()\n",
    "    prop = np.clip(df[\"prop\"].to_numpy(), 1e-6, 1.0)\n",
    "\n",
    "    # Outcome models\n",
    "    m1 = float(df.loc[df[\"arm\"] == 1, \"reward\"].mean())\n",
    "    m0 = float(df.loc[df[\"arm\"] == 0, \"reward\"].mean())\n",
    "\n",
    "    # DR term\n",
    "    term = (m1 - m0) + (t * (y - m1) / prop) - ((1.0 - t) * (y - m0) / (1.0 - prop))\n",
    "    return float(np.mean(term))\n",
    "\n",
    "ate_ipw_demo: float = ipw_ate_from_log(log_ts)\n",
    "ate_dr_demo: float = dr_ate_constant(log_ts)\n",
    "\n",
    "{\n",
    "    \"true_diff\": pB_demo - pA_demo,\n",
    "    \"IPW_ATE\": ate_ipw_demo,\n",
    "    \"DR_ATE_const\": ate_dr_demo,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5892608",
   "metadata": {},
   "source": [
    "\n",
    "**Interpretation**\n",
    "\n",
    "- `true_diff` is the true success-probability difference we used to simulate the bandit.\n",
    "- `IPW_ATE` and `DR_ATE_const` are two ways of recovering that effect under adaptive allocation.\n",
    "- In real experiments:\n",
    "  - You should log **propensities** whenever you use a bandit or any adaptive policy.\n",
    "  - If you have user features \\(X\\), you can fit richer outcome models (e.g., logistic regression)\n",
    "    and use a fully **doubly-robust** estimator.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4ebb05",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Executive summary and decision template\n",
    "\n",
    "When the notebook is run on the real `cookie_cats.csv`, you will have:\n",
    "\n",
    "- Baseline 1-day and 7-day retention for `gate_30`.\n",
    "- Absolute lifts and 95% CIs for `gate_40` vs `gate_30`.\n",
    "- CUPED-adjusted tests (using `sum_gamerounds`).\n",
    "- MDE at 80% power for each metric.\n",
    "\n",
    "A concise, decision-grade executive summary should cover:\n",
    "\n",
    "1. **Sanity checks**\n",
    "   - SRM p-value for the user split between `gate_30` and `gate_40`.\n",
    "   - Any data quality issues (missing fields, outliers, logging changes).\n",
    "\n",
    "2. **Primary metrics and effect sizes**\n",
    "   - 1-day retention difference with 95% CI and p-value.\n",
    "   - 7-day retention difference with 95% CI and p-value.\n",
    "   - CUPED results for the same metrics and how they compare to the raw tests.\n",
    "\n",
    "3. **Power & MDE context**\n",
    "   - Whether the observed CIs and MDE indicate that “no meaningful effect” is plausible,\n",
    "     or whether the experiment was underpowered.\n",
    "\n",
    "4. **Decision and rollout plan**\n",
    "   - **Ship**: if the effect is positive, practically meaningful (above MDE) and robust across methods.\n",
    "   - **Hold / rerun**: if CIs include both small positive and negative effects, or if power is insufficient.\n",
    "   - **Roll back**: if there is strong evidence of harm (e.g. 7-day retention clearly lower).\n",
    "\n",
    "A concrete narrative template:\n",
    "\n",
    "> SRM check for the user split passed (p = ...), suggesting randomization is sound.  \n",
    "> 1-day retention improved by Δ₁ = ... percentage points (95% CI [..., ...], p = ...).  \n",
    "> 7-day retention improved by Δ₇ = ... percentage points (95% CI [..., ...], p = ...).  \n",
    "> CUPED with `sum_gamerounds` yields similar direction and slightly tighter intervals (p = ...).  \n",
    "> The MDE at 80% power for 7-day retention is ... pp, and the observed lift is (above / below) that threshold.  \n",
    "> Given the estimated uplift and business value per retained user, we recommend **(ship / hold / roll back)**,\n",
    "> with a rollout plan of (25% → 50% → 100%) and ongoing monitoring of retention and monetisation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31b5328",
   "metadata": {},
   "source": [
    "\n",
    "### 5.2 Lan–DeMets α-spending (OBF-like and Pocock-like)\n",
    "\n",
    "Group-sequential tests can be expressed in terms of how they **spend Type I error** over time.\n",
    "The Lan–DeMets framework defines a **spending function** \\(\\alpha(t)\\) where \\(t \\in (0,1]\\) is the\n",
    "information fraction.\n",
    "\n",
    "Two popular choices:\n",
    "\n",
    "- **OBF-like spending**: very conservative early, spends most of \\(\\alpha\\) near the end.  \n",
    "- **Pocock-like spending**: spends \\(\\alpha\\) more uniformly across looks.\n",
    "\n",
    "For discrete looks \\(0 < t_1 < \\dots < t_K \\leq 1\\), the incremental spending at look \\(i\\) is\n",
    "\\(\\alpha_i = \\alpha(t_i) - \\alpha(t_{i-1})\\) (with \\(\\alpha(t_0) = 0\\)).\n",
    "We can then approximate critical \\(|z_i|\\) by treating \\(\\alpha_i\\) as a two-sided error\n",
    "piece at that look and computing \\(z_i \\approx \\Phi^{-1}(1 - \\alpha_i / 2)\\).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abccdada",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def Phi_ld(z: float) -> float:\n",
    "    \"\"\"Standard normal CDF (duplicate name to avoid conflicts).\"\"\"\n",
    "    return 0.5 * (1.0 + math.erf(z / math.sqrt(2.0)))\n",
    "\n",
    "def Phi_inv_ld(p: float) -> float:\n",
    "    \"\"\"Inverse standard normal CDF using erfcinv for Lan–DeMets helpers.\"\"\"\n",
    "    if not 0.0 < p < 1.0:\n",
    "        raise ValueError(\"p must be in (0,1)\")\n",
    "    return math.sqrt(2.0) * math.erfcinv(2.0 * (1.0 - p))\n",
    "\n",
    "def spending_obf_like(t: np.ndarray, alpha: float = 0.05) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    O'Brien–Fleming-like alpha-spending function (approximate).\n",
    "    This function is small for small t and approaches alpha as t -> 1.\n",
    "    \"\"\"\n",
    "    z = Phi_inv_ld(1.0 - alpha / 2.0)\n",
    "    t_clipped = np.clip(t, 1e-6, 1.0)\n",
    "    # One common approximation for OBF-like spending:\n",
    "    return 2.0 - 2.0 * Phi_ld(z / np.sqrt(t_clipped))\n",
    "\n",
    "def spending_pocock_like(t: np.ndarray, alpha: float = 0.05) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Pocock-like alpha-spending function (approximate).\n",
    "    Spends alpha more uniformly over information fraction.\n",
    "    \"\"\"\n",
    "    t_clipped = np.clip(t, 1e-6, 1.0)\n",
    "    return alpha * np.log(1.0 + (math.e - 1.0) * t_clipped)\n",
    "\n",
    "def lan_demets_boundaries(info_fracs, alpha: float = 0.05, kind: str = \"OBF\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute approximate Lan–DeMets-style alpha-spending and critical z per look.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    info_fracs : sequence of float\n",
    "        Monotone increasing information fractions in (0,1].\n",
    "    alpha : float\n",
    "        Global two-sided alpha.\n",
    "    kind : {\"OBF\", \"Pocock\"}\n",
    "        Spending function flavor.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame with columns: look, t, alpha_cum, alpha_inc, crit_z.\n",
    "    \"\"\"\n",
    "    t = np.asarray(info_fracs, dtype=float)\n",
    "    if not np.all((t > 0.0) & (t <= 1.0)):\n",
    "        raise ValueError(\"Information fractions must all be in (0,1].\")\n",
    "    if not np.all(np.diff(t) > 0):\n",
    "        raise ValueError(\"Information fractions must be strictly increasing.\")\n",
    "\n",
    "    if kind.upper() == \"OBF\":\n",
    "        A = spending_obf_like(t, alpha=alpha)\n",
    "    else:\n",
    "        A = spending_pocock_like(t, alpha=alpha)\n",
    "\n",
    "    A_prev = np.r_[0.0, A[:-1]]\n",
    "    alpha_inc = np.clip(A - A_prev, 1e-10, 1.0)\n",
    "    crit_z = np.array([Phi_inv_ld(1.0 - a_i / 2.0) for a_i in alpha_inc])\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"look\": np.arange(1, len(t) + 1),\n",
    "            \"t\": t,\n",
    "            \"alpha_cum\": A,\n",
    "            \"alpha_inc\": alpha_inc,\n",
    "            \"crit_z\": crit_z,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Example: 5 looks at 20%, 40%, 60%, 80%, 100% info\n",
    "t_grid = np.array([0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "df_obf_ld = lan_demets_boundaries(t_grid, alpha=0.05, kind=\"OBF\")\n",
    "df_poc_ld = lan_demets_boundaries(t_grid, alpha=0.05, kind=\"Pocock\")\n",
    "\n",
    "# Plot cumulative alpha spending\n",
    "plt.figure()\n",
    "plt.plot(df_obf_ld[\"t\"], df_obf_ld[\"alpha_cum\"], marker=\"o\", label=\"OBF-like α(t)\")\n",
    "plt.plot(df_poc_ld[\"t\"], df_poc_ld[\"alpha_cum\"], marker=\"s\", label=\"Pocock-like α(t)\")\n",
    "plt.title(\"Lan–DeMets cumulative alpha-spending (two-sided α=0.05)\")\n",
    "plt.xlabel(\"Information fraction t\")\n",
    "plt.ylabel(\"Cumulative α(t)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot critical z per look\n",
    "plt.figure()\n",
    "plt.plot(df_obf_ld[\"t\"], df_obf_ld[\"crit_z\"], marker=\"o\", label=\"OBF-like critical |z|\")\n",
    "plt.plot(df_poc_ld[\"t\"], df_poc_ld[\"crit_z\"], marker=\"s\", label=\"Pocock-like critical |z|\")\n",
    "plt.title(\"Lan–DeMets approximate critical |z| per look\")\n",
    "plt.xlabel(\"Information fraction t\")\n",
    "plt.ylabel(\"Critical |z|\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "df_obf_ld, df_poc_ld\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440c4089",
   "metadata": {},
   "source": [
    "\n",
    "**Interpretation.**\n",
    "\n",
    "- The **OBF-like** spending function keeps cumulative \\(\\alpha(t)\\) very low at early information fractions,\n",
    "  then spends most of \\(\\alpha\\) near \\(t \\approx 1\\). This corresponds to very strict early boundaries.\n",
    "- The **Pocock-like** spending function increases \\(\\alpha(t)\\) more uniformly in \\(t\\), resulting in\n",
    "  similar critical \\(|z|\\) thresholds across looks.\n",
    "- In real systems, you would usually rely on a validated group-sequential design library that solves\n",
    "  the exact boundaries, but this construction is very useful for planning and intuition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c962377",
   "metadata": {},
   "source": [
    "\n",
    "### 5.3 Peeking without correction — Type I inflation (simulation)\n",
    "\n",
    "To see *why* we bother with sequential corrections, we can simulate a scenario where the **null hypothesis is true**\n",
    "(no difference between arms), and repeatedly:\n",
    "\n",
    "1. Draw Bernoulli outcomes for A and B with the same true rate \\(p\\).  \n",
    "2. Compute a standard two-proportion z-test at several interim looks (e.g. 25%, 50%, 75%, 100%).  \n",
    "3. Declare \"significance\" as soon as any look passes the usual 1.96 threshold (two-sided 5%).\n",
    "\n",
    "If we repeat this over many simulated experiments, we can estimate the **empirical Type I error**.\n",
    "It will be **larger** than 5%, illustrating the **peeking problem**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b099f4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def simulate_peeking_type1(\n",
    "    true_p: float = 0.25,\n",
    "    total_n_per_arm: int = 40000,\n",
    "    looks: list[float] | None = None,\n",
    "    n_experiments: int = 2000,\n",
    "    seed: int | None = 123,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Simulate Type I error under repeated peeking using naive 0.05 z-threshold.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    true_p : float\n",
    "        True success probability in both arms (null is true).\n",
    "    total_n_per_arm : int\n",
    "        Total planned sample size per arm.\n",
    "    looks : list of float\n",
    "        Fractions of the total sample size at which we peek (e.g. [0.25,0.5,0.75,1.0]).\n",
    "    n_experiments : int\n",
    "        Number of independent experiments to simulate.\n",
    "    seed : int | None\n",
    "        Random seed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame with per-look cumulative reject proportion and overall Type I error.\n",
    "    \"\"\"\n",
    "    if looks is None:\n",
    "        looks = [0.25, 0.5, 0.75, 1.0]\n",
    "    looks = sorted(looks)\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    reject_any = 0\n",
    "    reject_by_look = np.zeros(len(looks), dtype=int)\n",
    "\n",
    "    for exp_idx in range(n_experiments):\n",
    "        # pre-generate outcomes under the null\n",
    "        A = rng.binomial(1, true_p, size=total_n_per_arm)\n",
    "        B = rng.binomial(1, true_p, size=total_n_per_arm)\n",
    "\n",
    "        rejected_this_exp = False\n",
    "        for i, f in enumerate(looks):\n",
    "            n_look = int(total_n_per_arm * f)\n",
    "            xA = int(A[:n_look].sum())\n",
    "            xB = int(B[:n_look].sum())\n",
    "\n",
    "            # pooled z-test under null\n",
    "            p_pool = (xA + xB) / (2.0 * n_look)\n",
    "            se = math.sqrt(p_pool * (1.0 - p_pool) * (2.0 / n_look))\n",
    "            if se == 0.0:\n",
    "                continue\n",
    "            z = (xB / n_look - xA / n_look) / se\n",
    "            pval = 2.0 * (1.0 - 0.5 * (1.0 + math.erf(abs(z) / math.sqrt(2.0))))\n",
    "\n",
    "            if pval < 0.05 and not rejected_this_exp:\n",
    "                rejected_this_exp = True\n",
    "                reject_any += 1\n",
    "                reject_by_look[i] += 1\n",
    "\n",
    "    # Compute proportions\n",
    "    type1_overall = reject_any / n_experiments\n",
    "    per_look = reject_by_look / n_experiments\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"look_index\": np.arange(1, len(looks) + 1),\n",
    "            \"info_fraction\": looks,\n",
    "            \"reject_at_look\": per_look,\n",
    "        }\n",
    "    )\n",
    "    df.attrs[\"type1_overall\"] = type1_overall\n",
    "    return df\n",
    "\n",
    "df_peek = simulate_peeking_type1(\n",
    "    true_p=0.25, total_n_per_arm=40000,\n",
    "    looks=[0.25, 0.5, 0.75, 1.0],\n",
    "    n_experiments=2000, seed=2025,\n",
    ")\n",
    "\n",
    "overall_type1 = df_peek.attrs[\"type1_overall\"]\n",
    "display(df_peek)\n",
    "overall_type1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c342e0",
   "metadata": {},
   "source": [
    "\n",
    "If you run the simulation multiple times with reasonable settings (e.g. 4 looks, 2,000–5,000 experiments),\n",
    "you will typically see an **overall Type I error** substantially **above 5%** (often in the 8–12% range,\n",
    "depending on the configuration).\n",
    "\n",
    "This is why **sequential designs** (Pocock, O'Brien–Fleming, Lan–DeMets) matter: they make it possible to\n",
    "peek **and** keep the nominal Type I error under control.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}